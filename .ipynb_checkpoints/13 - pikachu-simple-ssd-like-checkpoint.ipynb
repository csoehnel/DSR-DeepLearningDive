{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i008/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [14, 10]\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from retinanet.encoder import DataEncoder\n",
    "import imgaug as ia\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from retinanet.retinanet import RetinaNet\n",
    "from retinanet.loss import FocalLoss\n",
    "from pikachu_dataset import load_data_pikachu\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "device  = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PikachuDataset(Dataset):\n",
    "    def __init__(self, anchor_areas=None):\n",
    "        \n",
    "        self.anchor_areas = anchor_areas\n",
    "        self.train, self.val = load_data_pikachu(1)\n",
    "    \n",
    "        encoder = DataEncoder()\n",
    "        if self.anchor_areas is not None:\n",
    "            encoder.anchor_areas = self.anchor_areas  # p3 -> p7\n",
    "            \n",
    "        self.encoder = encoder \n",
    "        \n",
    "    def __len__(self):\n",
    "        return 900\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        try:\n",
    "            b = self.train.next()\n",
    "        except StopIteration:\n",
    "            self.train.reset()\n",
    "            b = self.train.next()\n",
    "            \n",
    "        image = b.data[0].asnumpy()\n",
    "        bbox = b.label[0].asnumpy()[:, 0, 1:] * 256\n",
    "        label = b.label[0].asnumpy()[:, 0, 0]\n",
    "    \n",
    "        return torch.from_numpy(image), torch.from_numpy(bbox), torch.from_numpy(label)    \n",
    "    \n",
    "    def collate_func(self, batch):\n",
    "    \n",
    "\n",
    "        images = [b[0][0] for b in batch]\n",
    "        bbox = [b[1] for b in batch]\n",
    "        labels = [b[2] for b in batch]\n",
    "        \n",
    "        encoded = [self.encoder.encode(bb, l, torch.Tensor([256, 256])) for bb, l in zip(bbox, labels)]\n",
    "        loc_target = [l[0] for l in encoded]\n",
    "        cls_target = [l[1] for l in encoded]\n",
    "        \n",
    "\n",
    "        return torch.stack(images) / 255, torch.stack(loc_target), torch.stack(cls_target)\n",
    "        \n",
    "        \n",
    "def down_sample(in_channels,out_channels):\n",
    "    return nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1), \n",
    "                  nn.BatchNorm2d(out_channels), \n",
    "                  nn.ReLU(),\n",
    "                 nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1), \n",
    "                  nn.BatchNorm2d(out_channels), \n",
    "                  nn.ReLU(),\n",
    "                  nn.MaxPool2d(2,2)\n",
    "                 \n",
    "                 )\n",
    "\n",
    "class SimpleSSD(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_cls=1, num_anchors=9):\n",
    "        super(SimpleSSD, self).__init__()\n",
    "        \n",
    "        self.n_cls = n_cls\n",
    "        self.num_anchors = num_anchors\n",
    "        \n",
    "        \n",
    "        # Base CNN (think resnet/vgg or other base network)\n",
    "        self.step1 = down_sample(3, 128)\n",
    "        self.step2 = down_sample(128, 128)\n",
    "        \n",
    "        self.step3 = down_sample(128, 128)\n",
    "        self.step4 = down_sample(128, 128)\n",
    "        self.step5 = down_sample(128, 128)\n",
    "\n",
    "        self.cls_head1 = nn.Conv2d(128, self.num_anchors * self.n_cls , 3, padding=1)\n",
    "        self.bbox_head1 = nn.Conv2d(128, self.num_anchors *4, 3, padding=1)\n",
    "        \n",
    "        self.cls_head2 = nn.Conv2d(128, self.num_anchors * self.n_cls , 3, padding=1)\n",
    "        self.bbox_head2 = nn.Conv2d(128,self.num_anchors * 4,3, padding=1)\n",
    "        \n",
    "        self.cls_head3 = nn.Conv2d(128, self.num_anchors * self.n_cls , 3, padding=1)\n",
    "        self.bbox_head3 = nn.Conv2d(128, self.num_anchors * 4,3, padding=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        step1=self.step1(x)\n",
    "        step2=self.step2(step1)\n",
    "\n",
    "        step3=self.step3(step2)\n",
    "        step4 = self.step4(step3)\n",
    "        step5 = self.step5(step4)\n",
    "        \n",
    "    \n",
    "        cls1 = self.cls_head1(step3)\n",
    "        bbox1 = self.bbox_head1(step3)\n",
    "        \n",
    "        cls2 = self.cls_head2(step4)\n",
    "        bbox2 = self.bbox_head2(step4)\n",
    "        \n",
    "        cls3 = self.cls_head3(step5)\n",
    "        bbox3 = self.bbox_head3(step5)\n",
    "    \n",
    "        cls1 = cls1.permute(0,2,3,1).contiguous().view(x.size(0), -1, self.n_cls)\n",
    "        cls2 = cls2.permute(0,2,3,1).contiguous().view(x.size(0), -1, self.n_cls)\n",
    "        cls3 = cls3.permute(0,2,3,1).contiguous().view(x.size(0), -1, self.n_cls)\n",
    "        \n",
    "        bbox1 = bbox1.permute(0,2,3,1).contiguous().view(x.size(0), -1, 4)\n",
    "        bbox2 = bbox2.permute(0,2,3,1).contiguous().view(x.size(0), -1, 4)\n",
    "        bbox3 = bbox3.permute(0,2,3,1).contiguous().view(x.size(0), -1, 4)\n",
    "      \n",
    "        cls_pred = torch.cat([cls1, cls2, cls3], dim=1)\n",
    "        bbox_pred = torch.cat([bbox1, bbox2, bbox3], dim=1)\n",
    "        \n",
    "        return bbox_pred, cls_pred\n",
    "                \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pikachu_ds =PikachuDataset(anchor_areas=[8*8.,16*16.,32*32])\n",
    "pikachu_dl = DataLoader(pikachu_ds, batch_size=2, collate_fn=pikachu_ds.collate_func)\n",
    "\n",
    "\n",
    "\n",
    "# for b in pikachu_dl:\n",
    "#     image, bounding_boxes, labels = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= SimpleSSD(1)\n",
    "model = model.to(device)\n",
    "criterion = FocalLoss(num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i008/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 3285.87158203125  loc loss 76.6645736694336\n",
      "tensor(3362.5361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 3261.96728515625  loc loss 53.99236297607422\n",
      "tensor(3315.9597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 3248.952880859375  loc loss 41.196510314941406\n",
      "tensor(3290.1494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 3206.88671875  loc loss 49.31182098388672\n",
      "tensor(3256.1985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 3182.223388671875  loc loss 56.370994567871094\n",
      "tensor(3238.5945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 3131.3857421875  loc loss 45.253597259521484\n",
      "tensor(3176.6394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 3082.290283203125  loc loss 37.85369873046875\n",
      "tensor(3120.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 3043.50390625  loc loss 33.85371780395508\n",
      "tensor(3077.3577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 3016.834716796875  loc loss 29.629013061523438\n",
      "tensor(3046.4636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2982.73486328125  loc loss 15.925989151000977\n",
      "tensor(2998.6609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2974.53173828125  loc loss 46.18855667114258\n",
      "tensor(3020.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2921.48583984375  loc loss 23.179014205932617\n",
      "tensor(2944.6648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2968.163330078125  loc loss 30.565662384033203\n",
      "tensor(2998.7290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2895.325439453125  loc loss 37.37202453613281\n",
      "tensor(2932.6975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2866.67431640625  loc loss 25.03348731994629\n",
      "tensor(2891.7078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2871.86767578125  loc loss 41.66110610961914\n",
      "tensor(2913.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2817.691650390625  loc loss 39.29642105102539\n",
      "tensor(2856.9880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2788.65380859375  loc loss 29.059206008911133\n",
      "tensor(2817.7131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2766.42333984375  loc loss 28.241535186767578\n",
      "tensor(2794.6648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2749.02880859375  loc loss 24.353925704956055\n",
      "tensor(2773.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2739.586181640625  loc loss 22.19219207763672\n",
      "tensor(2761.7783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2709.630126953125  loc loss 20.87640380859375\n",
      "tensor(2730.5066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2669.931640625  loc loss 42.31036376953125\n",
      "tensor(2712.2419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2657.5673828125  loc loss 25.90324592590332\n",
      "tensor(2683.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2629.750244140625  loc loss 23.152599334716797\n",
      "tensor(2652.9028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2588.33642578125  loc loss 26.03858184814453\n",
      "tensor(2614.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2619.80712890625  loc loss 14.86471176147461\n",
      "tensor(2634.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2662.102783203125  loc loss 61.21580505371094\n",
      "tensor(2723.3186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2523.325439453125  loc loss 14.120319366455078\n",
      "tensor(2537.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2562.727783203125  loc loss 23.70297622680664\n",
      "tensor(2586.4307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2506.60400390625  loc loss 24.417081832885742\n",
      "tensor(2531.0210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2503.404296875  loc loss 22.99323272705078\n",
      "tensor(2526.3975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2442.9443359375  loc loss 21.008052825927734\n",
      "tensor(2463.9524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2477.4013671875  loc loss 26.83771514892578\n",
      "tensor(2504.2390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2407.2216796875  loc loss 28.011106491088867\n",
      "tensor(2435.2327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2434.63720703125  loc loss 20.012638092041016\n",
      "tensor(2454.6499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2368.748046875  loc loss 26.25076675415039\n",
      "tensor(2394.9988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2342.796875  loc loss 13.538761138916016\n",
      "tensor(2356.3357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2341.41845703125  loc loss 25.788909912109375\n",
      "tensor(2367.2073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2309.81494140625  loc loss 15.452535629272461\n",
      "tensor(2325.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2291.41943359375  loc loss 14.870145797729492\n",
      "tensor(2306.2896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2376.29443359375  loc loss 31.401586532592773\n",
      "tensor(2407.6960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2269.61279296875  loc loss 16.023780822753906\n",
      "tensor(2285.6365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2222.720703125  loc loss 9.381233215332031\n",
      "tensor(2232.1021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2235.81396484375  loc loss 17.48438262939453\n",
      "tensor(2253.2983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2206.0400390625  loc loss 12.349071502685547\n",
      "tensor(2218.3892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2142.57080078125  loc loss 25.760255813598633\n",
      "tensor(2168.3311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2226.93310546875  loc loss 17.606477737426758\n",
      "tensor(2244.5396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2142.460205078125  loc loss 17.183076858520508\n",
      "tensor(2159.6433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2149.19580078125  loc loss 12.743430137634277\n",
      "tensor(2161.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2135.47314453125  loc loss 14.516846656799316\n",
      "tensor(2149.9900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2177.04931640625  loc loss 14.295112609863281\n",
      "tensor(2191.3445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2161.3447265625  loc loss 13.540294647216797\n",
      "tensor(2174.8850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2106.18701171875  loc loss 11.96468734741211\n",
      "tensor(2118.1516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2099.4384765625  loc loss 12.936064720153809\n",
      "tensor(2112.3745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2119.6376953125  loc loss 11.039684295654297\n",
      "tensor(2130.6775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2080.506591796875  loc loss 10.759475708007812\n",
      "tensor(2091.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2018.441162109375  loc loss 25.925212860107422\n",
      "tensor(2044.3663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1992.8399658203125  loc loss 10.368677139282227\n",
      "tensor(2003.2086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2045.333740234375  loc loss 17.642946243286133\n",
      "tensor(2062.9768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1948.802734375  loc loss 15.881096839904785\n",
      "tensor(1964.6838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1959.4224853515625  loc loss 12.770339965820312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1972.1929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 2044.9967041015625  loc loss 11.361414909362793\n",
      "tensor(2056.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1888.945556640625  loc loss 9.24569034576416\n",
      "tensor(1898.1913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1893.763916015625  loc loss 10.417829513549805\n",
      "tensor(1904.1818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1915.620361328125  loc loss 9.940876007080078\n",
      "tensor(1925.5613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1913.145263671875  loc loss 15.706160545349121\n",
      "tensor(1928.8514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1936.7666015625  loc loss 14.889689445495605\n",
      "tensor(1951.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1847.9910888671875  loc loss 11.877334594726562\n",
      "tensor(1859.8684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1855.0537109375  loc loss 29.955204010009766\n",
      "tensor(1885.0089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1906.30322265625  loc loss 10.312846183776855\n",
      "tensor(1916.6161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1864.270263671875  loc loss 8.142165184020996\n",
      "tensor(1872.4125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1785.515869140625  loc loss 11.912141799926758\n",
      "tensor(1797.4280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1843.782470703125  loc loss 26.44822883605957\n",
      "tensor(1870.2307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1767.713623046875  loc loss 13.507705688476562\n",
      "tensor(1781.2213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1836.9913330078125  loc loss 13.716440200805664\n",
      "tensor(1850.7078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1955.615966796875  loc loss 26.571758270263672\n",
      "tensor(1982.1877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1738.9334716796875  loc loss 9.949370384216309\n",
      "tensor(1748.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1700.738037109375  loc loss 11.364908218383789\n",
      "tensor(1712.1029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1736.716552734375  loc loss 17.296072006225586\n",
      "tensor(1754.0126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1720.91064453125  loc loss 14.957012176513672\n",
      "tensor(1735.8677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1765.8369140625  loc loss 19.233776092529297\n",
      "tensor(1785.0707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1660.055419921875  loc loss 11.145013809204102\n",
      "tensor(1671.2004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1605.175048828125  loc loss 9.66372013092041\n",
      "tensor(1614.8387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1706.220947265625  loc loss 14.49929141998291\n",
      "tensor(1720.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1689.017578125  loc loss 22.132762908935547\n",
      "tensor(1711.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1702.6192626953125  loc loss 15.026373863220215\n",
      "tensor(1717.6456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1643.9298095703125  loc loss 13.505001068115234\n",
      "tensor(1657.4348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1623.19580078125  loc loss 8.366905212402344\n",
      "tensor(1631.5627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1632.289306640625  loc loss 17.352069854736328\n",
      "tensor(1649.6414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1613.38671875  loc loss 11.507685661315918\n",
      "tensor(1624.8944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1581.041748046875  loc loss 7.856517791748047\n",
      "tensor(1588.8983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1533.66259765625  loc loss 12.593685150146484\n",
      "tensor(1546.2562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1569.561279296875  loc loss 13.291672706604004\n",
      "tensor(1582.8529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1548.8682861328125  loc loss 9.829854011535645\n",
      "tensor(1558.6981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1571.917724609375  loc loss 18.970169067382812\n",
      "tensor(1590.8879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1606.740478515625  loc loss 11.203216552734375\n",
      "tensor(1617.9437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1573.3277587890625  loc loss 15.678356170654297\n",
      "tensor(1589.0061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1534.228515625  loc loss 8.207372665405273\n",
      "tensor(1542.4359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1571.900390625  loc loss 11.178975105285645\n",
      "tensor(1583.0793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1511.7333984375  loc loss 11.359208106994629\n",
      "tensor(1523.0927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1596.04443359375  loc loss 9.38558578491211\n",
      "tensor(1605.4301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1412.10107421875  loc loss 9.711989402770996\n",
      "tensor(1421.8131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1531.2669677734375  loc loss 15.668204307556152\n",
      "tensor(1546.9352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1406.953369140625  loc loss 15.282175064086914\n",
      "tensor(1422.2356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1430.1055908203125  loc loss 10.810382843017578\n",
      "tensor(1440.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1402.48779296875  loc loss 13.844560623168945\n",
      "tensor(1416.3324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1462.1943359375  loc loss 15.048137664794922\n",
      "tensor(1477.2424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1542.38671875  loc loss 13.326001167297363\n",
      "tensor(1555.7128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1339.54638671875  loc loss 15.308671951293945\n",
      "tensor(1354.8551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1349.24853515625  loc loss 7.928434371948242\n",
      "tensor(1357.1770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1366.676025390625  loc loss 9.34000015258789\n",
      "tensor(1376.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1403.13916015625  loc loss 10.72277545928955\n",
      "tensor(1413.8619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1379.908447265625  loc loss 11.092170715332031\n",
      "tensor(1391.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1494.964599609375  loc loss 10.110591888427734\n",
      "tensor(1505.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1272.2088623046875  loc loss 10.609888076782227\n",
      "tensor(1282.8187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1273.8778076171875  loc loss 9.169063568115234\n",
      "tensor(1283.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1350.146484375  loc loss 17.14336585998535\n",
      "tensor(1367.2898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1321.916259765625  loc loss 6.416915416717529\n",
      "tensor(1328.3331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1311.806640625  loc loss 11.836688995361328\n",
      "tensor(1323.6433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1270.103515625  loc loss 13.802555084228516\n",
      "tensor(1283.9061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1205.541259765625  loc loss 11.37027645111084\n",
      "tensor(1216.9115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1374.905029296875  loc loss 12.509012222290039\n",
      "tensor(1387.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1263.30078125  loc loss 11.544059753417969\n",
      "tensor(1274.8448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1209.4803466796875  loc loss 7.849997520446777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1217.3303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1267.7724609375  loc loss 12.23473072052002\n",
      "tensor(1280.0072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1279.4405517578125  loc loss 10.723088264465332\n",
      "tensor(1290.1637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1170.8897705078125  loc loss 8.72569465637207\n",
      "tensor(1179.6155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1160.641845703125  loc loss 18.372451782226562\n",
      "tensor(1179.0143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1245.3135986328125  loc loss 10.028266906738281\n",
      "tensor(1255.3419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1232.726806640625  loc loss 9.862029075622559\n",
      "tensor(1242.5889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1340.91357421875  loc loss 8.856801986694336\n",
      "tensor(1349.7704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1195.817138671875  loc loss 12.678191184997559\n",
      "tensor(1208.4954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1307.896484375  loc loss 10.581029891967773\n",
      "tensor(1318.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1202.222900390625  loc loss 11.342426300048828\n",
      "tensor(1213.5653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1163.2794189453125  loc loss 7.035325050354004\n",
      "tensor(1170.3147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1241.07373046875  loc loss 13.78880500793457\n",
      "tensor(1254.8625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1126.987548828125  loc loss 9.139640808105469\n",
      "tensor(1136.1272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1180.17529296875  loc loss 8.587514877319336\n",
      "tensor(1188.7628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1056.59228515625  loc loss 9.514862060546875\n",
      "tensor(1066.1072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1147.3272705078125  loc loss 14.376334190368652\n",
      "tensor(1161.7036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1126.6572265625  loc loss 5.2635345458984375\n",
      "tensor(1131.9208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1084.9642333984375  loc loss 6.749878406524658\n",
      "tensor(1091.7141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1121.968017578125  loc loss 11.197881698608398\n",
      "tensor(1133.1659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1037.119873046875  loc loss 10.782554626464844\n",
      "tensor(1047.9025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1134.9295654296875  loc loss 8.603981971740723\n",
      "tensor(1143.5336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1191.6300048828125  loc loss 8.834219932556152\n",
      "tensor(1200.4642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1104.6748046875  loc loss 12.85537052154541\n",
      "tensor(1117.5302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1103.5369873046875  loc loss 9.192060470581055\n",
      "tensor(1112.7290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1088.125  loc loss 6.353013515472412\n",
      "tensor(1094.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1148.2213134765625  loc loss 7.071103096008301\n",
      "tensor(1155.2924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1073.256103515625  loc loss 9.243708610534668\n",
      "tensor(1082.4998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1105.847900390625  loc loss 12.046500205993652\n",
      "tensor(1117.8944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1061.256103515625  loc loss 7.208425998687744\n",
      "tensor(1068.4645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1066.12255859375  loc loss 8.001481056213379\n",
      "tensor(1074.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1147.7576904296875  loc loss 11.5269775390625\n",
      "tensor(1159.2847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1102.905029296875  loc loss 10.591523170471191\n",
      "tensor(1113.4966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 990.695556640625  loc loss 13.846624374389648\n",
      "tensor(1004.5422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1256.72705078125  loc loss 13.577152252197266\n",
      "tensor(1270.3042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 989.1255493164062  loc loss 5.551806926727295\n",
      "tensor(994.6774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 952.8417358398438  loc loss 17.321062088012695\n",
      "tensor(970.1628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1060.1201171875  loc loss 7.645580768585205\n",
      "tensor(1067.7657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 950.0921020507812  loc loss 7.862603187561035\n",
      "tensor(957.9547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 966.0123291015625  loc loss 7.887875556945801\n",
      "tensor(973.9002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1008.473388671875  loc loss 12.14117431640625\n",
      "tensor(1020.6146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1098.1610107421875  loc loss 9.553675651550293\n",
      "tensor(1107.7147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 925.3370971679688  loc loss 9.112220764160156\n",
      "tensor(934.4493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1001.5693359375  loc loss 9.903810501098633\n",
      "tensor(1011.4731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 937.9564208984375  loc loss 8.056436538696289\n",
      "tensor(946.0129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 929.6883544921875  loc loss 11.199777603149414\n",
      "tensor(940.8881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 873.3460083007812  loc loss 6.474143981933594\n",
      "tensor(879.8201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 899.376708984375  loc loss 8.352806091308594\n",
      "tensor(907.7295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 872.4580078125  loc loss 7.160400867462158\n",
      "tensor(879.6184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 1046.3055419921875  loc loss 7.940572261810303\n",
      "tensor(1054.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 857.7037353515625  loc loss 9.969640731811523\n",
      "tensor(867.6734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 950.3812255859375  loc loss 10.726058959960938\n",
      "tensor(961.1073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 905.1376953125  loc loss 9.531628608703613\n",
      "tensor(914.6693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 963.0993041992188  loc loss 8.812248229980469\n",
      "tensor(971.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 926.6613159179688  loc loss 6.1313395500183105\n",
      "tensor(932.7927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 888.2501220703125  loc loss 14.673927307128906\n",
      "tensor(902.9241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 847.635498046875  loc loss 9.789331436157227\n",
      "tensor(857.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 913.1992797851562  loc loss 7.329581260681152\n",
      "tensor(920.5289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 783.7783203125  loc loss 11.340782165527344\n",
      "tensor(795.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 828.283935546875  loc loss 11.48036003112793\n",
      "tensor(839.7643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 961.394775390625  loc loss 13.987804412841797\n",
      "tensor(975.3826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 803.12646484375  loc loss 9.827432632446289\n",
      "tensor(812.9539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 874.2571411132812  loc loss 12.800724983215332\n",
      "tensor(887.0579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 862.8438110351562  loc loss 8.376605033874512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(871.2204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 765.312744140625  loc loss 8.971872329711914\n",
      "tensor(774.2846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 891.738525390625  loc loss 10.102952003479004\n",
      "tensor(901.8415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 908.17724609375  loc loss 8.135419845581055\n",
      "tensor(916.3127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 831.1828002929688  loc loss 7.790644645690918\n",
      "tensor(838.9734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 896.2454833984375  loc loss 10.274604797363281\n",
      "tensor(906.5201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 815.21923828125  loc loss 9.364142417907715\n",
      "tensor(824.5834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 764.0496826171875  loc loss 7.516724586486816\n",
      "tensor(771.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 763.677490234375  loc loss 9.388988494873047\n",
      "tensor(773.0665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 846.4490356445312  loc loss 8.807718276977539\n",
      "tensor(855.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 927.8341064453125  loc loss 7.974050998687744\n",
      "tensor(935.8082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 759.3652954101562  loc loss 7.83391809463501\n",
      "tensor(767.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 772.5014038085938  loc loss 9.232112884521484\n",
      "tensor(781.7335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 774.54345703125  loc loss 7.225408554077148\n",
      "tensor(781.7689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 783.367919921875  loc loss 7.322676658630371\n",
      "tensor(790.6906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 740.5195922851562  loc loss 8.939311981201172\n",
      "tensor(749.4589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 812.8895263671875  loc loss 7.723189353942871\n",
      "tensor(820.6127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 788.5986938476562  loc loss 4.776003360748291\n",
      "tensor(793.3747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 916.9932250976562  loc loss 6.721926212310791\n",
      "tensor(923.7151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 856.0028076171875  loc loss 5.721637725830078\n",
      "tensor(861.7244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 854.0195922851562  loc loss 11.168086051940918\n",
      "tensor(865.1877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 777.5559692382812  loc loss 7.4509687423706055\n",
      "tensor(785.0070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 666.6636352539062  loc loss 6.341188430786133\n",
      "tensor(673.0048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 676.2173461914062  loc loss 11.160908699035645\n",
      "tensor(687.3782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 754.793212890625  loc loss 8.098443031311035\n",
      "tensor(762.8917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 767.188232421875  loc loss 7.020396709442139\n",
      "tensor(774.2086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 904.0557250976562  loc loss 12.443731307983398\n",
      "tensor(916.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 684.7647705078125  loc loss 7.643856048583984\n",
      "tensor(692.4086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 709.7652587890625  loc loss 10.34721851348877\n",
      "tensor(720.1125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 854.8023681640625  loc loss 5.366368293762207\n",
      "tensor(860.1688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 686.653076171875  loc loss 8.2383394241333\n",
      "tensor(694.8914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 786.8370971679688  loc loss 8.518568992614746\n",
      "tensor(795.3557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 792.3135375976562  loc loss 5.172852993011475\n",
      "tensor(797.4864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 773.3515625  loc loss 5.98248291015625\n",
      "tensor(779.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 711.8477783203125  loc loss 5.755982875823975\n",
      "tensor(717.6038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 846.4076538085938  loc loss 7.986079692840576\n",
      "tensor(854.3937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 644.7921142578125  loc loss 7.023562431335449\n",
      "tensor(651.8157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 665.6483154296875  loc loss 9.716602325439453\n",
      "tensor(675.3649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 757.6094360351562  loc loss 4.139438152313232\n",
      "tensor(761.7489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 651.4296875  loc loss 4.069673538208008\n",
      "tensor(655.4994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 759.7023315429688  loc loss 9.861740112304688\n",
      "tensor(769.5641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 649.5433349609375  loc loss 9.020590782165527\n",
      "tensor(658.5639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 646.2435913085938  loc loss 7.551451683044434\n",
      "tensor(653.7950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 664.5481567382812  loc loss 5.5805182456970215\n",
      "tensor(670.1287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 748.9874267578125  loc loss 6.619818687438965\n",
      "tensor(755.6072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 598.0517578125  loc loss 13.371084213256836\n",
      "tensor(611.4229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 643.89990234375  loc loss 5.138298034667969\n",
      "tensor(649.0382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 705.5062255859375  loc loss 12.716773986816406\n",
      "tensor(718.2230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 652.4996337890625  loc loss 7.342280387878418\n",
      "tensor(659.8419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 624.680908203125  loc loss 6.505617618560791\n",
      "tensor(631.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 662.0791625976562  loc loss 6.6422038078308105\n",
      "tensor(668.7214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 647.4371948242188  loc loss 7.849791526794434\n",
      "tensor(655.2870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 597.814453125  loc loss 8.383774757385254\n",
      "tensor(606.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 572.0115966796875  loc loss 7.388213157653809\n",
      "tensor(579.3998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 673.6963500976562  loc loss 9.930808067321777\n",
      "tensor(683.6271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 618.77734375  loc loss 9.598755836486816\n",
      "tensor(628.3761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 691.6387939453125  loc loss 7.672940254211426\n",
      "tensor(699.3117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 633.114501953125  loc loss 8.935126304626465\n",
      "tensor(642.0496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 584.6348876953125  loc loss 7.9141435623168945\n",
      "tensor(592.5490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 648.6368408203125  loc loss 5.287744522094727\n",
      "tensor(653.9246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 704.998046875  loc loss 7.949850082397461\n",
      "tensor(712.9479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 617.5164794921875  loc loss 8.852579116821289\n",
      "tensor(626.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 584.099365234375  loc loss 7.050443649291992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(591.1498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 578.287841796875  loc loss 7.251117706298828\n",
      "tensor(585.5389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 591.87451171875  loc loss 6.422189712524414\n",
      "tensor(598.2967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 616.0679931640625  loc loss 3.4737141132354736\n",
      "tensor(619.5417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 676.2862548828125  loc loss 6.3622355461120605\n",
      "tensor(682.6485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 637.5068359375  loc loss 6.822163105010986\n",
      "tensor(644.3290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 651.19970703125  loc loss 7.644341468811035\n",
      "tensor(658.8441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 661.4060668945312  loc loss 7.278464317321777\n",
      "tensor(668.6845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 538.4419555664062  loc loss 9.23504638671875\n",
      "tensor(547.6770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 581.9776000976562  loc loss 5.678793907165527\n",
      "tensor(587.6564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 600.849853515625  loc loss 9.862859725952148\n",
      "tensor(610.7127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 569.8580322265625  loc loss 10.224550247192383\n",
      "tensor(580.0826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 590.8272094726562  loc loss 6.805682182312012\n",
      "tensor(597.6329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 545.31591796875  loc loss 4.415274620056152\n",
      "tensor(549.7312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 615.2406616210938  loc loss 7.798072814941406\n",
      "tensor(623.0388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 606.5202026367188  loc loss 6.294327735900879\n",
      "tensor(612.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 582.0732421875  loc loss 5.478848934173584\n",
      "tensor(587.5521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 544.4407348632812  loc loss 9.415063858032227\n",
      "tensor(553.8558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 508.9964599609375  loc loss 8.444482803344727\n",
      "tensor(517.4409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 486.23394775390625  loc loss 7.174124717712402\n",
      "tensor(493.4081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 488.46258544921875  loc loss 7.718693733215332\n",
      "tensor(496.1813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 681.6246948242188  loc loss 8.747051239013672\n",
      "tensor(690.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 553.101806640625  loc loss 9.47026538848877\n",
      "tensor(562.5721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 546.4764404296875  loc loss 9.227690696716309\n",
      "tensor(555.7041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 590.8658447265625  loc loss 7.144738674163818\n",
      "tensor(598.0106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 530.1080322265625  loc loss 9.280265808105469\n",
      "tensor(539.3883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 463.136474609375  loc loss 7.296663761138916\n",
      "tensor(470.4331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 520.87158203125  loc loss 10.237894058227539\n",
      "tensor(531.1095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 508.0268859863281  loc loss 6.827630519866943\n",
      "tensor(514.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 518.3152465820312  loc loss 4.826203346252441\n",
      "tensor(523.1415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 558.0244750976562  loc loss 7.16107177734375\n",
      "tensor(565.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 484.26702880859375  loc loss 7.616641521453857\n",
      "tensor(491.8837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 548.3311157226562  loc loss 8.265716552734375\n",
      "tensor(556.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 569.6304321289062  loc loss 9.177925109863281\n",
      "tensor(578.8083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 525.4456787109375  loc loss 10.738445281982422\n",
      "tensor(536.1841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 552.8018798828125  loc loss 11.377461433410645\n",
      "tensor(564.1793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 561.8331298828125  loc loss 8.578487396240234\n",
      "tensor(570.4116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 506.9928283691406  loc loss 11.071276664733887\n",
      "tensor(518.0641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 498.38507080078125  loc loss 7.75950288772583\n",
      "tensor(506.1446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 483.7197265625  loc loss 6.294797897338867\n",
      "tensor(490.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 497.04302978515625  loc loss 5.656007766723633\n",
      "tensor(502.6990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 467.4388427734375  loc loss 9.367650032043457\n",
      "tensor(476.8065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 431.76324462890625  loc loss 5.571557521820068\n",
      "tensor(437.3348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 474.37841796875  loc loss 7.450189590454102\n",
      "tensor(481.8286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 575.3406372070312  loc loss 6.484808444976807\n",
      "tensor(581.8254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 523.4397583007812  loc loss 7.138615608215332\n",
      "tensor(530.5784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 447.082275390625  loc loss 8.102928161621094\n",
      "tensor(455.1852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 445.8819274902344  loc loss 10.636224746704102\n",
      "tensor(456.5182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 564.6690673828125  loc loss 8.204337120056152\n",
      "tensor(572.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 479.358154296875  loc loss 6.3165483474731445\n",
      "tensor(485.6747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 566.5474853515625  loc loss 7.546850204467773\n",
      "tensor(574.0944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 450.6460266113281  loc loss 9.010122299194336\n",
      "tensor(459.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 442.9755859375  loc loss 4.327910900115967\n",
      "tensor(447.3035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 431.55828857421875  loc loss 9.123764991760254\n",
      "tensor(440.6821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 463.6028137207031  loc loss 5.932278633117676\n",
      "tensor(469.5351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 427.4938049316406  loc loss 9.168363571166992\n",
      "tensor(436.6622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 400.32769775390625  loc loss 8.139074325561523\n",
      "tensor(408.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 410.9111022949219  loc loss 5.595576763153076\n",
      "tensor(416.5067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 608.0372314453125  loc loss 5.8040056228637695\n",
      "tensor(613.8412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 424.4757995605469  loc loss 5.273575305938721\n",
      "tensor(429.7494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 413.42333984375  loc loss 9.707335472106934\n",
      "tensor(423.1307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 450.18963623046875  loc loss 12.11575984954834\n",
      "tensor(462.3054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 422.170166015625  loc loss 7.143620014190674\n",
      "tensor(429.3138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 507.0335998535156  loc loss 6.859777450561523\n",
      "tensor(513.8934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 502.04681396484375  loc loss 5.562747955322266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(507.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 378.04290771484375  loc loss 6.034755706787109\n",
      "tensor(384.0777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 377.4385681152344  loc loss 6.565042972564697\n",
      "tensor(384.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 453.92425537109375  loc loss 8.305401802062988\n",
      "tensor(462.2296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 401.0892333984375  loc loss 6.728890895843506\n",
      "tensor(407.8181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 437.09771728515625  loc loss 5.129941940307617\n",
      "tensor(442.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 504.13116455078125  loc loss 5.730410575866699\n",
      "tensor(509.8616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 453.5032653808594  loc loss 8.655441284179688\n",
      "tensor(462.1587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 460.472900390625  loc loss 4.716477394104004\n",
      "tensor(465.1894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 390.742919921875  loc loss 6.731926441192627\n",
      "tensor(397.4749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 399.7297668457031  loc loss 4.773828983306885\n",
      "tensor(404.5036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 412.9272766113281  loc loss 8.667088508605957\n",
      "tensor(421.5944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 451.8145751953125  loc loss 9.917591094970703\n",
      "tensor(461.7322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 370.56756591796875  loc loss 9.606132507324219\n",
      "tensor(380.1737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 479.63836669921875  loc loss 7.024224281311035\n",
      "tensor(486.6626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 402.52191162109375  loc loss 7.986855506896973\n",
      "tensor(410.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 468.8424072265625  loc loss 6.342695713043213\n",
      "tensor(475.1851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 418.96173095703125  loc loss 6.539679050445557\n",
      "tensor(425.5014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 359.20562744140625  loc loss 5.909200668334961\n",
      "tensor(365.1148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 533.5340576171875  loc loss 7.272063255310059\n",
      "tensor(540.8061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 469.092041015625  loc loss 7.158749103546143\n",
      "tensor(476.2508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 475.8917541503906  loc loss 5.932609558105469\n",
      "tensor(481.8244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 457.7275390625  loc loss 7.916302680969238\n",
      "tensor(465.6438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 430.0735168457031  loc loss 5.430431365966797\n",
      "tensor(435.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 382.4666442871094  loc loss 6.965640068054199\n",
      "tensor(389.4323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 350.6961364746094  loc loss 5.284470081329346\n",
      "tensor(355.9806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 510.5841369628906  loc loss 8.511045455932617\n",
      "tensor(519.0952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 368.8526916503906  loc loss 7.016007900238037\n",
      "tensor(375.8687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 367.19329833984375  loc loss 6.611667633056641\n",
      "tensor(373.8050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 419.4164123535156  loc loss 7.364597797393799\n",
      "tensor(426.7810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 359.2715759277344  loc loss 6.30223274230957\n",
      "tensor(365.5738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 370.34979248046875  loc loss 7.041408061981201\n",
      "tensor(377.3912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 372.7960510253906  loc loss 4.262754917144775\n",
      "tensor(377.0588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 347.92523193359375  loc loss 6.731017589569092\n",
      "tensor(354.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 384.3581237792969  loc loss 5.259423732757568\n",
      "tensor(389.6176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 342.4346008300781  loc loss 5.4310688972473145\n",
      "tensor(347.8657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 378.57080078125  loc loss 6.669511318206787\n",
      "tensor(385.2403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 399.066162109375  loc loss 5.5589518547058105\n",
      "tensor(404.6251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 412.7855529785156  loc loss 9.327040672302246\n",
      "tensor(422.1126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 357.2080078125  loc loss 5.72936487197876\n",
      "tensor(362.9374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 372.20550537109375  loc loss 12.830167770385742\n",
      "tensor(385.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 357.29888916015625  loc loss 6.865756034851074\n",
      "tensor(364.1646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 363.44293212890625  loc loss 7.710369110107422\n",
      "tensor(371.1533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 347.76068115234375  loc loss 4.901301383972168\n",
      "tensor(352.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 393.3672790527344  loc loss 7.090780258178711\n",
      "tensor(400.4581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 380.2107238769531  loc loss 8.894845008850098\n",
      "tensor(389.1056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 329.18719482421875  loc loss 11.394655227661133\n",
      "tensor(340.5818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 382.3927917480469  loc loss 6.644443511962891\n",
      "tensor(389.0372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 356.2972412109375  loc loss 6.59812068939209\n",
      "tensor(362.8954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 401.7032775878906  loc loss 7.046457767486572\n",
      "tensor(408.7497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 337.7335205078125  loc loss 8.507415771484375\n",
      "tensor(346.2409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 346.1295471191406  loc loss 7.457559585571289\n",
      "tensor(353.5871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 408.54461669921875  loc loss 7.420755863189697\n",
      "tensor(415.9654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 331.935302734375  loc loss 5.076373100280762\n",
      "tensor(337.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 416.12261962890625  loc loss 7.11423397064209\n",
      "tensor(423.2368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 360.0269775390625  loc loss 6.769518852233887\n",
      "tensor(366.7965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 308.96014404296875  loc loss 6.034977436065674\n",
      "tensor(314.9951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 351.4039306640625  loc loss 5.749231338500977\n",
      "tensor(357.1532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 331.62542724609375  loc loss 3.753783941268921\n",
      "tensor(335.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 362.000732421875  loc loss 9.375555038452148\n",
      "tensor(371.3763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 420.47723388671875  loc loss 7.843111991882324\n",
      "tensor(428.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 302.016357421875  loc loss 6.001448631286621\n",
      "tensor(308.0178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 321.9652099609375  loc loss 5.823017120361328\n",
      "tensor(327.7882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 316.44482421875  loc loss 6.164759159088135\n",
      "tensor(322.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 373.46343994140625  loc loss 11.38671588897705\n",
      "tensor(384.8502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 295.0682373046875  loc loss 4.551215171813965\n",
      "tensor(299.6194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 300.40283203125  loc loss 5.54019832611084\n",
      "tensor(305.9430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 495.18756103515625  loc loss 7.676693916320801\n",
      "tensor(502.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 348.8798828125  loc loss 5.741318702697754\n",
      "tensor(354.6212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 301.29180908203125  loc loss 6.4577226638793945\n",
      "tensor(307.7495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 283.36614990234375  loc loss 9.557084083557129\n",
      "tensor(292.9232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 317.5331115722656  loc loss 6.53816032409668\n",
      "tensor(324.0713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 412.471923828125  loc loss 8.751762390136719\n",
      "tensor(421.2237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 344.33099365234375  loc loss 8.612858772277832\n",
      "tensor(352.9438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 311.2261657714844  loc loss 6.417726993560791\n",
      "tensor(317.6439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 335.16717529296875  loc loss 8.399380683898926\n",
      "tensor(343.5666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 340.57373046875  loc loss 5.474073886871338\n",
      "tensor(346.0478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 302.7657775878906  loc loss 6.397538185119629\n",
      "tensor(309.1633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 269.840087890625  loc loss 6.3307390213012695\n",
      "tensor(276.1708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 322.10223388671875  loc loss 6.795153617858887\n",
      "tensor(328.8974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 305.7728271484375  loc loss 4.274228096008301\n",
      "tensor(310.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 339.2903137207031  loc loss 7.292749881744385\n",
      "tensor(346.5831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 361.58837890625  loc loss 8.119805335998535\n",
      "tensor(369.7082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 377.0443115234375  loc loss 6.28514289855957\n",
      "tensor(383.3295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 366.8945617675781  loc loss 5.585314750671387\n",
      "tensor(372.4799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 289.22552490234375  loc loss 5.854689598083496\n",
      "tensor(295.0802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 309.4285583496094  loc loss 2.867388963699341\n",
      "tensor(312.2960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 384.66400146484375  loc loss 6.935401439666748\n",
      "tensor(391.5994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 360.599853515625  loc loss 7.743044376373291\n",
      "tensor(368.3429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 300.5042724609375  loc loss 6.714565277099609\n",
      "tensor(307.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 280.49945068359375  loc loss 4.7211809158325195\n",
      "tensor(285.2206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 305.6270446777344  loc loss 9.025368690490723\n",
      "tensor(314.6524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 329.2408142089844  loc loss 6.764604568481445\n",
      "tensor(336.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 346.1770935058594  loc loss 7.833428382873535\n",
      "tensor(354.0105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 344.434326171875  loc loss 5.298814296722412\n",
      "tensor(349.7332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 274.28778076171875  loc loss 5.532984256744385\n",
      "tensor(279.8208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 282.48187255859375  loc loss 4.74644136428833\n",
      "tensor(287.2283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 287.6801452636719  loc loss 7.397300720214844\n",
      "tensor(295.0775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 431.30560302734375  loc loss 8.299577713012695\n",
      "tensor(439.6052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 299.85186767578125  loc loss 6.937039375305176\n",
      "tensor(306.7889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 291.5814514160156  loc loss 5.297724723815918\n",
      "tensor(296.8792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 288.953125  loc loss 7.544590950012207\n",
      "tensor(296.4977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 271.3542785644531  loc loss 8.716989517211914\n",
      "tensor(280.0713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 273.44390869140625  loc loss 4.220965385437012\n",
      "tensor(277.6649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 360.1443176269531  loc loss 7.262930393218994\n",
      "tensor(367.4073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 290.34783935546875  loc loss 6.537079811096191\n",
      "tensor(296.8849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 293.82861328125  loc loss 5.400479793548584\n",
      "tensor(299.2291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 330.34002685546875  loc loss 5.184327125549316\n",
      "tensor(335.5244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 288.5615234375  loc loss 6.976616382598877\n",
      "tensor(295.5381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 277.8075256347656  loc loss 5.103297233581543\n",
      "tensor(282.9108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 261.9868469238281  loc loss 5.7892255783081055\n",
      "tensor(267.7761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 251.9537353515625  loc loss 5.064450740814209\n",
      "tensor(257.0182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 378.135986328125  loc loss 8.893627166748047\n",
      "tensor(387.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 306.3197937011719  loc loss 9.777067184448242\n",
      "tensor(316.0969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 293.90185546875  loc loss 10.828682899475098\n",
      "tensor(304.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 288.04486083984375  loc loss 8.612605094909668\n",
      "tensor(296.6575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 293.4414367675781  loc loss 6.852163791656494\n",
      "tensor(300.2936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 343.83721923828125  loc loss 5.406965255737305\n",
      "tensor(349.2442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 285.4630126953125  loc loss 7.635936260223389\n",
      "tensor(293.0989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 240.2296142578125  loc loss 6.175248146057129\n",
      "tensor(246.4049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 270.3486022949219  loc loss 5.600019454956055\n",
      "tensor(275.9486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 257.39215087890625  loc loss 5.5664496421813965\n",
      "tensor(262.9586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 258.8192138671875  loc loss 8.791301727294922\n",
      "tensor(267.6105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 266.4305419921875  loc loss 6.154366970062256\n",
      "tensor(272.5849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 246.86669921875  loc loss 6.774384498596191\n",
      "tensor(253.6411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 280.2986755371094  loc loss 3.247237205505371\n",
      "tensor(283.5459, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12096])\n",
      "cls loss 327.48309326171875  loc loss 7.090371608734131\n",
      "tensor(334.5735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 248.7919921875  loc loss 5.123443603515625\n",
      "tensor(253.9154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 261.503662109375  loc loss 5.812217712402344\n",
      "tensor(267.3159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 223.19418334960938  loc loss 7.327603340148926\n",
      "tensor(230.5218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 281.7286376953125  loc loss 5.527695655822754\n",
      "tensor(287.2563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 235.23562622070312  loc loss 6.460136413574219\n",
      "tensor(241.6958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 260.2429504394531  loc loss 4.825088977813721\n",
      "tensor(265.0681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 259.74420166015625  loc loss 4.73804235458374\n",
      "tensor(264.4822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 229.6614990234375  loc loss 5.053355693817139\n",
      "tensor(234.7149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 259.07147216796875  loc loss 5.398843765258789\n",
      "tensor(264.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 229.3874969482422  loc loss 4.117529392242432\n",
      "tensor(233.5050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 248.5463409423828  loc loss 4.521607398986816\n",
      "tensor(253.0679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 254.2607879638672  loc loss 7.250014781951904\n",
      "tensor(261.5108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 240.97445678710938  loc loss 6.886149883270264\n",
      "tensor(247.8606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 252.0354461669922  loc loss 6.00750207901001\n",
      "tensor(258.0429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 275.6295166015625  loc loss 6.344069480895996\n",
      "tensor(281.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 272.98455810546875  loc loss 5.106873512268066\n",
      "tensor(278.0914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 256.1997985839844  loc loss 7.792313098907471\n",
      "tensor(263.9921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 221.18185424804688  loc loss 6.283848285675049\n",
      "tensor(227.4657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 269.2344970703125  loc loss 8.758363723754883\n",
      "tensor(277.9929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 231.87173461914062  loc loss 6.137012958526611\n",
      "tensor(238.0087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 204.48001098632812  loc loss 7.627584934234619\n",
      "tensor(212.1076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 277.2667236328125  loc loss 7.011575698852539\n",
      "tensor(284.2783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 226.13360595703125  loc loss 6.062939167022705\n",
      "tensor(232.1965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 332.23040771484375  loc loss 6.667318820953369\n",
      "tensor(338.8977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 264.26336669921875  loc loss 5.815512657165527\n",
      "tensor(270.0789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 226.2802734375  loc loss 5.0887227058410645\n",
      "tensor(231.3690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 291.4265441894531  loc loss 7.819347381591797\n",
      "tensor(299.2459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 295.13690185546875  loc loss 8.572685241699219\n",
      "tensor(303.7096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 226.15927124023438  loc loss 6.103741645812988\n",
      "tensor(232.2630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 257.63836669921875  loc loss 4.923111438751221\n",
      "tensor(262.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 278.4736328125  loc loss 5.875802516937256\n",
      "tensor(284.3494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 236.4990234375  loc loss 6.710069179534912\n",
      "tensor(243.2091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 255.61810302734375  loc loss 4.0656843185424805\n",
      "tensor(259.6838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 225.85696411132812  loc loss 4.283249855041504\n",
      "tensor(230.1402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 219.14593505859375  loc loss 7.140487194061279\n",
      "tensor(226.2864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 245.9205780029297  loc loss 11.67036247253418\n",
      "tensor(257.5909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 221.26947021484375  loc loss 7.82185173034668\n",
      "tensor(229.0913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 251.06488037109375  loc loss 4.596872806549072\n",
      "tensor(255.6618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 256.2195739746094  loc loss 5.3662848472595215\n",
      "tensor(261.5858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 232.5198516845703  loc loss 6.08377742767334\n",
      "tensor(238.6036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 238.17724609375  loc loss 5.092045783996582\n",
      "tensor(243.2693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 234.4169921875  loc loss 4.289168834686279\n",
      "tensor(238.7062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 227.97157287597656  loc loss 7.637247085571289\n",
      "tensor(235.6088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 233.49008178710938  loc loss 5.5827436447143555\n",
      "tensor(239.0728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 220.2316131591797  loc loss 4.751599311828613\n",
      "tensor(224.9832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 216.41900634765625  loc loss 6.514000415802002\n",
      "tensor(222.9330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 307.42529296875  loc loss 8.075220108032227\n",
      "tensor(315.5005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 206.90081787109375  loc loss 4.9009904861450195\n",
      "tensor(211.8018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 233.77615356445312  loc loss 5.863875865936279\n",
      "tensor(239.6400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 218.03106689453125  loc loss 5.599704265594482\n",
      "tensor(223.6308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 217.5615997314453  loc loss 9.478326797485352\n",
      "tensor(227.0399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 292.0037536621094  loc loss 6.167435169219971\n",
      "tensor(298.1712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 216.8769073486328  loc loss 5.749723434448242\n",
      "tensor(222.6266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 217.59352111816406  loc loss 5.101159572601318\n",
      "tensor(222.6947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 216.6243438720703  loc loss 4.897605895996094\n",
      "tensor(221.5219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 223.62844848632812  loc loss 6.101966857910156\n",
      "tensor(229.7304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 225.2606964111328  loc loss 5.859795570373535\n",
      "tensor(231.1205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 226.94683837890625  loc loss 6.985782623291016\n",
      "tensor(233.9326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 210.80490112304688  loc loss 7.6949052810668945\n",
      "tensor(218.4998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 240.16212463378906  loc loss 6.236854076385498\n",
      "tensor(246.3990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 253.1503143310547  loc loss 5.567217826843262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(258.7175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 205.28070068359375  loc loss 6.801978588104248\n",
      "tensor(212.0827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 236.23004150390625  loc loss 5.455997467041016\n",
      "tensor(241.6860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 184.78012084960938  loc loss 5.47457218170166\n",
      "tensor(190.2547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 230.50820922851562  loc loss 4.744688510894775\n",
      "tensor(235.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 239.99537658691406  loc loss 6.8641180992126465\n",
      "tensor(246.8595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 193.25192260742188  loc loss 4.572373390197754\n",
      "tensor(197.8243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 203.0159149169922  loc loss 4.778600215911865\n",
      "tensor(207.7945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 217.03732299804688  loc loss 7.506738185882568\n",
      "tensor(224.5441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 235.24588012695312  loc loss 4.245026111602783\n",
      "tensor(239.4909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 243.35284423828125  loc loss 3.905702829360962\n",
      "tensor(247.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 194.27349853515625  loc loss 3.9432313442230225\n",
      "tensor(198.2167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 206.83250427246094  loc loss 6.57634162902832\n",
      "tensor(213.4088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 239.025390625  loc loss 6.743068695068359\n",
      "tensor(245.7685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 224.80813598632812  loc loss 6.588603496551514\n",
      "tensor(231.3967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 215.5626220703125  loc loss 5.693303108215332\n",
      "tensor(221.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 173.2412567138672  loc loss 5.1651458740234375\n",
      "tensor(178.4064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 183.96804809570312  loc loss 3.533245086669922\n",
      "tensor(187.5013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 174.9559326171875  loc loss 5.99810791015625\n",
      "tensor(180.9540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 214.51234436035156  loc loss 5.410541534423828\n",
      "tensor(219.9229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 200.26019287109375  loc loss 6.725700378417969\n",
      "tensor(206.9859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 180.03903198242188  loc loss 6.589330196380615\n",
      "tensor(186.6284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 182.4921417236328  loc loss 2.602607250213623\n",
      "tensor(185.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 195.51278686523438  loc loss 4.662590503692627\n",
      "tensor(200.1754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 196.37088012695312  loc loss 7.730219841003418\n",
      "tensor(204.1011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 222.25657653808594  loc loss 7.387070655822754\n",
      "tensor(229.6436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 188.15158081054688  loc loss 6.398629665374756\n",
      "tensor(194.5502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 183.40121459960938  loc loss 7.749333381652832\n",
      "tensor(191.1505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 218.99636840820312  loc loss 6.217997074127197\n",
      "tensor(225.2144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 193.30947875976562  loc loss 6.223555564880371\n",
      "tensor(199.5330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 215.41314697265625  loc loss 7.937741756439209\n",
      "tensor(223.3509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 179.00515747070312  loc loss 3.204458713531494\n",
      "tensor(182.2096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 422.2532043457031  loc loss 11.33621597290039\n",
      "tensor(433.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 228.32630920410156  loc loss 3.7542428970336914\n",
      "tensor(232.0806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 211.57472229003906  loc loss 5.259911060333252\n",
      "tensor(216.8346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 183.95611572265625  loc loss 5.650094032287598\n",
      "tensor(189.6062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 218.4730682373047  loc loss 8.560098648071289\n",
      "tensor(227.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 182.2923126220703  loc loss 7.379561424255371\n",
      "tensor(189.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 199.47653198242188  loc loss 5.491265296936035\n",
      "tensor(204.9678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 205.9868621826172  loc loss 7.257369518280029\n",
      "tensor(213.2442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 165.2572784423828  loc loss 4.9625563621521\n",
      "tensor(170.2198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 200.5819549560547  loc loss 5.298486232757568\n",
      "tensor(205.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 179.45294189453125  loc loss 7.196346759796143\n",
      "tensor(186.6493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 229.79702758789062  loc loss 5.896480560302734\n",
      "tensor(235.6935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 233.57437133789062  loc loss 8.01831340789795\n",
      "tensor(241.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 168.12269592285156  loc loss 4.304046630859375\n",
      "tensor(172.4267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 200.58401489257812  loc loss 6.313994884490967\n",
      "tensor(206.8980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 209.70330810546875  loc loss 5.709033966064453\n",
      "tensor(215.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 169.1063232421875  loc loss 6.399399757385254\n",
      "tensor(175.5057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 251.27699279785156  loc loss 3.9191505908966064\n",
      "tensor(255.1961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 160.16995239257812  loc loss 5.3567633628845215\n",
      "tensor(165.5267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 195.9623565673828  loc loss 4.806557655334473\n",
      "tensor(200.7689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 159.19155883789062  loc loss 5.697267055511475\n",
      "tensor(164.8888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 183.19952392578125  loc loss 4.126376628875732\n",
      "tensor(187.3259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 191.89947509765625  loc loss 4.751429557800293\n",
      "tensor(196.6509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 169.14361572265625  loc loss 5.2971720695495605\n",
      "tensor(174.4408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 158.38369750976562  loc loss 3.8727798461914062\n",
      "tensor(162.2565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 175.2626190185547  loc loss 6.119356632232666\n",
      "tensor(181.3820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 203.7194061279297  loc loss 4.856245040893555\n",
      "tensor(208.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 187.92974853515625  loc loss 6.985488414764404\n",
      "tensor(194.9152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 222.0102081298828  loc loss 6.114643573760986\n",
      "tensor(228.1248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 203.1772003173828  loc loss 9.178474426269531\n",
      "tensor(212.3557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 203.67373657226562  loc loss 7.869675636291504\n",
      "tensor(211.5434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 183.8951416015625  loc loss 4.707430839538574\n",
      "tensor(188.6026, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12096])\n",
      "cls loss 231.92701721191406  loc loss 7.717380523681641\n",
      "tensor(239.6444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 187.31385803222656  loc loss 2.616347312927246\n",
      "tensor(189.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 170.10499572753906  loc loss 8.88068675994873\n",
      "tensor(178.9857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 175.59625244140625  loc loss 3.6189897060394287\n",
      "tensor(179.2152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 193.76837158203125  loc loss 6.86328125\n",
      "tensor(200.6317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 178.15538024902344  loc loss 5.502488136291504\n",
      "tensor(183.6579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 197.88681030273438  loc loss 5.491021633148193\n",
      "tensor(203.3778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 191.86788940429688  loc loss 6.15083122253418\n",
      "tensor(198.0187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 166.70144653320312  loc loss 8.490184783935547\n",
      "tensor(175.1916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 199.31011962890625  loc loss 8.934731483459473\n",
      "tensor(208.2449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 151.45745849609375  loc loss 6.2073259353637695\n",
      "tensor(157.6648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 178.79502868652344  loc loss 7.652075290679932\n",
      "tensor(186.4471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 186.164306640625  loc loss 5.056857585906982\n",
      "tensor(191.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 171.6805419921875  loc loss 4.719346523284912\n",
      "tensor(176.3999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 167.43258666992188  loc loss 10.358981132507324\n",
      "tensor(177.7916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 158.42819213867188  loc loss 5.434312343597412\n",
      "tensor(163.8625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 203.35220336914062  loc loss 5.263153553009033\n",
      "tensor(208.6154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 168.1515655517578  loc loss 4.717605113983154\n",
      "tensor(172.8692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 218.61256408691406  loc loss 5.604955673217773\n",
      "tensor(224.2175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 190.2777862548828  loc loss 5.390472412109375\n",
      "tensor(195.6683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 165.24298095703125  loc loss 6.112460613250732\n",
      "tensor(171.3554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 161.32327270507812  loc loss 3.0182576179504395\n",
      "tensor(164.3415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 181.8321990966797  loc loss 3.8437345027923584\n",
      "tensor(185.6759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 155.29794311523438  loc loss 5.777359485626221\n",
      "tensor(161.0753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 149.49246215820312  loc loss 5.4019670486450195\n",
      "tensor(154.8944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 156.07293701171875  loc loss 5.160704612731934\n",
      "tensor(161.2336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 267.104736328125  loc loss 6.281024932861328\n",
      "tensor(273.3858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 167.6705322265625  loc loss 3.878105640411377\n",
      "tensor(171.5486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 144.82028198242188  loc loss 4.784117221832275\n",
      "tensor(149.6044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 171.0174102783203  loc loss 4.951042652130127\n",
      "tensor(175.9685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 150.56829833984375  loc loss 4.676766395568848\n",
      "tensor(155.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 179.41879272460938  loc loss 5.723695755004883\n",
      "tensor(185.1425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 183.25262451171875  loc loss 4.951030731201172\n",
      "tensor(188.2037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 151.83302307128906  loc loss 7.151525974273682\n",
      "tensor(158.9845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 165.96775817871094  loc loss 6.0424933433532715\n",
      "tensor(172.0103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 145.823486328125  loc loss 6.49046516418457\n",
      "tensor(152.3139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 214.1167449951172  loc loss 7.308408737182617\n",
      "tensor(221.4252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 162.98513793945312  loc loss 5.157073020935059\n",
      "tensor(168.1422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 196.59384155273438  loc loss 8.562614440917969\n",
      "tensor(205.1565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 204.17755126953125  loc loss 7.876747131347656\n",
      "tensor(212.0543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 162.32357788085938  loc loss 3.6329305171966553\n",
      "tensor(165.9565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 222.07322692871094  loc loss 5.902604579925537\n",
      "tensor(227.9758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 166.97610473632812  loc loss 6.40524959564209\n",
      "tensor(173.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 144.35231018066406  loc loss 5.044997692108154\n",
      "tensor(149.3973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 148.80303955078125  loc loss 5.206136703491211\n",
      "tensor(154.0092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 181.92962646484375  loc loss 4.808941841125488\n",
      "tensor(186.7386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 177.66891479492188  loc loss 8.309224128723145\n",
      "tensor(185.9781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 210.56101989746094  loc loss 5.9399285316467285\n",
      "tensor(216.5009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 157.7766571044922  loc loss 3.0549123287200928\n",
      "tensor(160.8316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 180.17620849609375  loc loss 4.223977565765381\n",
      "tensor(184.4002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 192.41717529296875  loc loss 4.388128757476807\n",
      "tensor(196.8053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 140.05465698242188  loc loss 4.23935604095459\n",
      "tensor(144.2940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 193.7879638671875  loc loss 7.235928058624268\n",
      "tensor(201.0239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 168.25189208984375  loc loss 3.9789414405822754\n",
      "tensor(172.2308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 171.0375213623047  loc loss 5.939217567443848\n",
      "tensor(176.9767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 144.86941528320312  loc loss 6.293292045593262\n",
      "tensor(151.1627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 150.79937744140625  loc loss 5.098196029663086\n",
      "tensor(155.8976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 133.60064697265625  loc loss 3.2062947750091553\n",
      "tensor(136.8069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 131.43075561523438  loc loss 3.5529236793518066\n",
      "tensor(134.9837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 139.77064514160156  loc loss 4.623579502105713\n",
      "tensor(144.3942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 187.64930725097656  loc loss 4.826178073883057\n",
      "tensor(192.4755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 231.07345581054688  loc loss 5.821016788482666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(236.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 157.7209930419922  loc loss 4.718783378601074\n",
      "tensor(162.4398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 148.4544677734375  loc loss 4.5763468742370605\n",
      "tensor(153.0308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 190.07876586914062  loc loss 4.517838478088379\n",
      "tensor(194.5966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 154.33526611328125  loc loss 4.177760124206543\n",
      "tensor(158.5130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 131.61947631835938  loc loss 4.6436662673950195\n",
      "tensor(136.2631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 155.23043823242188  loc loss 4.127845764160156\n",
      "tensor(159.3583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 140.42080688476562  loc loss 6.397702217102051\n",
      "tensor(146.8185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 152.27719116210938  loc loss 4.196048736572266\n",
      "tensor(156.4732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 136.09075927734375  loc loss 5.483612060546875\n",
      "tensor(141.5744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 160.89031982421875  loc loss 4.696157455444336\n",
      "tensor(165.5865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 143.38055419921875  loc loss 6.0276641845703125\n",
      "tensor(149.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 129.8314208984375  loc loss 5.655170440673828\n",
      "tensor(135.4866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 302.9538879394531  loc loss 11.135047912597656\n",
      "tensor(314.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 152.12332153320312  loc loss 5.2903971672058105\n",
      "tensor(157.4137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 161.46560668945312  loc loss 4.028515815734863\n",
      "tensor(165.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 123.30648040771484  loc loss 3.985769271850586\n",
      "tensor(127.2923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 180.23583984375  loc loss 4.048703193664551\n",
      "tensor(184.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 173.96902465820312  loc loss 4.98051643371582\n",
      "tensor(178.9495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 152.72315979003906  loc loss 5.188917636871338\n",
      "tensor(157.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 145.731201171875  loc loss 4.885473728179932\n",
      "tensor(150.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 146.2028350830078  loc loss 4.502451419830322\n",
      "tensor(150.7053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 242.72869873046875  loc loss 5.128593444824219\n",
      "tensor(247.8573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 143.97149658203125  loc loss 5.315390586853027\n",
      "tensor(149.2869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 169.146728515625  loc loss 7.982405185699463\n",
      "tensor(177.1291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 156.11817932128906  loc loss 4.816446781158447\n",
      "tensor(160.9346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 182.88772583007812  loc loss 8.225722312927246\n",
      "tensor(191.1134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 162.677001953125  loc loss 5.185582160949707\n",
      "tensor(167.8626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 140.42190551757812  loc loss 3.7806379795074463\n",
      "tensor(144.2025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 152.68560791015625  loc loss 4.767428398132324\n",
      "tensor(157.4530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 163.00762939453125  loc loss 6.791205406188965\n",
      "tensor(169.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 130.65557861328125  loc loss 4.469545364379883\n",
      "tensor(135.1251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 137.5098876953125  loc loss 3.848069429397583\n",
      "tensor(141.3580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 128.56829833984375  loc loss 6.667160987854004\n",
      "tensor(135.2355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 126.70332336425781  loc loss 3.977720260620117\n",
      "tensor(130.6810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 146.0133056640625  loc loss 3.1946487426757812\n",
      "tensor(149.2079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 178.83938598632812  loc loss 4.843513488769531\n",
      "tensor(183.6829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 124.2530517578125  loc loss 3.318429946899414\n",
      "tensor(127.5715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 154.97122192382812  loc loss 7.567912578582764\n",
      "tensor(162.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 135.68760681152344  loc loss 6.837397575378418\n",
      "tensor(142.5250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 131.14556884765625  loc loss 7.8033671379089355\n",
      "tensor(138.9489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 119.22632598876953  loc loss 3.7089643478393555\n",
      "tensor(122.9353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 159.55189514160156  loc loss 5.5113983154296875\n",
      "tensor(165.0633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 151.89938354492188  loc loss 6.2701311111450195\n",
      "tensor(158.1695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 138.2167510986328  loc loss 6.079787254333496\n",
      "tensor(144.2965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 152.22360229492188  loc loss 4.814971923828125\n",
      "tensor(157.0386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 145.20449829101562  loc loss 5.889596939086914\n",
      "tensor(151.0941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 121.08926391601562  loc loss 4.753891944885254\n",
      "tensor(125.8432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 135.05853271484375  loc loss 7.916131973266602\n",
      "tensor(142.9747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 136.67901611328125  loc loss 3.903075695037842\n",
      "tensor(140.5821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 138.09458923339844  loc loss 4.824631690979004\n",
      "tensor(142.9192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 130.0759735107422  loc loss 4.57584285736084\n",
      "tensor(134.6518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 148.15708923339844  loc loss 4.709096431732178\n",
      "tensor(152.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 109.44390106201172  loc loss 3.5271713733673096\n",
      "tensor(112.9711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 119.16507720947266  loc loss 5.68964958190918\n",
      "tensor(124.8547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 124.33151245117188  loc loss 5.639957904815674\n",
      "tensor(129.9715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 133.70657348632812  loc loss 7.098288059234619\n",
      "tensor(140.8049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 148.00411987304688  loc loss 3.9912424087524414\n",
      "tensor(151.9954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 138.4674835205078  loc loss 5.0380754470825195\n",
      "tensor(143.5056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 131.0654754638672  loc loss 4.006661891937256\n",
      "tensor(135.0721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 131.27597045898438  loc loss 4.286508083343506\n",
      "tensor(135.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 135.36647033691406  loc loss 5.033090114593506\n",
      "tensor(140.3996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 136.30377197265625  loc loss 6.459209442138672\n",
      "tensor(142.7630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 157.5568084716797  loc loss 7.324143409729004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(164.8810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 118.58671569824219  loc loss 4.096336364746094\n",
      "tensor(122.6831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 140.8395233154297  loc loss 5.956819534301758\n",
      "tensor(146.7963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 151.74111938476562  loc loss 3.31246018409729\n",
      "tensor(155.0536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 121.60789489746094  loc loss 7.182447910308838\n",
      "tensor(128.7903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 143.69564819335938  loc loss 5.950768947601318\n",
      "tensor(149.6464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 117.6705551147461  loc loss 5.582603454589844\n",
      "tensor(123.2532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.83900451660156  loc loss 6.135856628417969\n",
      "tensor(114.9749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 130.1708984375  loc loss 6.294121742248535\n",
      "tensor(136.4650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.43988037109375  loc loss 3.941164970397949\n",
      "tensor(112.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 143.45973205566406  loc loss 4.846334934234619\n",
      "tensor(148.3061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 123.60946655273438  loc loss 5.083743095397949\n",
      "tensor(128.6932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 105.34028625488281  loc loss 5.0334978103637695\n",
      "tensor(110.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 116.89747619628906  loc loss 4.73158597946167\n",
      "tensor(121.6291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 121.47175598144531  loc loss 6.655073642730713\n",
      "tensor(128.1268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 141.75656127929688  loc loss 5.120118141174316\n",
      "tensor(146.8767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 147.47470092773438  loc loss 4.37204647064209\n",
      "tensor(151.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 106.88877868652344  loc loss 6.0211381912231445\n",
      "tensor(112.9099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 133.55508422851562  loc loss 4.735930919647217\n",
      "tensor(138.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 115.13337707519531  loc loss 4.659002304077148\n",
      "tensor(119.7924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.39785766601562  loc loss 5.889142036437988\n",
      "tensor(114.2870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 106.87904357910156  loc loss 6.107645034790039\n",
      "tensor(112.9867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 194.11514282226562  loc loss 4.1856536865234375\n",
      "tensor(198.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 172.8415985107422  loc loss 4.2919816970825195\n",
      "tensor(177.1336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 164.7836456298828  loc loss 6.308644771575928\n",
      "tensor(171.0923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 119.93263244628906  loc loss 5.406186580657959\n",
      "tensor(125.3388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 113.28661346435547  loc loss 8.072786331176758\n",
      "tensor(121.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 109.69596099853516  loc loss 4.440974712371826\n",
      "tensor(114.1369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 196.53375244140625  loc loss 5.747898578643799\n",
      "tensor(202.2816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.91039276123047  loc loss 4.987308502197266\n",
      "tensor(113.8977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 110.99115753173828  loc loss 4.529909133911133\n",
      "tensor(115.5211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 128.50247192382812  loc loss 4.685250282287598\n",
      "tensor(133.1877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 121.328857421875  loc loss 4.880517482757568\n",
      "tensor(126.2094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 111.77284240722656  loc loss 3.8088619709014893\n",
      "tensor(115.5817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 148.63375854492188  loc loss 6.851225852966309\n",
      "tensor(155.4850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 113.04165649414062  loc loss 5.577593803405762\n",
      "tensor(118.6192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 121.0301513671875  loc loss 3.8675472736358643\n",
      "tensor(124.8977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 132.3829803466797  loc loss 6.2927374839782715\n",
      "tensor(138.6757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 105.499267578125  loc loss 4.536262512207031\n",
      "tensor(110.0355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 189.04620361328125  loc loss 9.380952835083008\n",
      "tensor(198.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 144.7046661376953  loc loss 4.365370273590088\n",
      "tensor(149.0700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 110.47236633300781  loc loss 4.705624103546143\n",
      "tensor(115.1780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.4979019165039  loc loss 4.8913774490356445\n",
      "tensor(113.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 102.9817123413086  loc loss 3.9592092037200928\n",
      "tensor(106.9409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 111.72941589355469  loc loss 5.695197582244873\n",
      "tensor(117.4246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 171.42959594726562  loc loss 6.525938034057617\n",
      "tensor(177.9555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 123.34307861328125  loc loss 4.916518211364746\n",
      "tensor(128.2596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 124.06568908691406  loc loss 6.870564937591553\n",
      "tensor(130.9362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 128.0999755859375  loc loss 4.669175624847412\n",
      "tensor(132.7691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 147.72381591796875  loc loss 4.900781154632568\n",
      "tensor(152.6246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 102.42550659179688  loc loss 6.666775226593018\n",
      "tensor(109.0923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 119.18807220458984  loc loss 3.745974540710449\n",
      "tensor(122.9340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 104.9261245727539  loc loss 5.524979591369629\n",
      "tensor(110.4511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.78599548339844  loc loss 4.874785900115967\n",
      "tensor(113.6608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 143.25860595703125  loc loss 5.429095268249512\n",
      "tensor(148.6877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 128.4843292236328  loc loss 5.5538177490234375\n",
      "tensor(134.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 124.09922790527344  loc loss 5.475837707519531\n",
      "tensor(129.5751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 100.10113525390625  loc loss 4.705236434936523\n",
      "tensor(104.8064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 99.23007202148438  loc loss 5.697781562805176\n",
      "tensor(104.9279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 293.7601623535156  loc loss 8.461371421813965\n",
      "tensor(302.2215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 116.591064453125  loc loss 5.018249034881592\n",
      "tensor(121.6093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 114.4100341796875  loc loss 4.8909454345703125\n",
      "tensor(119.3010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 94.55907440185547  loc loss 5.498040199279785\n",
      "tensor(100.0571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 128.76580810546875  loc loss 7.209307670593262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(135.9751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 155.46728515625  loc loss 6.565298080444336\n",
      "tensor(162.0326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 141.41986083984375  loc loss 5.314916610717773\n",
      "tensor(146.7348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 132.7715606689453  loc loss 3.3180508613586426\n",
      "tensor(136.0896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 106.00665283203125  loc loss 5.592774391174316\n",
      "tensor(111.5994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 107.1451187133789  loc loss 5.5063796043396\n",
      "tensor(112.6515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 91.51304626464844  loc loss 7.643474578857422\n",
      "tensor(99.1565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 98.87196350097656  loc loss 3.7576303482055664\n",
      "tensor(102.6296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 100.03448486328125  loc loss 3.724177122116089\n",
      "tensor(103.7587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 102.0662612915039  loc loss 5.376596450805664\n",
      "tensor(107.4429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 111.60929870605469  loc loss 5.321178436279297\n",
      "tensor(116.9305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 184.76882934570312  loc loss 4.736166000366211\n",
      "tensor(189.5050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 124.25698852539062  loc loss 5.235949516296387\n",
      "tensor(129.4929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 94.98377227783203  loc loss 4.9159345626831055\n",
      "tensor(99.8997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 113.3111801147461  loc loss 10.415051460266113\n",
      "tensor(123.7262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 113.7177734375  loc loss 6.7266340255737305\n",
      "tensor(120.4444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 109.07500457763672  loc loss 3.2724249362945557\n",
      "tensor(112.3474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 94.435546875  loc loss 4.1857590675354\n",
      "tensor(98.6213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 115.40092468261719  loc loss 3.9617934226989746\n",
      "tensor(119.3627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 118.2782974243164  loc loss 3.661986827850342\n",
      "tensor(121.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 156.6790008544922  loc loss 8.797964096069336\n",
      "tensor(165.4770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 120.42808532714844  loc loss 5.576697826385498\n",
      "tensor(126.0048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 106.98287963867188  loc loss 6.755821228027344\n",
      "tensor(113.7387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 107.36774444580078  loc loss 4.664826393127441\n",
      "tensor(112.0326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 97.0099868774414  loc loss 4.254508972167969\n",
      "tensor(101.2645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 122.12033081054688  loc loss 5.5970306396484375\n",
      "tensor(127.7174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 133.8323974609375  loc loss 5.115051746368408\n",
      "tensor(138.9474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.89833068847656  loc loss 4.0680365562438965\n",
      "tensor(99.9664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 157.0390625  loc loss 7.278515815734863\n",
      "tensor(164.3176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 123.99868774414062  loc loss 4.28196907043457\n",
      "tensor(128.2807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 120.06656646728516  loc loss 6.085013389587402\n",
      "tensor(126.1516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 99.51725006103516  loc loss 4.796055793762207\n",
      "tensor(104.3133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 121.19017028808594  loc loss 3.6292409896850586\n",
      "tensor(124.8194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 96.04463958740234  loc loss 4.342320919036865\n",
      "tensor(100.3870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 155.91162109375  loc loss 6.951099395751953\n",
      "tensor(162.8627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.93572235107422  loc loss 7.620495796203613\n",
      "tensor(103.5562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 111.7262191772461  loc loss 3.6589770317077637\n",
      "tensor(115.3852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 97.2353286743164  loc loss 5.575384616851807\n",
      "tensor(102.8107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 86.14656066894531  loc loss 4.206949234008789\n",
      "tensor(90.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 123.86775970458984  loc loss 3.750908851623535\n",
      "tensor(127.6187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.7873764038086  loc loss 4.760713577270508\n",
      "tensor(100.5481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 115.23332214355469  loc loss 4.321324348449707\n",
      "tensor(119.5546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 129.47531127929688  loc loss 6.161421298980713\n",
      "tensor(135.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 102.4455795288086  loc loss 5.629127025604248\n",
      "tensor(108.0747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 152.29595947265625  loc loss 4.424189567565918\n",
      "tensor(156.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 113.14859008789062  loc loss 5.280843257904053\n",
      "tensor(118.4294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 93.59255981445312  loc loss 4.017003536224365\n",
      "tensor(97.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.93641662597656  loc loss 4.824769020080566\n",
      "tensor(100.7612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 118.48644256591797  loc loss 4.942900657653809\n",
      "tensor(123.4293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 87.45515441894531  loc loss 4.040261745452881\n",
      "tensor(91.4954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 99.39563751220703  loc loss 5.538028717041016\n",
      "tensor(104.9337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 111.31302642822266  loc loss 5.907177448272705\n",
      "tensor(117.2202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 90.42340087890625  loc loss 7.244152069091797\n",
      "tensor(97.6676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 113.22509765625  loc loss 6.400548934936523\n",
      "tensor(119.6256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 100.59049987792969  loc loss 3.239591121673584\n",
      "tensor(103.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.73341369628906  loc loss 5.6137542724609375\n",
      "tensor(101.3472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 91.21360778808594  loc loss 4.06090784072876\n",
      "tensor(95.2745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 101.4683837890625  loc loss 3.7527847290039062\n",
      "tensor(105.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 106.09088134765625  loc loss 6.482509136199951\n",
      "tensor(112.5734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 104.8220443725586  loc loss 5.51627779006958\n",
      "tensor(110.3383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 86.99452209472656  loc loss 3.316837787628174\n",
      "tensor(90.3114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 102.27020263671875  loc loss 5.274364948272705\n",
      "tensor(107.5446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 113.57106018066406  loc loss 7.942592620849609\n",
      "tensor(121.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 113.13663482666016  loc loss 6.3080058097839355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(119.4446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 90.44198608398438  loc loss 4.320512771606445\n",
      "tensor(94.7625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 111.71403503417969  loc loss 4.941837787628174\n",
      "tensor(116.6559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 106.74333190917969  loc loss 7.3629021644592285\n",
      "tensor(114.1062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 94.23078918457031  loc loss 3.777273178100586\n",
      "tensor(98.0081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 101.27265930175781  loc loss 8.821348190307617\n",
      "tensor(110.0940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 92.25596618652344  loc loss 5.282378196716309\n",
      "tensor(97.5383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.35166931152344  loc loss 3.6956255435943604\n",
      "tensor(99.0473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.23532104492188  loc loss 4.318776607513428\n",
      "tensor(85.5541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 85.111083984375  loc loss 5.37470817565918\n",
      "tensor(90.4858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 103.75104522705078  loc loss 6.1275763511657715\n",
      "tensor(109.8786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 110.17021942138672  loc loss 5.363161563873291\n",
      "tensor(115.5334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 106.7646713256836  loc loss 6.772730350494385\n",
      "tensor(113.5374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 102.91690063476562  loc loss 5.769068241119385\n",
      "tensor(108.6860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 85.07347869873047  loc loss 3.7557761669158936\n",
      "tensor(88.8293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 87.07075500488281  loc loss 5.7898125648498535\n",
      "tensor(92.8606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 99.84490966796875  loc loss 6.712029933929443\n",
      "tensor(106.5569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 89.29033660888672  loc loss 6.1125593185424805\n",
      "tensor(95.4029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 106.32804870605469  loc loss 4.603719234466553\n",
      "tensor(110.9318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 89.66314697265625  loc loss 3.458183765411377\n",
      "tensor(93.1213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 78.7900390625  loc loss 5.949967384338379\n",
      "tensor(84.7400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 86.16702270507812  loc loss 4.77902889251709\n",
      "tensor(90.9461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.97579956054688  loc loss 6.073949337005615\n",
      "tensor(115.0498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 128.09506225585938  loc loss 3.8264527320861816\n",
      "tensor(131.9215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 96.71881103515625  loc loss 5.15162467956543\n",
      "tensor(101.8704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 84.77365112304688  loc loss 3.9976444244384766\n",
      "tensor(88.7713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 82.60942840576172  loc loss 4.544126987457275\n",
      "tensor(87.1536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 84.79486083984375  loc loss 3.7482659816741943\n",
      "tensor(88.5431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 109.49725341796875  loc loss 3.454019546508789\n",
      "tensor(112.9513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.5542221069336  loc loss 4.836097717285156\n",
      "tensor(86.3903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 83.10385131835938  loc loss 4.471402168273926\n",
      "tensor(87.5753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 117.9750747680664  loc loss 6.587724685668945\n",
      "tensor(124.5628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 94.24259948730469  loc loss 4.43662691116333\n",
      "tensor(98.6792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 93.6768798828125  loc loss 6.539761066436768\n",
      "tensor(100.2166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 115.28778076171875  loc loss 5.570703983306885\n",
      "tensor(120.8585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 85.706298828125  loc loss 3.7366952896118164\n",
      "tensor(89.4430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 101.07327270507812  loc loss 3.0338544845581055\n",
      "tensor(104.1071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 97.15745544433594  loc loss 4.100542068481445\n",
      "tensor(101.2580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.83515167236328  loc loss 7.336746692657471\n",
      "tensor(103.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 74.21481323242188  loc loss 3.2797012329101562\n",
      "tensor(77.4945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 96.16322326660156  loc loss 6.244757652282715\n",
      "tensor(102.4080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 93.24436950683594  loc loss 5.236522674560547\n",
      "tensor(98.4809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 92.47032928466797  loc loss 3.470216751098633\n",
      "tensor(95.9405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 88.65191650390625  loc loss 2.9645392894744873\n",
      "tensor(91.6165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 80.02226257324219  loc loss 3.3814542293548584\n",
      "tensor(83.4037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 187.2135009765625  loc loss 7.4730024337768555\n",
      "tensor(194.6865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 96.77029418945312  loc loss 4.867474555969238\n",
      "tensor(101.6378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 87.21798706054688  loc loss 3.028890609741211\n",
      "tensor(90.2469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 93.9994125366211  loc loss 3.2879080772399902\n",
      "tensor(97.2873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 91.2268295288086  loc loss 4.243941783905029\n",
      "tensor(95.4708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.99200439453125  loc loss 5.14449405670166\n",
      "tensor(101.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 106.89974975585938  loc loss 4.256654262542725\n",
      "tensor(111.1564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 89.37014770507812  loc loss 4.502681732177734\n",
      "tensor(93.8728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 99.13070678710938  loc loss 5.606350421905518\n",
      "tensor(104.7371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 84.20709991455078  loc loss 6.264237403869629\n",
      "tensor(90.4713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 91.20736694335938  loc loss 4.938340187072754\n",
      "tensor(96.1457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.33336639404297  loc loss 6.096856117248535\n",
      "tensor(114.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 77.33901977539062  loc loss 3.9747157096862793\n",
      "tensor(81.3137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 91.55928039550781  loc loss 2.810750722885132\n",
      "tensor(94.3700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 89.39518737792969  loc loss 3.6512413024902344\n",
      "tensor(93.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 107.4273681640625  loc loss 6.2637739181518555\n",
      "tensor(113.6911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 90.87083435058594  loc loss 3.7115182876586914\n",
      "tensor(94.5824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 87.14805603027344  loc loss 5.183619022369385\n",
      "tensor(92.3317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 85.26954650878906  loc loss 3.10607647895813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(88.3756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 89.61546325683594  loc loss 3.3758010864257812\n",
      "tensor(92.9913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.57488250732422  loc loss 4.541606903076172\n",
      "tensor(86.1165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 132.06153869628906  loc loss 5.416371822357178\n",
      "tensor(137.4779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 101.63670349121094  loc loss 3.6301217079162598\n",
      "tensor(105.2668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 80.83634948730469  loc loss 4.364205360412598\n",
      "tensor(85.2006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 87.56717681884766  loc loss 4.314673900604248\n",
      "tensor(91.8819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 110.92359924316406  loc loss 6.478265762329102\n",
      "tensor(117.4019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.47395324707031  loc loss 4.760473251342773\n",
      "tensor(81.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 103.18009948730469  loc loss 5.809998035430908\n",
      "tensor(108.9901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.23098754882812  loc loss 4.1327433586120605\n",
      "tensor(80.3637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 193.9993438720703  loc loss 5.491720199584961\n",
      "tensor(199.4911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 96.998779296875  loc loss 6.247262954711914\n",
      "tensor(103.2460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.3741455078125  loc loss 4.699070930480957\n",
      "tensor(77.0732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 82.12672424316406  loc loss 5.216318130493164\n",
      "tensor(87.3430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 101.22753143310547  loc loss 3.2675931453704834\n",
      "tensor(104.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 112.40415954589844  loc loss 4.26350212097168\n",
      "tensor(116.6677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 83.64390563964844  loc loss 4.180018424987793\n",
      "tensor(87.8239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 80.14603424072266  loc loss 2.069999933242798\n",
      "tensor(82.2160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 89.78074645996094  loc loss 4.9441633224487305\n",
      "tensor(94.7249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 90.32264709472656  loc loss 5.953233242034912\n",
      "tensor(96.2759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 104.06898498535156  loc loss 2.7893459796905518\n",
      "tensor(106.8583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 84.61613464355469  loc loss 3.6941113471984863\n",
      "tensor(88.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 120.14470672607422  loc loss 9.24424934387207\n",
      "tensor(129.3890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 80.13373565673828  loc loss 5.355309963226318\n",
      "tensor(85.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.61669158935547  loc loss 4.435701847076416\n",
      "tensor(74.0524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 107.86863708496094  loc loss 4.647277355194092\n",
      "tensor(112.5159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.9433822631836  loc loss 4.395132541656494\n",
      "tensor(113.3385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.87236022949219  loc loss 5.358701705932617\n",
      "tensor(87.2311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 88.17548370361328  loc loss 5.103311061859131\n",
      "tensor(93.2788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 80.15240478515625  loc loss 3.903122663497925\n",
      "tensor(84.0555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 100.52827453613281  loc loss 3.9341859817504883\n",
      "tensor(104.4625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 89.84410858154297  loc loss 6.069844722747803\n",
      "tensor(95.9140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 91.17565155029297  loc loss 4.542581081390381\n",
      "tensor(95.7182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 77.62664794921875  loc loss 4.578486442565918\n",
      "tensor(82.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 82.15489196777344  loc loss 2.771533727645874\n",
      "tensor(84.9264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.7789306640625  loc loss 5.059640407562256\n",
      "tensor(86.8386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.44876098632812  loc loss 4.130958080291748\n",
      "tensor(73.5797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 101.06660461425781  loc loss 3.9000349044799805\n",
      "tensor(104.9666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 86.27859497070312  loc loss 4.61098051071167\n",
      "tensor(90.8896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 104.61698913574219  loc loss 7.115572929382324\n",
      "tensor(111.7326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 280.82440185546875  loc loss 9.043514251708984\n",
      "tensor(289.8679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 86.17262268066406  loc loss 3.4346253871917725\n",
      "tensor(89.6072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 105.92919921875  loc loss 3.9884235858917236\n",
      "tensor(109.9176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 73.85269165039062  loc loss 5.524819850921631\n",
      "tensor(79.3775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 77.57911682128906  loc loss 4.297825336456299\n",
      "tensor(81.8769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.58780670166016  loc loss 4.867434501647949\n",
      "tensor(86.4552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 98.38150024414062  loc loss 4.299731254577637\n",
      "tensor(102.6812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 79.5367431640625  loc loss 4.432142734527588\n",
      "tensor(83.9689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 74.04216766357422  loc loss 3.9778406620025635\n",
      "tensor(78.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 83.66634368896484  loc loss 3.7058236598968506\n",
      "tensor(87.3722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 114.37933349609375  loc loss 3.4153666496276855\n",
      "tensor(117.7947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 87.09784698486328  loc loss 5.651437759399414\n",
      "tensor(92.7493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 137.1142578125  loc loss 6.330646991729736\n",
      "tensor(143.4449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 77.736572265625  loc loss 3.185349941253662\n",
      "tensor(80.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 73.15982055664062  loc loss 3.473395586013794\n",
      "tensor(76.6332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 79.79893493652344  loc loss 4.712267875671387\n",
      "tensor(84.5112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 83.007568359375  loc loss 6.354964733123779\n",
      "tensor(89.3625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.59751892089844  loc loss 4.882486343383789\n",
      "tensor(81.4800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 74.51795959472656  loc loss 6.027799129486084\n",
      "tensor(80.5458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 74.42314147949219  loc loss 4.357640743255615\n",
      "tensor(78.7808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 71.24995422363281  loc loss 3.0378589630126953\n",
      "tensor(74.2878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.84358215332031  loc loss 3.517415761947632\n",
      "tensor(80.3610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 73.30493927001953  loc loss 3.438180923461914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(76.7431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 78.50405883789062  loc loss 3.5213279724121094\n",
      "tensor(82.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 73.57288360595703  loc loss 3.2746267318725586\n",
      "tensor(76.8475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 80.47843933105469  loc loss 3.8500359058380127\n",
      "tensor(84.3285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.82644653320312  loc loss 6.580259799957275\n",
      "tensor(102.4067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.77591705322266  loc loss 4.015711307525635\n",
      "tensor(76.7916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 70.845947265625  loc loss 4.262945652008057\n",
      "tensor(75.1089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 87.85208129882812  loc loss 4.742483139038086\n",
      "tensor(92.5946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 92.05121612548828  loc loss 4.094731330871582\n",
      "tensor(96.1460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 108.04563903808594  loc loss 5.889023303985596\n",
      "tensor(113.9347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 84.59974670410156  loc loss 2.9618964195251465\n",
      "tensor(87.5616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 110.97349548339844  loc loss 7.189484596252441\n",
      "tensor(118.1630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 126.40689086914062  loc loss 4.722349166870117\n",
      "tensor(131.1292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 74.10701751708984  loc loss 4.9039387702941895\n",
      "tensor(79.0110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 75.26417541503906  loc loss 5.300469398498535\n",
      "tensor(80.5646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.30792236328125  loc loss 4.065143585205078\n",
      "tensor(70.3731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 71.39314270019531  loc loss 4.282020568847656\n",
      "tensor(75.6752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 101.33430480957031  loc loss 6.754646301269531\n",
      "tensor(108.0890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 114.8277587890625  loc loss 3.7547388076782227\n",
      "tensor(118.5825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 82.43367767333984  loc loss 3.6765706539154053\n",
      "tensor(86.1102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 82.57426452636719  loc loss 3.128173351287842\n",
      "tensor(85.7024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.19119262695312  loc loss 4.931315898895264\n",
      "tensor(71.1225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 90.98519134521484  loc loss 3.4066765308380127\n",
      "tensor(94.3919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 71.1322021484375  loc loss 3.465059995651245\n",
      "tensor(74.5973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.56757354736328  loc loss 4.903796195983887\n",
      "tensor(73.4714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 84.05220031738281  loc loss 8.453627586364746\n",
      "tensor(92.5058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 80.59542846679688  loc loss 5.506437301635742\n",
      "tensor(86.1019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.62105560302734  loc loss 3.7976572513580322\n",
      "tensor(72.4187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.32256317138672  loc loss 5.21669340133667\n",
      "tensor(81.5393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 82.92543029785156  loc loss 6.550250053405762\n",
      "tensor(89.4757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.85160064697266  loc loss 4.028013706207275\n",
      "tensor(72.8796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 91.52671813964844  loc loss 4.661513805389404\n",
      "tensor(96.1882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 60.656089782714844  loc loss 4.706262588500977\n",
      "tensor(65.3624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 113.13513946533203  loc loss 6.602033615112305\n",
      "tensor(119.7372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.87135314941406  loc loss 3.827332019805908\n",
      "tensor(80.6987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.11747741699219  loc loss 5.961515426635742\n",
      "tensor(70.0790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 71.5780258178711  loc loss 4.560328483581543\n",
      "tensor(76.1384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 93.90310668945312  loc loss 3.2099967002868652\n",
      "tensor(97.1131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 101.49345397949219  loc loss 6.185858726501465\n",
      "tensor(107.6793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.72764587402344  loc loss 5.149044990539551\n",
      "tensor(77.8767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 75.30009460449219  loc loss 4.650144577026367\n",
      "tensor(79.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 98.41121673583984  loc loss 5.164434432983398\n",
      "tensor(103.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.95198059082031  loc loss 6.327814102172852\n",
      "tensor(88.2798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 114.89773559570312  loc loss 3.9498825073242188\n",
      "tensor(118.8476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 73.16783905029297  loc loss 3.7721686363220215\n",
      "tensor(76.9400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 118.4444808959961  loc loss 7.5192060470581055\n",
      "tensor(125.9637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 89.40192413330078  loc loss 6.2646870613098145\n",
      "tensor(95.6666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.95846557617188  loc loss 4.226263999938965\n",
      "tensor(73.1847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 86.74232482910156  loc loss 5.526547908782959\n",
      "tensor(92.2689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.6664810180664  loc loss 3.668962001800537\n",
      "tensor(70.3354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 77.4274673461914  loc loss 5.009572982788086\n",
      "tensor(82.4370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 73.96214294433594  loc loss 3.21809458732605\n",
      "tensor(77.1802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 94.5791244506836  loc loss 5.798129081726074\n",
      "tensor(100.3773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 67.148681640625  loc loss 3.857470989227295\n",
      "tensor(71.0061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 73.3941650390625  loc loss 3.975055694580078\n",
      "tensor(77.3692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.91401672363281  loc loss 3.8968985080718994\n",
      "tensor(85.8109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.42092895507812  loc loss 4.035404205322266\n",
      "tensor(72.4563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.65770721435547  loc loss 3.924229145050049\n",
      "tensor(73.5819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.61546325683594  loc loss 4.887398719787598\n",
      "tensor(81.5029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 110.98899841308594  loc loss 3.5930521488189697\n",
      "tensor(114.5821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.88516235351562  loc loss 2.8152103424072266\n",
      "tensor(72.7004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.58736419677734  loc loss 4.857160568237305\n",
      "tensor(73.4445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.00385284423828  loc loss 2.963162899017334\n",
      "tensor(83.9670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.2479248046875  loc loss 3.938898801803589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(76.1868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 71.99861145019531  loc loss 3.884775161743164\n",
      "tensor(75.8834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.65718078613281  loc loss 4.131545066833496\n",
      "tensor(73.7887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 85.18939208984375  loc loss 3.944995403289795\n",
      "tensor(89.1344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.611328125  loc loss 5.666829586029053\n",
      "tensor(72.2782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.29338073730469  loc loss 3.7635209560394287\n",
      "tensor(80.0569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.8743896484375  loc loss 4.297360420227051\n",
      "tensor(70.1718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 67.08055114746094  loc loss 5.52571964263916\n",
      "tensor(72.6063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.03338623046875  loc loss 2.9682719707489014\n",
      "tensor(79.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 92.00357055664062  loc loss 3.7289140224456787\n",
      "tensor(95.7325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.31494140625  loc loss 4.14036750793457\n",
      "tensor(76.4553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 63.35807418823242  loc loss 3.42578125\n",
      "tensor(66.7839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 67.95170593261719  loc loss 4.896080493927002\n",
      "tensor(72.8478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.89875793457031  loc loss 3.6073591709136963\n",
      "tensor(76.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 70.59310150146484  loc loss 4.251521110534668\n",
      "tensor(74.8446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.73991012573242  loc loss 3.2108359336853027\n",
      "tensor(58.9507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.62162780761719  loc loss 3.3088953495025635\n",
      "tensor(72.9305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.35079956054688  loc loss 4.786269187927246\n",
      "tensor(71.1371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.83638763427734  loc loss 7.484306812286377\n",
      "tensor(76.3207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.361572265625  loc loss 2.801177501678467\n",
      "tensor(72.1628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.47539520263672  loc loss 5.16102409362793\n",
      "tensor(64.6364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.13404846191406  loc loss 3.630680799484253\n",
      "tensor(69.7647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.9424819946289  loc loss 5.04160737991333\n",
      "tensor(70.9841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 60.201412200927734  loc loss 3.2152204513549805\n",
      "tensor(63.4166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.78007507324219  loc loss 2.7666542530059814\n",
      "tensor(67.5467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.96189880371094  loc loss 3.099466323852539\n",
      "tensor(85.0614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 100.33818817138672  loc loss 6.181878566741943\n",
      "tensor(106.5201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.8861083984375  loc loss 3.326852321624756\n",
      "tensor(61.2130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.49198913574219  loc loss 3.0783467292785645\n",
      "tensor(68.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.88318634033203  loc loss 3.135296583175659\n",
      "tensor(85.0185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.4041519165039  loc loss 4.261318206787109\n",
      "tensor(70.6655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 118.98530578613281  loc loss 5.498013496398926\n",
      "tensor(124.4833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.46845245361328  loc loss 5.900549411773682\n",
      "tensor(65.3690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 70.68655395507812  loc loss 4.0837273597717285\n",
      "tensor(74.7703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 67.22232055664062  loc loss 5.046001434326172\n",
      "tensor(72.2683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.01715087890625  loc loss 3.6488492488861084\n",
      "tensor(60.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.84248352050781  loc loss 5.142706871032715\n",
      "tensor(71.9852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.15113067626953  loc loss 3.8041703701019287\n",
      "tensor(61.9553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.51473999023438  loc loss 5.294981479644775\n",
      "tensor(81.8097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.737083435058594  loc loss 3.24051833152771\n",
      "tensor(59.9776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 67.26687622070312  loc loss 9.894391059875488\n",
      "tensor(77.1613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.61221313476562  loc loss 4.997775077819824\n",
      "tensor(74.6100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 75.88032531738281  loc loss 6.779618263244629\n",
      "tensor(82.6599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.763999938964844  loc loss 3.361577272415161\n",
      "tensor(65.1256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 75.24036407470703  loc loss 4.983717918395996\n",
      "tensor(80.2241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 88.57669067382812  loc loss 6.106965065002441\n",
      "tensor(94.6837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.1927490234375  loc loss 4.725186347961426\n",
      "tensor(70.9179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 86.15264129638672  loc loss 5.067803382873535\n",
      "tensor(91.2204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.223358154296875  loc loss 4.9559125900268555\n",
      "tensor(62.1793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 93.90060424804688  loc loss 6.840932846069336\n",
      "tensor(100.7415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.51297760009766  loc loss 5.2681474685668945\n",
      "tensor(77.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 71.8045654296875  loc loss 6.099318504333496\n",
      "tensor(77.9039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.868141174316406  loc loss 3.370626926422119\n",
      "tensor(63.2388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 73.12010192871094  loc loss 6.0491108894348145\n",
      "tensor(79.1692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 67.99221801757812  loc loss 3.032553195953369\n",
      "tensor(71.0248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 84.67203521728516  loc loss 5.098686218261719\n",
      "tensor(89.7707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.21995544433594  loc loss 4.280646800994873\n",
      "tensor(72.5006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.8203125  loc loss 5.834445476531982\n",
      "tensor(64.6548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.95746612548828  loc loss 4.322133541107178\n",
      "tensor(74.2796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.95649719238281  loc loss 3.7256505489349365\n",
      "tensor(69.6821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 63.47808837890625  loc loss 7.774791240692139\n",
      "tensor(71.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.09637451171875  loc loss 3.5264735221862793\n",
      "tensor(67.6228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 63.20507049560547  loc loss 4.015103816986084\n",
      "tensor(67.2202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.80878448486328  loc loss 3.166388750076294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(64.9752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.960845947265625  loc loss 2.9046313762664795\n",
      "tensor(57.8655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 80.52540588378906  loc loss 5.294931888580322\n",
      "tensor(85.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 70.48277282714844  loc loss 4.69124698638916\n",
      "tensor(75.1740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.29747009277344  loc loss 7.024054527282715\n",
      "tensor(71.3215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.06697082519531  loc loss 4.252843379974365\n",
      "tensor(62.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.81297302246094  loc loss 3.2154250144958496\n",
      "tensor(69.0284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.76165771484375  loc loss 2.760835886001587\n",
      "tensor(71.5225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 67.29127502441406  loc loss 3.944918394088745\n",
      "tensor(71.2362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.606903076171875  loc loss 2.859121799468994\n",
      "tensor(64.4660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 74.74459838867188  loc loss 5.046102046966553\n",
      "tensor(79.7907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.89215850830078  loc loss 3.392786979675293\n",
      "tensor(58.2849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.89541244506836  loc loss 4.645473957061768\n",
      "tensor(61.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.63597869873047  loc loss 4.109951972961426\n",
      "tensor(68.7459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.037925720214844  loc loss 4.109649658203125\n",
      "tensor(66.1476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 77.8777847290039  loc loss 4.345441818237305\n",
      "tensor(82.2232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.18010711669922  loc loss 4.6053547859191895\n",
      "tensor(68.7855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 85.82481384277344  loc loss 3.468317747116089\n",
      "tensor(89.2931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.61662292480469  loc loss 2.591231107711792\n",
      "tensor(68.2079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.84796142578125  loc loss 6.565633296966553\n",
      "tensor(65.4136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 105.40200805664062  loc loss 4.4058003425598145\n",
      "tensor(109.8078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 85.55084228515625  loc loss 5.335271835327148\n",
      "tensor(90.8861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.722103118896484  loc loss 3.637329339981079\n",
      "tensor(58.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 63.799903869628906  loc loss 5.30299186706543\n",
      "tensor(69.1029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 157.5352020263672  loc loss 7.164284706115723\n",
      "tensor(164.6995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.66865539550781  loc loss 2.863621950149536\n",
      "tensor(62.5323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 67.14666748046875  loc loss 3.168856143951416\n",
      "tensor(70.3155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 75.713134765625  loc loss 4.176025867462158\n",
      "tensor(79.8892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 80.04229736328125  loc loss 5.471773624420166\n",
      "tensor(85.5141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.2815170288086  loc loss 3.4396791458129883\n",
      "tensor(67.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 84.75210571289062  loc loss 9.489713668823242\n",
      "tensor(94.2418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 86.48831176757812  loc loss 4.662644863128662\n",
      "tensor(91.1510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.787025451660156  loc loss 3.8338418006896973\n",
      "tensor(62.6209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.0673828125  loc loss 3.918701171875\n",
      "tensor(62.9861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.91357421875  loc loss 7.36870813369751\n",
      "tensor(80.2823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 79.80607604980469  loc loss 6.015072822570801\n",
      "tensor(85.8212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.08422088623047  loc loss 4.855006217956543\n",
      "tensor(66.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.63279724121094  loc loss 3.2264952659606934\n",
      "tensor(53.8593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 75.22091674804688  loc loss 4.0778937339782715\n",
      "tensor(79.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.12152099609375  loc loss 4.654735088348389\n",
      "tensor(70.7763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.242671966552734  loc loss 3.4332849979400635\n",
      "tensor(61.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 79.32618713378906  loc loss 5.700651168823242\n",
      "tensor(85.0268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.790122985839844  loc loss 4.0786566734313965\n",
      "tensor(65.8688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.06147003173828  loc loss 3.818765878677368\n",
      "tensor(60.8802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.09257507324219  loc loss 4.290266990661621\n",
      "tensor(72.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.48065185546875  loc loss 2.700422763824463\n",
      "tensor(75.1811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.570518493652344  loc loss 4.361975193023682\n",
      "tensor(63.9325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.545501708984375  loc loss 3.5110042095184326\n",
      "tensor(65.0565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 63.455299377441406  loc loss 3.981774091720581\n",
      "tensor(67.4371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 63.02669143676758  loc loss 4.970126152038574\n",
      "tensor(67.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.8827133178711  loc loss 4.314245223999023\n",
      "tensor(77.1970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 74.25225830078125  loc loss 4.708213806152344\n",
      "tensor(78.9605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.17007064819336  loc loss 3.3598546981811523\n",
      "tensor(59.5299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.75776672363281  loc loss 4.428380012512207\n",
      "tensor(64.1861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.75636291503906  loc loss 4.781993865966797\n",
      "tensor(67.5384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 70.27218627929688  loc loss 4.692296028137207\n",
      "tensor(74.9645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.15386199951172  loc loss 4.8504414558410645\n",
      "tensor(61.0043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.41963958740234  loc loss 4.740983963012695\n",
      "tensor(77.1606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.2677001953125  loc loss 2.8713858127593994\n",
      "tensor(52.1391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.76060485839844  loc loss 3.3902039527893066\n",
      "tensor(68.1508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.509979248046875  loc loss 4.639627933502197\n",
      "tensor(56.1496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 73.63270568847656  loc loss 4.566104412078857\n",
      "tensor(78.1988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 88.65277099609375  loc loss 4.89058780670166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(93.5434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 60.60931396484375  loc loss 2.3869872093200684\n",
      "tensor(62.9963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.976558685302734  loc loss 3.381366014480591\n",
      "tensor(53.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.713645935058594  loc loss 4.3293843269348145\n",
      "tensor(54.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.40861511230469  loc loss 8.114141464233398\n",
      "tensor(84.5228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.1131820678711  loc loss 3.6927380561828613\n",
      "tensor(79.8059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 70.4659194946289  loc loss 6.435417175292969\n",
      "tensor(76.9013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.99437713623047  loc loss 3.134927749633789\n",
      "tensor(57.1293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.39356231689453  loc loss 4.7375168800354\n",
      "tensor(71.1311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.98861694335938  loc loss 4.966372013092041\n",
      "tensor(73.9550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 91.13671875  loc loss 4.189271926879883\n",
      "tensor(95.3260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.6762809753418  loc loss 3.8447232246398926\n",
      "tensor(62.5210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.7706184387207  loc loss 3.103764772415161\n",
      "tensor(54.8744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.870628356933594  loc loss 5.003831386566162\n",
      "tensor(67.8745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.88717269897461  loc loss 3.6258203983306885\n",
      "tensor(58.5130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.61235427856445  loc loss 4.176430702209473\n",
      "tensor(65.7888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 79.73666381835938  loc loss 5.084305763244629\n",
      "tensor(84.8210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.915382385253906  loc loss 4.93173885345459\n",
      "tensor(61.8471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 84.5146484375  loc loss 6.025984764099121\n",
      "tensor(90.5406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.89751434326172  loc loss 6.965481758117676\n",
      "tensor(62.8630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 67.03376770019531  loc loss 5.142502307891846\n",
      "tensor(72.1763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.515411376953125  loc loss 4.269644737243652\n",
      "tensor(61.7851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.63503646850586  loc loss 4.357849597930908\n",
      "tensor(60.9929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.87179183959961  loc loss 2.9080793857574463\n",
      "tensor(56.7799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.69453430175781  loc loss 4.8004231452941895\n",
      "tensor(69.4950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.98631286621094  loc loss 6.258281230926514\n",
      "tensor(83.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.36936950683594  loc loss 4.668884754180908\n",
      "tensor(74.0383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.79621887207031  loc loss 3.8204312324523926\n",
      "tensor(70.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.89071655273438  loc loss 4.557870388031006\n",
      "tensor(74.4486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.61457824707031  loc loss 3.5576119422912598\n",
      "tensor(69.1722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.12683868408203  loc loss 3.2380597591400146\n",
      "tensor(51.3649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.42236328125  loc loss 2.870741367340088\n",
      "tensor(59.2931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.71656799316406  loc loss 2.851083993911743\n",
      "tensor(54.5677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.36260986328125  loc loss 5.0808563232421875\n",
      "tensor(54.4435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.155731201171875  loc loss 5.178334712982178\n",
      "tensor(64.3341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.470252990722656  loc loss 5.210841178894043\n",
      "tensor(61.6811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.054222106933594  loc loss 7.124383926391602\n",
      "tensor(65.1786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.304656982421875  loc loss 4.757257461547852\n",
      "tensor(58.0619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.733158111572266  loc loss 5.494512557983398\n",
      "tensor(62.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.511192321777344  loc loss 5.213005065917969\n",
      "tensor(58.7242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.11027526855469  loc loss 2.962476968765259\n",
      "tensor(59.0728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.04106140136719  loc loss 4.912270545959473\n",
      "tensor(53.9533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.95428466796875  loc loss 4.0367937088012695\n",
      "tensor(66.9911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.69775390625  loc loss 3.078883171081543\n",
      "tensor(60.7766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.364891052246094  loc loss 2.75900936126709\n",
      "tensor(51.1239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.848854064941406  loc loss 3.2861177921295166\n",
      "tensor(62.1350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.828826904296875  loc loss 3.4556734561920166\n",
      "tensor(56.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.11443328857422  loc loss 5.026094436645508\n",
      "tensor(58.1405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.90895080566406  loc loss 4.906091213226318\n",
      "tensor(66.8150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.24272918701172  loc loss 2.7612862586975098\n",
      "tensor(52.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.27061462402344  loc loss 3.807889699935913\n",
      "tensor(61.0785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.39014434814453  loc loss 4.167947769165039\n",
      "tensor(69.5581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.48198699951172  loc loss 4.816230773925781\n",
      "tensor(57.2982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.084693908691406  loc loss 2.9343178272247314\n",
      "tensor(60.0190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.393310546875  loc loss 3.348867654800415\n",
      "tensor(51.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.72468566894531  loc loss 3.120659589767456\n",
      "tensor(67.8453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.65033721923828  loc loss 4.839800834655762\n",
      "tensor(59.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.277610778808594  loc loss 5.1024274826049805\n",
      "tensor(62.3800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.3436279296875  loc loss 2.870558738708496\n",
      "tensor(58.2142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.144805908203125  loc loss 4.398959159851074\n",
      "tensor(56.5438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.185081481933594  loc loss 2.929774284362793\n",
      "tensor(52.1149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.99108123779297  loc loss 3.5628702640533447\n",
      "tensor(47.5540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 63.00252151489258  loc loss 6.006772994995117\n",
      "tensor(69.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 68.98223876953125  loc loss 5.978772163391113\n",
      "tensor(74.9610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 92.81682586669922  loc loss 3.6799354553222656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(96.4968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 87.1522445678711  loc loss 5.9526166915893555\n",
      "tensor(93.1049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.16080474853516  loc loss 3.625447988510132\n",
      "tensor(68.7863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.34617614746094  loc loss 4.478714942932129\n",
      "tensor(63.8249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.62859344482422  loc loss 2.746124029159546\n",
      "tensor(54.3747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.75555419921875  loc loss 6.73408842086792\n",
      "tensor(73.4896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.625667572021484  loc loss 2.747204542160034\n",
      "tensor(47.3729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.155372619628906  loc loss 4.106509208679199\n",
      "tensor(62.2619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.93077087402344  loc loss 3.5008418560028076\n",
      "tensor(52.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.9892578125  loc loss 4.713689804077148\n",
      "tensor(58.7029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 60.17441177368164  loc loss 6.657012939453125\n",
      "tensor(66.8314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.652015686035156  loc loss 4.282207489013672\n",
      "tensor(55.9342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.064903259277344  loc loss 4.772281646728516\n",
      "tensor(56.8372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.00238800048828  loc loss 3.0970818996429443\n",
      "tensor(69.0995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.26039123535156  loc loss 3.8340930938720703\n",
      "tensor(57.0945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.03297424316406  loc loss 2.7565360069274902\n",
      "tensor(74.7895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.65772247314453  loc loss 3.812537670135498\n",
      "tensor(55.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.77142333984375  loc loss 4.964531421661377\n",
      "tensor(81.7360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.44059753417969  loc loss 3.7425925731658936\n",
      "tensor(54.1832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.72548294067383  loc loss 3.691777467727661\n",
      "tensor(56.4173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.656517028808594  loc loss 3.6603400707244873\n",
      "tensor(44.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.11854553222656  loc loss 3.1718294620513916\n",
      "tensor(48.2904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.16877746582031  loc loss 3.9272217750549316\n",
      "tensor(56.0960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.60108184814453  loc loss 3.2832229137420654\n",
      "tensor(65.8843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.708221435546875  loc loss 4.386933326721191\n",
      "tensor(67.0952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.56279754638672  loc loss 4.1385273933410645\n",
      "tensor(66.7013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.73695755004883  loc loss 5.46059513092041\n",
      "tensor(53.1976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.624794006347656  loc loss 3.3046231269836426\n",
      "tensor(47.9294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.8284797668457  loc loss 3.5470762252807617\n",
      "tensor(56.3756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 95.65733337402344  loc loss 3.349628210067749\n",
      "tensor(99.0070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.760128021240234  loc loss 2.406325578689575\n",
      "tensor(56.1665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 137.80169677734375  loc loss 4.895476818084717\n",
      "tensor(142.6972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.88654327392578  loc loss 2.864795446395874\n",
      "tensor(48.7513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.936641693115234  loc loss 3.7565250396728516\n",
      "tensor(62.6932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.064361572265625  loc loss 7.942273139953613\n",
      "tensor(66.0066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.585472106933594  loc loss 4.32421350479126\n",
      "tensor(53.9097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.48841857910156  loc loss 4.712612628936768\n",
      "tensor(66.2010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.512107849121094  loc loss 5.410360813140869\n",
      "tensor(59.9225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.35866165161133  loc loss 3.1840503215789795\n",
      "tensor(56.5427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.55516815185547  loc loss 2.832408905029297\n",
      "tensor(46.3876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.79486846923828  loc loss 3.2079200744628906\n",
      "tensor(66.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.48538589477539  loc loss 3.8568460941314697\n",
      "tensor(62.3422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.155372619628906  loc loss 5.911741256713867\n",
      "tensor(62.0671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.2548713684082  loc loss 4.156431198120117\n",
      "tensor(57.4113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.80400085449219  loc loss 3.495260715484619\n",
      "tensor(50.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.20024871826172  loc loss 3.709014654159546\n",
      "tensor(51.9093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.57203674316406  loc loss 2.8121628761291504\n",
      "tensor(57.3842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.82203674316406  loc loss 5.690543174743652\n",
      "tensor(65.5126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.4781608581543  loc loss 3.1308794021606445\n",
      "tensor(51.6090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.62594604492188  loc loss 4.084179401397705\n",
      "tensor(85.7101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.932525634765625  loc loss 2.9596965312957764\n",
      "tensor(46.8922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.798397064208984  loc loss 3.8591654300689697\n",
      "tensor(48.6576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.343772888183594  loc loss 7.693995952606201\n",
      "tensor(62.0378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.34950256347656  loc loss 2.3266944885253906\n",
      "tensor(50.6762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.6549186706543  loc loss 6.6443681716918945\n",
      "tensor(69.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.848052978515625  loc loss 3.502333402633667\n",
      "tensor(54.3504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.454349517822266  loc loss 2.8391799926757812\n",
      "tensor(61.2935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.744014739990234  loc loss 3.4690678119659424\n",
      "tensor(54.2131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.86015701293945  loc loss 3.605334997177124\n",
      "tensor(47.4655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 59.447166442871094  loc loss 4.668936729431152\n",
      "tensor(64.1161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.08537292480469  loc loss 4.684435844421387\n",
      "tensor(58.7698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.56494903564453  loc loss 2.446411609649658\n",
      "tensor(48.0114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.32773208618164  loc loss 2.6133437156677246\n",
      "tensor(54.9411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.857234954833984  loc loss 2.9334065914154053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(43.7906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.00580978393555  loc loss 5.579113483428955\n",
      "tensor(57.5849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.44562530517578  loc loss 4.249852657318115\n",
      "tensor(69.6955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.156044006347656  loc loss 4.066799163818359\n",
      "tensor(56.2228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.153343200683594  loc loss 4.799725532531738\n",
      "tensor(61.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.01624298095703  loc loss 3.885655403137207\n",
      "tensor(47.9019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.91949462890625  loc loss 4.736544609069824\n",
      "tensor(50.6560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.079830169677734  loc loss 3.856532335281372\n",
      "tensor(47.9364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.787513732910156  loc loss 3.185839891433716\n",
      "tensor(43.9734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.68208312988281  loc loss 6.476099967956543\n",
      "tensor(63.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.954261779785156  loc loss 3.5250275135040283\n",
      "tensor(44.4793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.93871307373047  loc loss 2.4369351863861084\n",
      "tensor(43.3756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.41844940185547  loc loss 3.1870415210723877\n",
      "tensor(53.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.63405990600586  loc loss 2.599132776260376\n",
      "tensor(50.2332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.842254638671875  loc loss 4.695952892303467\n",
      "tensor(61.5382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.05812072753906  loc loss 5.13365364074707\n",
      "tensor(58.1918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.61183166503906  loc loss 3.9727416038513184\n",
      "tensor(48.5846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.36452865600586  loc loss 2.944159984588623\n",
      "tensor(57.3087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.489479064941406  loc loss 3.578214645385742\n",
      "tensor(50.0677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.787841796875  loc loss 3.839539051055908\n",
      "tensor(68.6274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.43580627441406  loc loss 2.5802109241485596\n",
      "tensor(54.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.902069091796875  loc loss 2.785977363586426\n",
      "tensor(50.6880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.56044387817383  loc loss 3.806124210357666\n",
      "tensor(49.3666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 60.02949142456055  loc loss 4.843888759613037\n",
      "tensor(64.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.04487609863281  loc loss 3.638164758682251\n",
      "tensor(45.6830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.05617141723633  loc loss 2.64371919631958\n",
      "tensor(60.6999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.387123107910156  loc loss 2.4540762901306152\n",
      "tensor(48.8412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.615821838378906  loc loss 4.898934364318848\n",
      "tensor(59.5148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.38079833984375  loc loss 5.789384365081787\n",
      "tensor(61.1702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 81.75746154785156  loc loss 10.120292663574219\n",
      "tensor(91.8778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.85466766357422  loc loss 2.817918300628662\n",
      "tensor(42.6726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.450401306152344  loc loss 2.669705390930176\n",
      "tensor(49.1201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.454795837402344  loc loss 3.5017404556274414\n",
      "tensor(41.9565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.75440979003906  loc loss 3.5145866870880127\n",
      "tensor(56.2690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.87165069580078  loc loss 4.2069807052612305\n",
      "tensor(61.0786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.615760803222656  loc loss 3.4636805057525635\n",
      "tensor(57.0794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.09239196777344  loc loss 3.4599146842956543\n",
      "tensor(51.5523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.15350341796875  loc loss 4.33385705947876\n",
      "tensor(52.4874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.99827575683594  loc loss 4.548062324523926\n",
      "tensor(61.5463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.59380340576172  loc loss 3.213125705718994\n",
      "tensor(48.8069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.63007354736328  loc loss 3.772252082824707\n",
      "tensor(46.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.45001983642578  loc loss 3.124814987182617\n",
      "tensor(41.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.50246047973633  loc loss 3.831303119659424\n",
      "tensor(65.3338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 76.29020690917969  loc loss 3.434335231781006\n",
      "tensor(79.7245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.5318489074707  loc loss 4.664444446563721\n",
      "tensor(51.1963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.97107696533203  loc loss 3.9583356380462646\n",
      "tensor(54.9294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.94105911254883  loc loss 4.616772174835205\n",
      "tensor(56.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.78820037841797  loc loss 3.7765934467315674\n",
      "tensor(65.5648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.48870086669922  loc loss 4.304407596588135\n",
      "tensor(59.7931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.096946716308594  loc loss 3.238064765930176\n",
      "tensor(45.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 70.15283966064453  loc loss 4.3376054763793945\n",
      "tensor(74.4904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 89.53196716308594  loc loss 9.33785343170166\n",
      "tensor(98.8698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.7776985168457  loc loss 3.979356050491333\n",
      "tensor(46.7571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.61070251464844  loc loss 3.4118096828460693\n",
      "tensor(60.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.35749053955078  loc loss 4.441666603088379\n",
      "tensor(54.7992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.97502136230469  loc loss 3.3632054328918457\n",
      "tensor(49.3382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 90.51383972167969  loc loss 5.958139419555664\n",
      "tensor(96.4720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.165283203125  loc loss 3.6428146362304688\n",
      "tensor(57.8081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.180381774902344  loc loss 2.866603374481201\n",
      "tensor(43.0470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.21931076049805  loc loss 1.9111671447753906\n",
      "tensor(55.1305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.94126892089844  loc loss 6.198629856109619\n",
      "tensor(58.1399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.41157531738281  loc loss 4.681804180145264\n",
      "tensor(48.0934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.05375671386719  loc loss 3.493547201156616\n",
      "tensor(53.5473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.54566955566406  loc loss 4.133858680725098\n",
      "tensor(48.6795, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12096])\n",
      "cls loss 46.03948211669922  loc loss 4.751819133758545\n",
      "tensor(50.7913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.40061569213867  loc loss 4.126405715942383\n",
      "tensor(61.5270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.04054260253906  loc loss 4.5562028884887695\n",
      "tensor(66.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.84921646118164  loc loss 2.4996724128723145\n",
      "tensor(45.3489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.05548095703125  loc loss 3.3068325519561768\n",
      "tensor(46.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.22956848144531  loc loss 4.452296257019043\n",
      "tensor(44.6819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.73775863647461  loc loss 3.4902427196502686\n",
      "tensor(60.2280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.10700988769531  loc loss 3.149097442626953\n",
      "tensor(48.2561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.69527816772461  loc loss 2.015960216522217\n",
      "tensor(46.7112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.588165283203125  loc loss 3.153512716293335\n",
      "tensor(56.7417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.46796798706055  loc loss 8.049484252929688\n",
      "tensor(59.5175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.38515090942383  loc loss 3.717914581298828\n",
      "tensor(49.1031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.55996322631836  loc loss 2.9366767406463623\n",
      "tensor(45.4966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 61.019779205322266  loc loss 3.8085362911224365\n",
      "tensor(64.8283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.55570983886719  loc loss 5.251760005950928\n",
      "tensor(52.8075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.02507400512695  loc loss 3.0838968753814697\n",
      "tensor(53.1090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 63.91663360595703  loc loss 7.412158489227295\n",
      "tensor(71.3288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.75990295410156  loc loss 3.014552116394043\n",
      "tensor(39.7745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.51611328125  loc loss 2.723285436630249\n",
      "tensor(48.2394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.04551696777344  loc loss 4.081658363342285\n",
      "tensor(58.1272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.24653625488281  loc loss 5.800015926361084\n",
      "tensor(57.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.01979064941406  loc loss 3.4823741912841797\n",
      "tensor(75.5022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 86.82953643798828  loc loss 3.9549918174743652\n",
      "tensor(90.7845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.44007110595703  loc loss 3.467099905014038\n",
      "tensor(45.9072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.947303771972656  loc loss 3.001241445541382\n",
      "tensor(43.9485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 79.2578353881836  loc loss 7.193087100982666\n",
      "tensor(86.4509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.318885803222656  loc loss 2.743835687637329\n",
      "tensor(47.0627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.77745819091797  loc loss 2.3172004222869873\n",
      "tensor(42.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.25273895263672  loc loss 3.140130043029785\n",
      "tensor(46.3929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.6331672668457  loc loss 4.835979461669922\n",
      "tensor(52.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 64.67982482910156  loc loss 3.4657232761383057\n",
      "tensor(68.1455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 116.66173553466797  loc loss 3.5713210105895996\n",
      "tensor(120.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.4735221862793  loc loss 4.646016597747803\n",
      "tensor(45.1195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.442420959472656  loc loss 3.2412161827087402\n",
      "tensor(44.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.99696350097656  loc loss 4.989735126495361\n",
      "tensor(57.9867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.701324462890625  loc loss 4.988461494445801\n",
      "tensor(51.6898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.45014953613281  loc loss 2.7315385341644287\n",
      "tensor(54.1817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.049095153808594  loc loss 4.612906455993652\n",
      "tensor(49.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.48938751220703  loc loss 5.024025917053223\n",
      "tensor(57.5134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.91364669799805  loc loss 4.422338008880615\n",
      "tensor(42.3360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.5531005859375  loc loss 3.943516731262207\n",
      "tensor(48.4966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.11829376220703  loc loss 3.0081043243408203\n",
      "tensor(49.1264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.252689361572266  loc loss 3.383847951889038\n",
      "tensor(43.6365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.77052307128906  loc loss 5.490878582000732\n",
      "tensor(59.2614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.360626220703125  loc loss 3.845982074737549\n",
      "tensor(52.2066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.59679412841797  loc loss 5.211743354797363\n",
      "tensor(56.8085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.21430206298828  loc loss 3.7548744678497314\n",
      "tensor(46.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.09738540649414  loc loss 3.9201254844665527\n",
      "tensor(48.0175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.894569396972656  loc loss 3.9473865032196045\n",
      "tensor(52.8420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.437477111816406  loc loss 3.641507863998413\n",
      "tensor(41.0790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.22967529296875  loc loss 5.210954189300537\n",
      "tensor(56.4406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.56175994873047  loc loss 3.397301197052002\n",
      "tensor(46.9591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.14519119262695  loc loss 4.3238701820373535\n",
      "tensor(42.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.855037689208984  loc loss 6.09814453125\n",
      "tensor(58.9532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.928932189941406  loc loss 2.927206039428711\n",
      "tensor(46.8561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.68312454223633  loc loss 3.7238407135009766\n",
      "tensor(47.4070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.792606353759766  loc loss 2.84965443611145\n",
      "tensor(41.6423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.72486114501953  loc loss 3.361476421356201\n",
      "tensor(50.0863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.407230377197266  loc loss 2.6283440589904785\n",
      "tensor(58.0356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.33640670776367  loc loss 3.5559167861938477\n",
      "tensor(42.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.28560256958008  loc loss 5.334721088409424\n",
      "tensor(62.6203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.606895446777344  loc loss 5.909862518310547\n",
      "tensor(62.5168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.43180847167969  loc loss 4.38555908203125\n",
      "tensor(46.8174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.629180908203125  loc loss 2.9072933197021484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(53.5365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.40170669555664  loc loss 2.219170570373535\n",
      "tensor(45.6209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.10639953613281  loc loss 4.511533737182617\n",
      "tensor(46.6179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.22975540161133  loc loss 3.8773670196533203\n",
      "tensor(60.1071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.42450714111328  loc loss 3.5151047706604004\n",
      "tensor(68.9396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.37709045410156  loc loss 3.247411012649536\n",
      "tensor(37.6245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.975303649902344  loc loss 2.733055830001831\n",
      "tensor(41.7084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.49915313720703  loc loss 3.312983989715576\n",
      "tensor(46.8121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.63349914550781  loc loss 2.5744223594665527\n",
      "tensor(59.2079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.36988830566406  loc loss 2.6570537090301514\n",
      "tensor(39.0269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.34330749511719  loc loss 4.775674343109131\n",
      "tensor(45.1190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.53624725341797  loc loss 2.559286594390869\n",
      "tensor(38.0955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.768272399902344  loc loss 5.539538383483887\n",
      "tensor(57.3078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.493228912353516  loc loss 2.0685744285583496\n",
      "tensor(38.5618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.50050354003906  loc loss 4.372924327850342\n",
      "tensor(45.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.084739685058594  loc loss 5.300992488861084\n",
      "tensor(62.3857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.96009063720703  loc loss 3.016510486602783\n",
      "tensor(47.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.84204864501953  loc loss 3.6849400997161865\n",
      "tensor(58.5270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.15304946899414  loc loss 3.153331756591797\n",
      "tensor(49.3064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.408973693847656  loc loss 3.337451696395874\n",
      "tensor(41.7464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.55992126464844  loc loss 4.18855619430542\n",
      "tensor(53.7485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.165714263916016  loc loss 3.4564805030822754\n",
      "tensor(57.6222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.42451477050781  loc loss 3.9213531017303467\n",
      "tensor(53.3459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.257354736328125  loc loss 3.7694647312164307\n",
      "tensor(48.0268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.783241271972656  loc loss 2.6993229389190674\n",
      "tensor(46.4826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.02790832519531  loc loss 3.720881223678589\n",
      "tensor(41.7488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.94011688232422  loc loss 2.6864194869995117\n",
      "tensor(58.6265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.95597839355469  loc loss 2.9819140434265137\n",
      "tensor(47.9379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.43279266357422  loc loss 3.6637163162231445\n",
      "tensor(45.0965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.62790298461914  loc loss 2.1326093673706055\n",
      "tensor(33.7605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.485206604003906  loc loss 2.9428086280822754\n",
      "tensor(43.4280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.32652282714844  loc loss 2.23222017288208\n",
      "tensor(34.5587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.3404541015625  loc loss 2.112917184829712\n",
      "tensor(38.4534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.65031433105469  loc loss 3.1465113162994385\n",
      "tensor(52.7968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.228736877441406  loc loss 2.7938754558563232\n",
      "tensor(38.0226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.62715148925781  loc loss 3.3319091796875\n",
      "tensor(49.9591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.36078643798828  loc loss 3.551867723464966\n",
      "tensor(51.9127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.555477142333984  loc loss 3.5202643871307373\n",
      "tensor(46.0757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.116119384765625  loc loss 3.260770559310913\n",
      "tensor(47.3769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.87076950073242  loc loss 4.144773960113525\n",
      "tensor(44.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.106712341308594  loc loss 2.969717502593994\n",
      "tensor(41.0764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.240421295166016  loc loss 3.6643476486206055\n",
      "tensor(41.9048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.897674560546875  loc loss 3.074638843536377\n",
      "tensor(39.9723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.760990142822266  loc loss 4.673354625701904\n",
      "tensor(47.4343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.79427719116211  loc loss 6.0027594566345215\n",
      "tensor(50.7970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 91.19390869140625  loc loss 3.135359048843384\n",
      "tensor(94.3293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.6416015625  loc loss 4.211620330810547\n",
      "tensor(44.8532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.786407470703125  loc loss 3.4081661701202393\n",
      "tensor(38.1946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.57060241699219  loc loss 2.8870341777801514\n",
      "tensor(54.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.85821533203125  loc loss 3.2216968536376953\n",
      "tensor(46.0799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.33779525756836  loc loss 3.233778953552246\n",
      "tensor(37.5716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.85788345336914  loc loss 5.27172327041626\n",
      "tensor(51.1296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.87580490112305  loc loss 2.786120891571045\n",
      "tensor(38.6619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.08843231201172  loc loss 2.947309732437134\n",
      "tensor(43.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.2427978515625  loc loss 4.090907096862793\n",
      "tensor(45.3337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.01552200317383  loc loss 2.936021327972412\n",
      "tensor(40.9515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 57.982948303222656  loc loss 3.2744829654693604\n",
      "tensor(61.2574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.141624450683594  loc loss 4.964869022369385\n",
      "tensor(58.1065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.966407775878906  loc loss 2.4903578758239746\n",
      "tensor(46.4568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.578216552734375  loc loss 3.1917028427124023\n",
      "tensor(45.7699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.50409698486328  loc loss 3.37030029296875\n",
      "tensor(40.8744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.8325309753418  loc loss 3.6113696098327637\n",
      "tensor(42.4439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.57846450805664  loc loss 2.9070684909820557\n",
      "tensor(40.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 39.40876770019531  loc loss 3.7221498489379883\n",
      "tensor(43.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.25542449951172  loc loss 5.322086334228516\n",
      "tensor(55.5775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.680023193359375  loc loss 3.8027477264404297\n",
      "tensor(53.4828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.999752044677734  loc loss 4.554017066955566\n",
      "tensor(43.5538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.3496208190918  loc loss 3.9763574600219727\n",
      "tensor(43.3260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.59580612182617  loc loss 3.968104362487793\n",
      "tensor(53.5639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.429534912109375  loc loss 2.430462121963501\n",
      "tensor(37.8600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.971378326416016  loc loss 4.713409423828125\n",
      "tensor(44.6848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.88298034667969  loc loss 3.9158668518066406\n",
      "tensor(46.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.194252014160156  loc loss 3.9451284408569336\n",
      "tensor(59.1394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.36577606201172  loc loss 3.3960325717926025\n",
      "tensor(47.7618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.72483825683594  loc loss 4.115891456604004\n",
      "tensor(59.8407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.36332702636719  loc loss 5.17182731628418\n",
      "tensor(71.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.280242919921875  loc loss 4.841664791107178\n",
      "tensor(45.1219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.73082733154297  loc loss 3.4544646739959717\n",
      "tensor(73.1853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.70002746582031  loc loss 4.1505126953125\n",
      "tensor(45.8505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.30938720703125  loc loss 2.6879348754882812\n",
      "tensor(41.9973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 60.657073974609375  loc loss 4.69649076461792\n",
      "tensor(65.3536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.102806091308594  loc loss 3.080770969390869\n",
      "tensor(36.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.318302154541016  loc loss 3.9959335327148438\n",
      "tensor(43.3142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.50202560424805  loc loss 8.656832695007324\n",
      "tensor(63.1589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.943973541259766  loc loss 3.230494499206543\n",
      "tensor(50.1745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 88.29927825927734  loc loss 7.664455890655518\n",
      "tensor(95.9637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.29503631591797  loc loss 3.028660297393799\n",
      "tensor(43.3237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.50454330444336  loc loss 3.313485860824585\n",
      "tensor(43.8180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.085994720458984  loc loss 2.740415096282959\n",
      "tensor(37.8264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.42283630371094  loc loss 3.0996875762939453\n",
      "tensor(35.5225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 77.49002075195312  loc loss 5.186642646789551\n",
      "tensor(82.6767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.81815719604492  loc loss 2.2988076210021973\n",
      "tensor(36.1170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.872100830078125  loc loss 4.923620223999023\n",
      "tensor(42.7957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.21290969848633  loc loss 4.243996620178223\n",
      "tensor(43.4569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.62546920776367  loc loss 3.4075160026550293\n",
      "tensor(45.0330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.411354064941406  loc loss 3.6023006439208984\n",
      "tensor(43.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.84107971191406  loc loss 3.8548290729522705\n",
      "tensor(42.6959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.91273880004883  loc loss 5.556066036224365\n",
      "tensor(57.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.75827407836914  loc loss 3.893834114074707\n",
      "tensor(42.6521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.67278289794922  loc loss 3.3178536891937256\n",
      "tensor(36.9906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.46282196044922  loc loss 2.9647889137268066\n",
      "tensor(40.4276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.04096984863281  loc loss 5.7732720375061035\n",
      "tensor(45.8142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.290122985839844  loc loss 2.6497185230255127\n",
      "tensor(47.9398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.6273078918457  loc loss 2.357555866241455\n",
      "tensor(49.9849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.58221435546875  loc loss 2.886486768722534\n",
      "tensor(44.4687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.599700927734375  loc loss 2.2175309658050537\n",
      "tensor(35.8172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.41646957397461  loc loss 2.6637802124023438\n",
      "tensor(36.0802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.81238555908203  loc loss 3.045650005340576\n",
      "tensor(40.8580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.016719818115234  loc loss 2.651121139526367\n",
      "tensor(56.6678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.56440734863281  loc loss 2.1242289543151855\n",
      "tensor(37.6886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.77381134033203  loc loss 5.323482036590576\n",
      "tensor(53.0973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.66462707519531  loc loss 5.496849060058594\n",
      "tensor(42.1615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.751163482666016  loc loss 3.7004289627075195\n",
      "tensor(42.4516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 56.91554260253906  loc loss 4.364476203918457\n",
      "tensor(61.2800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.322998046875  loc loss 3.4038004875183105\n",
      "tensor(38.7268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.29939270019531  loc loss 2.2793972492218018\n",
      "tensor(40.5788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.74274444580078  loc loss 3.5595102310180664\n",
      "tensor(47.3023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.804290771484375  loc loss 5.628927230834961\n",
      "tensor(55.4332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.80821990966797  loc loss 3.7294116020202637\n",
      "tensor(41.5376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.21524429321289  loc loss 2.987064838409424\n",
      "tensor(38.2023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.98931884765625  loc loss 2.6758768558502197\n",
      "tensor(39.6652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.79414367675781  loc loss 2.5589709281921387\n",
      "tensor(35.3531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.92585754394531  loc loss 5.349490165710449\n",
      "tensor(51.2753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.89312744140625  loc loss 4.326347351074219\n",
      "tensor(54.2195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.53860092163086  loc loss 3.9808285236358643\n",
      "tensor(46.5194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.701263427734375  loc loss 2.803847312927246\n",
      "tensor(44.5051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.18199157714844  loc loss 2.8378381729125977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.0198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.051116943359375  loc loss 3.4084300994873047\n",
      "tensor(42.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.84806823730469  loc loss 2.9795961380004883\n",
      "tensor(68.8277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.112144470214844  loc loss 3.4114630222320557\n",
      "tensor(42.5236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.10157775878906  loc loss 3.9273383617401123\n",
      "tensor(44.0289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.61421585083008  loc loss 3.9159140586853027\n",
      "tensor(50.5301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.301551818847656  loc loss 2.338325023651123\n",
      "tensor(43.6399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.17429733276367  loc loss 2.480123281478882\n",
      "tensor(35.6544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.707420349121094  loc loss 4.461180686950684\n",
      "tensor(45.1686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.56791305541992  loc loss 2.599531412124634\n",
      "tensor(40.1674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.797401428222656  loc loss 3.5289013385772705\n",
      "tensor(49.3263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.858009338378906  loc loss 2.5531017780303955\n",
      "tensor(37.4111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.662120819091797  loc loss 2.9971303939819336\n",
      "tensor(34.6593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.137393951416016  loc loss 4.636458873748779\n",
      "tensor(56.7739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.57978439331055  loc loss 2.2880167961120605\n",
      "tensor(37.8678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.1032829284668  loc loss 4.591915130615234\n",
      "tensor(41.6952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.23382568359375  loc loss 4.491038799285889\n",
      "tensor(53.7249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.1787109375  loc loss 2.777876615524292\n",
      "tensor(38.9566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.23404312133789  loc loss 3.5329980850219727\n",
      "tensor(43.7670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.229915618896484  loc loss 5.049713611602783\n",
      "tensor(42.2796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.27833938598633  loc loss 3.1257615089416504\n",
      "tensor(41.4041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.28157043457031  loc loss 3.5899014472961426\n",
      "tensor(42.8715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.14101028442383  loc loss 4.197910308837891\n",
      "tensor(44.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.115665435791016  loc loss 3.215017557144165\n",
      "tensor(40.3307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.383880615234375  loc loss 3.6625051498413086\n",
      "tensor(45.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.693603515625  loc loss 5.103445053100586\n",
      "tensor(39.7971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 54.17238235473633  loc loss 3.6676180362701416\n",
      "tensor(57.8400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.359012603759766  loc loss 5.919499397277832\n",
      "tensor(49.2785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.72732162475586  loc loss 2.9301671981811523\n",
      "tensor(33.6575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.508113861083984  loc loss 3.1371514797210693\n",
      "tensor(46.6453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.35737228393555  loc loss 4.982398986816406\n",
      "tensor(48.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.540771484375  loc loss 3.8955352306365967\n",
      "tensor(40.4363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.47815704345703  loc loss 8.256561279296875\n",
      "tensor(77.7347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.64392852783203  loc loss 4.401313781738281\n",
      "tensor(48.0452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.98908996582031  loc loss 4.368696689605713\n",
      "tensor(40.3578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.26203536987305  loc loss 2.737154245376587\n",
      "tensor(36.9992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.86293029785156  loc loss 4.002895355224609\n",
      "tensor(45.8658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.79467010498047  loc loss 2.5311708450317383\n",
      "tensor(36.3258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.21018981933594  loc loss 3.289376735687256\n",
      "tensor(41.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.457584381103516  loc loss 3.0180795192718506\n",
      "tensor(49.4757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.27696228027344  loc loss 4.015082359313965\n",
      "tensor(52.2920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.54018783569336  loc loss 3.5584230422973633\n",
      "tensor(57.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.10928726196289  loc loss 6.19503927230835\n",
      "tensor(54.3043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.926788330078125  loc loss 2.7746052742004395\n",
      "tensor(37.7014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.089988708496094  loc loss 2.4299020767211914\n",
      "tensor(37.5199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.98653030395508  loc loss 3.9503471851348877\n",
      "tensor(38.9369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.22536849975586  loc loss 3.936406135559082\n",
      "tensor(48.1618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.80238723754883  loc loss 3.1616461277008057\n",
      "tensor(45.9640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.818321228027344  loc loss 3.281768560409546\n",
      "tensor(34.1001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.77977752685547  loc loss 3.726086139678955\n",
      "tensor(37.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.30094528198242  loc loss 4.037783622741699\n",
      "tensor(43.3387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.97456741333008  loc loss 3.272547721862793\n",
      "tensor(36.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.63188934326172  loc loss 4.0229268074035645\n",
      "tensor(50.6548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.71049118041992  loc loss 3.268362522125244\n",
      "tensor(46.9789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.43634033203125  loc loss 3.3458054065704346\n",
      "tensor(43.7821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.35099792480469  loc loss 3.6993534564971924\n",
      "tensor(41.0504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.20193099975586  loc loss 2.3487420082092285\n",
      "tensor(30.5507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.96135711669922  loc loss 2.593000888824463\n",
      "tensor(44.5544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.659120559692383  loc loss 2.8959269523620605\n",
      "tensor(33.5550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.7877197265625  loc loss 2.931424379348755\n",
      "tensor(51.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.13799285888672  loc loss 2.9917259216308594\n",
      "tensor(37.1297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.33415985107422  loc loss 5.637299060821533\n",
      "tensor(44.9715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.647193908691406  loc loss 2.5235040187835693\n",
      "tensor(41.1707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.898841857910156  loc loss 4.040274143218994\n",
      "tensor(39.9391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.174957275390625  loc loss 2.8660759925842285\n",
      "tensor(34.0410, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12096])\n",
      "cls loss 36.07297897338867  loc loss 3.719658136367798\n",
      "tensor(39.7926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 72.17359161376953  loc loss 5.547178268432617\n",
      "tensor(77.7208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.32841873168945  loc loss 4.010211944580078\n",
      "tensor(37.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.80693435668945  loc loss 9.704702377319336\n",
      "tensor(61.5116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.3297119140625  loc loss 3.1522607803344727\n",
      "tensor(53.4820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.9045524597168  loc loss 5.155064105987549\n",
      "tensor(48.0596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.99366760253906  loc loss 4.149204254150391\n",
      "tensor(52.1429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.81946563720703  loc loss 4.537509918212891\n",
      "tensor(44.3570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.49626159667969  loc loss 5.1163835525512695\n",
      "tensor(48.6126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.191688537597656  loc loss 2.7881345748901367\n",
      "tensor(51.9798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.675392150878906  loc loss 4.210291385650635\n",
      "tensor(40.8857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 69.07833862304688  loc loss 6.222074031829834\n",
      "tensor(75.3004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.682579040527344  loc loss 1.8987356424331665\n",
      "tensor(35.5813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.07594299316406  loc loss 2.552382707595825\n",
      "tensor(35.6283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.58196258544922  loc loss 2.3999717235565186\n",
      "tensor(36.9819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.337223052978516  loc loss 3.671534776687622\n",
      "tensor(42.0088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 58.41868591308594  loc loss 8.483291625976562\n",
      "tensor(66.9020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.588844299316406  loc loss 4.942549228668213\n",
      "tensor(57.5314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.63460159301758  loc loss 3.0692267417907715\n",
      "tensor(37.7038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.09913635253906  loc loss 4.9060211181640625\n",
      "tensor(47.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.019187927246094  loc loss 2.861186981201172\n",
      "tensor(44.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.92528533935547  loc loss 3.250410795211792\n",
      "tensor(37.1757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.77899932861328  loc loss 2.8979272842407227\n",
      "tensor(46.6769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.67296028137207  loc loss 2.3918495178222656\n",
      "tensor(34.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.60765075683594  loc loss 4.735023498535156\n",
      "tensor(37.3427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.92559814453125  loc loss 3.7282187938690186\n",
      "tensor(39.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.160884857177734  loc loss 4.210982799530029\n",
      "tensor(42.3719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.907833099365234  loc loss 2.199798822402954\n",
      "tensor(31.1076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.21296310424805  loc loss 3.8034191131591797\n",
      "tensor(53.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.649566650390625  loc loss 2.6615355014801025\n",
      "tensor(30.3111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.59426498413086  loc loss 3.8046960830688477\n",
      "tensor(47.3990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.11635208129883  loc loss 3.8769476413726807\n",
      "tensor(45.9933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.97783279418945  loc loss 6.046598434448242\n",
      "tensor(52.0244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.96849822998047  loc loss 4.8332905769348145\n",
      "tensor(51.8018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.13224792480469  loc loss 3.165070056915283\n",
      "tensor(39.2973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.110530853271484  loc loss 4.1175031661987305\n",
      "tensor(40.2280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.047332763671875  loc loss 3.6445248126983643\n",
      "tensor(43.6919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.3707389831543  loc loss 5.2953877449035645\n",
      "tensor(52.6661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.20244216918945  loc loss 2.3735718727111816\n",
      "tensor(47.5760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.45979881286621  loc loss 2.085228204727173\n",
      "tensor(31.5450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.380897521972656  loc loss 3.030585765838623\n",
      "tensor(37.4115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.00587844848633  loc loss 2.46156907081604\n",
      "tensor(36.4674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.821754455566406  loc loss 2.5844640731811523\n",
      "tensor(36.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.046344757080078  loc loss 2.8280575275421143\n",
      "tensor(32.8744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.608665466308594  loc loss 3.159721851348877\n",
      "tensor(31.7684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.929107666015625  loc loss 4.281404495239258\n",
      "tensor(57.2105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.479705810546875  loc loss 3.0073890686035156\n",
      "tensor(41.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.719064712524414  loc loss 2.5513572692871094\n",
      "tensor(34.2704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.56916427612305  loc loss 3.2781341075897217\n",
      "tensor(43.8473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.52882385253906  loc loss 5.674997329711914\n",
      "tensor(72.2038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.49005889892578  loc loss 4.636925220489502\n",
      "tensor(37.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.532352447509766  loc loss 3.189114570617676\n",
      "tensor(38.7215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 63.6530647277832  loc loss 8.358744621276855\n",
      "tensor(72.0118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.10246658325195  loc loss 3.55446195602417\n",
      "tensor(46.6569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.557945251464844  loc loss 2.877319574356079\n",
      "tensor(40.4353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.73485565185547  loc loss 3.8027548789978027\n",
      "tensor(37.5376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.40525436401367  loc loss 2.4543673992156982\n",
      "tensor(35.8596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.098587036132812  loc loss 2.443528652191162\n",
      "tensor(30.5421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.58142852783203  loc loss 6.774474620819092\n",
      "tensor(46.3559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.12226867675781  loc loss 2.396743059158325\n",
      "tensor(49.5190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.98805236816406  loc loss 6.89376974105835\n",
      "tensor(45.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.219688415527344  loc loss 3.520961284637451\n",
      "tensor(33.7407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.75716018676758  loc loss 2.6017277240753174\n",
      "tensor(39.3589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.99396896362305  loc loss 4.098334312438965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48.0923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.977500915527344  loc loss 4.796138763427734\n",
      "tensor(38.7736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.858810424804688  loc loss 2.2321290969848633\n",
      "tensor(31.0909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 47.221805572509766  loc loss 4.816521644592285\n",
      "tensor(52.0383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.42633819580078  loc loss 6.578205108642578\n",
      "tensor(43.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.106204986572266  loc loss 3.5092451572418213\n",
      "tensor(37.6155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.79705238342285  loc loss 2.7879514694213867\n",
      "tensor(32.5850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.525230407714844  loc loss 2.7170333862304688\n",
      "tensor(36.2423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.631988525390625  loc loss 2.3004355430603027\n",
      "tensor(40.9324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.70000648498535  loc loss 2.9967172145843506\n",
      "tensor(34.6967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.549209594726562  loc loss 2.1386523246765137\n",
      "tensor(32.6879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.45539855957031  loc loss 3.899258852005005\n",
      "tensor(38.3547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.51090621948242  loc loss 2.517714023590088\n",
      "tensor(38.0286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.90727233886719  loc loss 3.0517120361328125\n",
      "tensor(37.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.056930541992188  loc loss 4.86696720123291\n",
      "tensor(33.9239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.748817443847656  loc loss 3.3757216930389404\n",
      "tensor(41.1245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.365997314453125  loc loss 2.1982743740081787\n",
      "tensor(30.5643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.32469940185547  loc loss 4.522906303405762\n",
      "tensor(38.8476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.8546028137207  loc loss 3.2064826488494873\n",
      "tensor(36.0611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.3291130065918  loc loss 3.5012753009796143\n",
      "tensor(40.8304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.48738670349121  loc loss 2.953416585922241\n",
      "tensor(33.4408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.008636474609375  loc loss 1.72456693649292\n",
      "tensor(42.7332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.76624298095703  loc loss 4.636474609375\n",
      "tensor(38.4027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.02081871032715  loc loss 2.732757091522217\n",
      "tensor(33.7536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.894195556640625  loc loss 2.6471314430236816\n",
      "tensor(35.5413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.87877655029297  loc loss 3.118187665939331\n",
      "tensor(35.9970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.51570129394531  loc loss 4.311349868774414\n",
      "tensor(55.8270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.59334945678711  loc loss 2.7655534744262695\n",
      "tensor(27.3589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.978912353515625  loc loss 4.728209018707275\n",
      "tensor(38.7071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.31662368774414  loc loss 4.702427387237549\n",
      "tensor(42.0191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.48735809326172  loc loss 4.892894268035889\n",
      "tensor(37.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.16088104248047  loc loss 5.018693923950195\n",
      "tensor(49.1796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.061920166015625  loc loss 1.863613247871399\n",
      "tensor(31.9255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 66.82469177246094  loc loss 5.004979610443115\n",
      "tensor(71.8297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.49147415161133  loc loss 3.181288003921509\n",
      "tensor(39.6728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.034696578979492  loc loss 3.9437904357910156\n",
      "tensor(32.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.39350128173828  loc loss 2.7376551628112793\n",
      "tensor(44.1312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.516544342041016  loc loss 4.4589338302612305\n",
      "tensor(36.9755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 53.396240234375  loc loss 2.013714551925659\n",
      "tensor(55.4100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.05308151245117  loc loss 3.6889634132385254\n",
      "tensor(38.7420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.212059020996094  loc loss 2.942948341369629\n",
      "tensor(58.1550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.529008865356445  loc loss 2.134303092956543\n",
      "tensor(31.6633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.68976593017578  loc loss 4.0187859535217285\n",
      "tensor(39.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.768604278564453  loc loss 2.367460012435913\n",
      "tensor(32.1361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.57300567626953  loc loss 4.017730236053467\n",
      "tensor(36.5907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.40729522705078  loc loss 3.58420467376709\n",
      "tensor(48.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.46674346923828  loc loss 2.4322452545166016\n",
      "tensor(41.8990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.552024841308594  loc loss 3.1020562648773193\n",
      "tensor(38.6541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.61090087890625  loc loss 3.8976235389709473\n",
      "tensor(41.5085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.263477325439453  loc loss 2.693244457244873\n",
      "tensor(30.9567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.154151916503906  loc loss 4.272078037261963\n",
      "tensor(49.4262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.465415954589844  loc loss 3.230618953704834\n",
      "tensor(39.6960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.28508377075195  loc loss 2.622534990310669\n",
      "tensor(38.9076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.307159423828125  loc loss 5.613487243652344\n",
      "tensor(42.9206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.05177307128906  loc loss 3.8232288360595703\n",
      "tensor(53.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.235313415527344  loc loss 3.1740121841430664\n",
      "tensor(44.4093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.05393981933594  loc loss 3.422914743423462\n",
      "tensor(38.4769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.79737091064453  loc loss 4.311716556549072\n",
      "tensor(45.1091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.4505729675293  loc loss 4.757256984710693\n",
      "tensor(37.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.34062194824219  loc loss 2.451022148132324\n",
      "tensor(37.7916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.521507263183594  loc loss 2.5166683197021484\n",
      "tensor(30.0382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.37116622924805  loc loss 3.7989983558654785\n",
      "tensor(36.1702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.74309539794922  loc loss 5.049053192138672\n",
      "tensor(38.7921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.94770050048828  loc loss 4.753497123718262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.29894256591797  loc loss 3.180417537689209\n",
      "tensor(32.4794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.251792907714844  loc loss 3.3112449645996094\n",
      "tensor(42.5630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.6326789855957  loc loss 3.5851259231567383\n",
      "tensor(39.2178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.00279235839844  loc loss 5.611285209655762\n",
      "tensor(42.6141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.365121841430664  loc loss 3.1647019386291504\n",
      "tensor(31.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.60612487792969  loc loss 2.540802478790283\n",
      "tensor(36.1469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.0233154296875  loc loss 3.994041681289673\n",
      "tensor(43.0174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.09354019165039  loc loss 4.015254497528076\n",
      "tensor(40.1088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.33604431152344  loc loss 4.337340354919434\n",
      "tensor(37.6734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 51.77165603637695  loc loss 4.805484771728516\n",
      "tensor(56.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.23072814941406  loc loss 3.008972406387329\n",
      "tensor(37.2397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.627655029296875  loc loss 5.668586730957031\n",
      "tensor(41.2962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.573814392089844  loc loss 4.117008686065674\n",
      "tensor(45.6908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.553157806396484  loc loss 5.170814514160156\n",
      "tensor(42.7240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.76338768005371  loc loss 2.8916001319885254\n",
      "tensor(30.6550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.832374572753906  loc loss 3.575788736343384\n",
      "tensor(37.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.47705841064453  loc loss 4.139014720916748\n",
      "tensor(32.6161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.309017181396484  loc loss 5.107728958129883\n",
      "tensor(35.4167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.69304656982422  loc loss 4.035650730133057\n",
      "tensor(37.7287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.13378143310547  loc loss 3.3147757053375244\n",
      "tensor(43.4486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.432668685913086  loc loss 3.308723211288452\n",
      "tensor(32.7414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.885032653808594  loc loss 3.8070006370544434\n",
      "tensor(37.6920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.24456787109375  loc loss 2.3986573219299316\n",
      "tensor(29.6432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.486507415771484  loc loss 2.911484479904175\n",
      "tensor(29.3980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.04456901550293  loc loss 3.628277063369751\n",
      "tensor(33.6728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.65576934814453  loc loss 2.932124614715576\n",
      "tensor(46.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.666513442993164  loc loss 4.325511932373047\n",
      "tensor(29.9920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.674057006835938  loc loss 3.4740238189697266\n",
      "tensor(31.1481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.360170364379883  loc loss 2.4654934406280518\n",
      "tensor(31.8257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.16248321533203  loc loss 3.8250250816345215\n",
      "tensor(37.9875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.94059181213379  loc loss 2.6873557567596436\n",
      "tensor(34.6279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.88835906982422  loc loss 3.9329657554626465\n",
      "tensor(36.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.04972839355469  loc loss 2.3150298595428467\n",
      "tensor(67.3648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.611339569091797  loc loss 3.522892713546753\n",
      "tensor(35.1342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.81427001953125  loc loss 2.768195390701294\n",
      "tensor(31.5825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.084388732910156  loc loss 2.3709094524383545\n",
      "tensor(33.4553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.63933181762695  loc loss 2.9176721572875977\n",
      "tensor(38.5570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.26853942871094  loc loss 6.538334846496582\n",
      "tensor(61.8069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.267452239990234  loc loss 4.131178855895996\n",
      "tensor(35.3986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 50.64543914794922  loc loss 5.381064414978027\n",
      "tensor(56.0265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.301055908203125  loc loss 3.212252378463745\n",
      "tensor(31.5133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.427473068237305  loc loss 2.458606004714966\n",
      "tensor(30.8861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.79999542236328  loc loss 2.3830323219299316\n",
      "tensor(39.1830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.54228973388672  loc loss 2.6564159393310547\n",
      "tensor(36.1987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.62727165222168  loc loss 2.5908257961273193\n",
      "tensor(34.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 65.44591522216797  loc loss 3.4399709701538086\n",
      "tensor(68.8859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.860103607177734  loc loss 2.67865252494812\n",
      "tensor(32.5388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.29671859741211  loc loss 3.705325126647949\n",
      "tensor(33.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.36742401123047  loc loss 2.7730324268341064\n",
      "tensor(49.1405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.95366859436035  loc loss 2.473512649536133\n",
      "tensor(30.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.13163757324219  loc loss 4.445374011993408\n",
      "tensor(56.5770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.351593017578125  loc loss 2.9259939193725586\n",
      "tensor(52.2776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.74785614013672  loc loss 2.394073009490967\n",
      "tensor(31.1419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.890785217285156  loc loss 4.972801208496094\n",
      "tensor(49.8636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.308860778808594  loc loss 3.669389247894287\n",
      "tensor(37.9782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.29244041442871  loc loss 2.283102512359619\n",
      "tensor(31.5755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.693389892578125  loc loss 2.0499913692474365\n",
      "tensor(34.7434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.374897003173828  loc loss 3.900912284851074\n",
      "tensor(33.2758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.397356033325195  loc loss 4.704798221588135\n",
      "tensor(32.1022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.27336883544922  loc loss 3.5114049911499023\n",
      "tensor(37.7848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.061439514160156  loc loss 3.7512083053588867\n",
      "tensor(37.8126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.399269104003906  loc loss 3.917365789413452\n",
      "tensor(44.3166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.281110763549805  loc loss 2.4582324028015137\n",
      "tensor(29.7393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.553936004638672  loc loss 2.558558702468872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(29.1125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.803558349609375  loc loss 3.64058256149292\n",
      "tensor(40.4441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 48.124778747558594  loc loss 3.7289481163024902\n",
      "tensor(51.8537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.576387405395508  loc loss 2.191704273223877\n",
      "tensor(30.7681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.224815368652344  loc loss 4.391479969024658\n",
      "tensor(41.6163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.807952880859375  loc loss 2.7084245681762695\n",
      "tensor(30.5164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.74681091308594  loc loss 4.446956634521484\n",
      "tensor(38.1938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.565242767333984  loc loss 3.5676064491271973\n",
      "tensor(35.1329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.678537368774414  loc loss 3.964980125427246\n",
      "tensor(31.6435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.947071075439453  loc loss 2.963761806488037\n",
      "tensor(32.9108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.510475158691406  loc loss 3.5264673233032227\n",
      "tensor(36.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.647972106933594  loc loss 3.255516290664673\n",
      "tensor(32.9035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.02625274658203  loc loss 5.135937690734863\n",
      "tensor(46.1622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.312637329101562  loc loss 2.254023313522339\n",
      "tensor(33.5667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.244224548339844  loc loss 3.3902125358581543\n",
      "tensor(35.6344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.9124755859375  loc loss 4.625186920166016\n",
      "tensor(34.5377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 52.94279098510742  loc loss 4.773917198181152\n",
      "tensor(57.7167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.2153263092041  loc loss 3.0336341857910156\n",
      "tensor(30.2490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.045366287231445  loc loss 2.322983503341675\n",
      "tensor(28.3683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.14879608154297  loc loss 4.324507713317871\n",
      "tensor(37.4733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.625383377075195  loc loss 3.0453391075134277\n",
      "tensor(34.6707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.266559600830078  loc loss 3.7953941822052\n",
      "tensor(34.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.680023193359375  loc loss 4.937572956085205\n",
      "tensor(36.6176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.27983093261719  loc loss 2.1753392219543457\n",
      "tensor(37.4552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.72628402709961  loc loss 3.07698917388916\n",
      "tensor(33.8033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.730621337890625  loc loss 2.5672481060028076\n",
      "tensor(30.2979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.157405853271484  loc loss 3.2444658279418945\n",
      "tensor(33.4019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.838176727294922  loc loss 3.9327986240386963\n",
      "tensor(30.7710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.532136917114258  loc loss 2.957216501235962\n",
      "tensor(31.4894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.12004852294922  loc loss 5.663700103759766\n",
      "tensor(39.7837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.682334899902344  loc loss 3.0277583599090576\n",
      "tensor(47.7101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.04529571533203  loc loss 3.138960361480713\n",
      "tensor(33.1843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.8358154296875  loc loss 4.371960639953613\n",
      "tensor(34.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.06789779663086  loc loss 5.647449493408203\n",
      "tensor(35.7153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.72574234008789  loc loss 4.043762683868408\n",
      "tensor(35.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.4073486328125  loc loss 3.917916774749756\n",
      "tensor(36.3253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.470966339111328  loc loss 2.418752670288086\n",
      "tensor(28.8897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.488189697265625  loc loss 2.5892014503479004\n",
      "tensor(30.0774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.629032135009766  loc loss 3.2260799407958984\n",
      "tensor(41.8551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.35197830200195  loc loss 3.2182681560516357\n",
      "tensor(45.5702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.869983673095703  loc loss 2.6862754821777344\n",
      "tensor(27.5563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.43124771118164  loc loss 2.7783002853393555\n",
      "tensor(27.2095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.40617370605469  loc loss 3.8570592403411865\n",
      "tensor(41.2632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.11843490600586  loc loss 2.2397878170013428\n",
      "tensor(31.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.14094543457031  loc loss 3.625180244445801\n",
      "tensor(43.7661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.390201568603516  loc loss 3.613389015197754\n",
      "tensor(43.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.4510440826416  loc loss 3.9344213008880615\n",
      "tensor(31.3855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.13273620605469  loc loss 2.361433267593384\n",
      "tensor(45.4942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.0355339050293  loc loss 5.418643474578857\n",
      "tensor(43.4542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.398483276367188  loc loss 2.2834978103637695\n",
      "tensor(33.6820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.851478576660156  loc loss 2.602827310562134\n",
      "tensor(35.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.64966583251953  loc loss 3.154257297515869\n",
      "tensor(39.8039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.282119750976562  loc loss 3.018747091293335\n",
      "tensor(30.3009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.796436309814453  loc loss 2.79742693901062\n",
      "tensor(30.5939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.46185302734375  loc loss 2.7524116039276123\n",
      "tensor(32.2143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.616554260253906  loc loss 3.056339740753174\n",
      "tensor(32.6729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.047645568847656  loc loss 3.2906501293182373\n",
      "tensor(30.3383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.72358703613281  loc loss 5.677768707275391\n",
      "tensor(41.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.396442413330078  loc loss 4.281380653381348\n",
      "tensor(35.6778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.776386260986328  loc loss 3.85793137550354\n",
      "tensor(31.6343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.37030029296875  loc loss 3.149132251739502\n",
      "tensor(42.5194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.69312286376953  loc loss 3.0648961067199707\n",
      "tensor(28.7580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.08292770385742  loc loss 2.751415491104126\n",
      "tensor(42.8343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.109081268310547  loc loss 2.0507283210754395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27.1598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.379520416259766  loc loss 2.9689714908599854\n",
      "tensor(29.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.014488220214844  loc loss 4.138034820556641\n",
      "tensor(38.1525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.80570983886719  loc loss 4.1634016036987305\n",
      "tensor(45.9691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.833778381347656  loc loss 2.3720483779907227\n",
      "tensor(41.2058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.53413200378418  loc loss 2.2126660346984863\n",
      "tensor(27.7468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.09760284423828  loc loss 3.1005725860595703\n",
      "tensor(40.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.69688034057617  loc loss 4.388601779937744\n",
      "tensor(43.0855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.15153121948242  loc loss 2.9450089931488037\n",
      "tensor(35.0965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.562908172607422  loc loss 2.1110806465148926\n",
      "tensor(26.6740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.77239990234375  loc loss 2.2619032859802246\n",
      "tensor(29.0343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.76673889160156  loc loss 4.7265424728393555\n",
      "tensor(41.4933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.40922737121582  loc loss 3.131915330886841\n",
      "tensor(31.5411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.40361404418945  loc loss 5.417018413543701\n",
      "tensor(48.8206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.075227737426758  loc loss 2.98282527923584\n",
      "tensor(29.0581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.51216125488281  loc loss 5.8009161949157715\n",
      "tensor(43.3131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.72368621826172  loc loss 2.8187947273254395\n",
      "tensor(34.5425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.645029067993164  loc loss 3.7990810871124268\n",
      "tensor(31.4441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.920612335205078  loc loss 2.5629031658172607\n",
      "tensor(26.4835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.756790161132812  loc loss 2.5908851623535156\n",
      "tensor(28.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.578033447265625  loc loss 4.290650367736816\n",
      "tensor(45.8687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.209070205688477  loc loss 2.68930721282959\n",
      "tensor(29.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.449668884277344  loc loss 3.1249210834503174\n",
      "tensor(35.5746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.92387580871582  loc loss 3.05045485496521\n",
      "tensor(31.9743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.898468017578125  loc loss 3.155600070953369\n",
      "tensor(32.0541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.73198127746582  loc loss 5.377863883972168\n",
      "tensor(36.1098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.854999542236328  loc loss 3.9557137489318848\n",
      "tensor(33.8107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.677352905273438  loc loss 3.48201322555542\n",
      "tensor(34.1594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.858978271484375  loc loss 3.1539018154144287\n",
      "tensor(30.0129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.689373016357422  loc loss 2.6333818435668945\n",
      "tensor(33.3228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 55.13339614868164  loc loss 3.0515031814575195\n",
      "tensor(58.1849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.422611236572266  loc loss 1.9714326858520508\n",
      "tensor(26.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.414276123046875  loc loss 5.012932300567627\n",
      "tensor(44.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.185752868652344  loc loss 3.3987364768981934\n",
      "tensor(47.5845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.91351890563965  loc loss 2.143183946609497\n",
      "tensor(24.0567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.472293853759766  loc loss 4.547878265380859\n",
      "tensor(43.0202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.710205078125  loc loss 3.841705799102783\n",
      "tensor(34.5519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.3377685546875  loc loss 2.9303483963012695\n",
      "tensor(37.2681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.45092010498047  loc loss 2.8818376064300537\n",
      "tensor(52.3328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.68158721923828  loc loss 3.005936861038208\n",
      "tensor(36.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.37464141845703  loc loss 2.888975143432617\n",
      "tensor(33.2636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.476036071777344  loc loss 3.064852476119995\n",
      "tensor(38.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.258960723876953  loc loss 2.8011276721954346\n",
      "tensor(34.0601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.15838623046875  loc loss 2.415236234664917\n",
      "tensor(31.5736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.169734954833984  loc loss 2.530738592147827\n",
      "tensor(26.7005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.710174560546875  loc loss 3.5021564960479736\n",
      "tensor(40.2123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.686023712158203  loc loss 2.791273355484009\n",
      "tensor(30.4773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.70113754272461  loc loss 2.3935904502868652\n",
      "tensor(31.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.624977111816406  loc loss 2.9250237941741943\n",
      "tensor(30.5500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.06336784362793  loc loss 3.3998169898986816\n",
      "tensor(31.4632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.172096252441406  loc loss 2.676046848297119\n",
      "tensor(32.8481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.59421157836914  loc loss 2.473609209060669\n",
      "tensor(37.0678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.32271957397461  loc loss 2.286257266998291\n",
      "tensor(28.6090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.17855453491211  loc loss 3.0928995609283447\n",
      "tensor(33.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.59662628173828  loc loss 5.3983964920043945\n",
      "tensor(39.9950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.600297927856445  loc loss 2.4731311798095703\n",
      "tensor(27.0734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.846515655517578  loc loss 2.118359088897705\n",
      "tensor(24.9649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.479496002197266  loc loss 2.7355151176452637\n",
      "tensor(27.2150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.220428466796875  loc loss 2.852949619293213\n",
      "tensor(36.0734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.007457733154297  loc loss 2.546088218688965\n",
      "tensor(26.5535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.936397552490234  loc loss 3.3475117683410645\n",
      "tensor(39.2839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.34250259399414  loc loss 3.039318799972534\n",
      "tensor(31.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.26141357421875  loc loss 2.5877583026885986\n",
      "tensor(28.8492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.79146957397461  loc loss 3.3915610313415527\n",
      "tensor(27.1830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.958919525146484  loc loss 2.743636131286621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(34.7026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.192852020263672  loc loss 3.175269842147827\n",
      "tensor(33.3681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.632373809814453  loc loss 3.550381660461426\n",
      "tensor(34.1828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.757658004760742  loc loss 2.6205430030822754\n",
      "tensor(33.3782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.777551651000977  loc loss 4.073010444641113\n",
      "tensor(33.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.529876708984375  loc loss 3.9360556602478027\n",
      "tensor(38.4659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.4002685546875  loc loss 2.984724998474121\n",
      "tensor(29.3850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.40626525878906  loc loss 3.7460501194000244\n",
      "tensor(36.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.674297332763672  loc loss 2.161675453186035\n",
      "tensor(24.8360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.00945281982422  loc loss 4.891421318054199\n",
      "tensor(39.9009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.14834213256836  loc loss 3.269784927368164\n",
      "tensor(35.4181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.68559646606445  loc loss 4.808032989501953\n",
      "tensor(49.4936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.05934715270996  loc loss 3.5505011081695557\n",
      "tensor(33.6098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.977497100830078  loc loss 2.113337278366089\n",
      "tensor(29.0908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.624740600585938  loc loss 2.32535719871521\n",
      "tensor(32.9501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.40172576904297  loc loss 1.9520814418792725\n",
      "tensor(31.3538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.34003448486328  loc loss 2.703939199447632\n",
      "tensor(30.0440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.806320190429688  loc loss 2.651318311691284\n",
      "tensor(28.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.2671012878418  loc loss 4.917118072509766\n",
      "tensor(38.1842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.99576950073242  loc loss 3.3885562419891357\n",
      "tensor(40.3843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.844715118408203  loc loss 2.6168160438537598\n",
      "tensor(29.4615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.62033462524414  loc loss 4.661336421966553\n",
      "tensor(31.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.040571212768555  loc loss 2.8854079246520996\n",
      "tensor(31.9260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.530534744262695  loc loss 3.7152364253997803\n",
      "tensor(29.2458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.622291564941406  loc loss 3.2347590923309326\n",
      "tensor(27.8570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.135711669921875  loc loss 3.298050880432129\n",
      "tensor(31.4338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.02179718017578  loc loss 3.5139617919921875\n",
      "tensor(27.5358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.550140380859375  loc loss 3.1948342323303223\n",
      "tensor(27.7450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.534225463867188  loc loss 4.3435959815979\n",
      "tensor(30.8778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.917024612426758  loc loss 4.56843900680542\n",
      "tensor(33.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.389371871948242  loc loss 3.562422752380371\n",
      "tensor(30.9518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.842008590698242  loc loss 1.8967859745025635\n",
      "tensor(24.7388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.04718017578125  loc loss 3.6166234016418457\n",
      "tensor(24.6638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.24109649658203  loc loss 1.6809046268463135\n",
      "tensor(42.9220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.986698150634766  loc loss 2.346872329711914\n",
      "tensor(33.3336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.152301788330078  loc loss 2.9558467864990234\n",
      "tensor(30.1081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.219890594482422  loc loss 2.0571868419647217\n",
      "tensor(26.2771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.91108512878418  loc loss 1.9228541851043701\n",
      "tensor(27.8339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.275226593017578  loc loss 2.285029411315918\n",
      "tensor(33.5603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.706260681152344  loc loss 2.44854474067688\n",
      "tensor(38.1548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.99879264831543  loc loss 2.88366436958313\n",
      "tensor(28.8825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.78880310058594  loc loss 7.91837215423584\n",
      "tensor(50.7072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.90700340270996  loc loss 2.286097764968872\n",
      "tensor(27.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.39699363708496  loc loss 2.4445974826812744\n",
      "tensor(29.8416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.56155014038086  loc loss 3.8539018630981445\n",
      "tensor(50.4155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.89665603637695  loc loss 3.3802998065948486\n",
      "tensor(36.2770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.8972053527832  loc loss 3.435337543487549\n",
      "tensor(37.3325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.594581604003906  loc loss 3.1109187602996826\n",
      "tensor(38.7055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.548583984375  loc loss 2.169890880584717\n",
      "tensor(35.7185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.497291564941406  loc loss 3.604499340057373\n",
      "tensor(29.1018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.771774291992188  loc loss 3.376847743988037\n",
      "tensor(26.1486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.525909423828125  loc loss 2.565281629562378\n",
      "tensor(29.0912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.36481475830078  loc loss 3.7851572036743164\n",
      "tensor(31.1500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.72294807434082  loc loss 1.8447210788726807\n",
      "tensor(26.5677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.970273971557617  loc loss 2.991986036300659\n",
      "tensor(29.9623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.102317810058594  loc loss 2.6253819465637207\n",
      "tensor(28.7277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.24188232421875  loc loss 3.9357223510742188\n",
      "tensor(36.1776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.41558074951172  loc loss 3.590860605239868\n",
      "tensor(33.0064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.288394927978516  loc loss 4.154225826263428\n",
      "tensor(44.4426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.007492065429688  loc loss 2.1009011268615723\n",
      "tensor(25.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.063751220703125  loc loss 2.622385025024414\n",
      "tensor(42.6861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.056838989257812  loc loss 2.8654720783233643\n",
      "tensor(30.9223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.208887100219727  loc loss 3.2471938133239746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.160865783691406  loc loss 3.713423490524292\n",
      "tensor(36.8743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.72822570800781  loc loss 2.8664629459381104\n",
      "tensor(43.5947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.07073211669922  loc loss 2.3825340270996094\n",
      "tensor(30.4533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.151996612548828  loc loss 2.430021047592163\n",
      "tensor(31.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.457195281982422  loc loss 3.478078842163086\n",
      "tensor(26.9353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.306209564208984  loc loss 2.8809447288513184\n",
      "tensor(30.1872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.442630767822266  loc loss 3.8039791584014893\n",
      "tensor(32.2466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.347476959228516  loc loss 2.2653510570526123\n",
      "tensor(24.6128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.89543914794922  loc loss 2.9065470695495605\n",
      "tensor(32.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.188480377197266  loc loss 4.60465669631958\n",
      "tensor(37.7931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.67576599121094  loc loss 5.580076694488525\n",
      "tensor(43.2558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.593454360961914  loc loss 3.0447757244110107\n",
      "tensor(27.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.568540573120117  loc loss 3.917833089828491\n",
      "tensor(33.4864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.491870880126953  loc loss 2.5435495376586914\n",
      "tensor(23.0354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.81578063964844  loc loss 3.134782314300537\n",
      "tensor(40.9506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.2276554107666  loc loss 1.7193254232406616\n",
      "tensor(24.9470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.00242233276367  loc loss 2.993114471435547\n",
      "tensor(39.9955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.976966857910156  loc loss 3.5434446334838867\n",
      "tensor(37.5204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.657520294189453  loc loss 2.204745054244995\n",
      "tensor(28.8623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.75942611694336  loc loss 4.823471546173096\n",
      "tensor(49.5829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.457489013671875  loc loss 2.9678258895874023\n",
      "tensor(40.4253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 36.55802917480469  loc loss 3.9100027084350586\n",
      "tensor(40.4680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.507728576660156  loc loss 4.014054775238037\n",
      "tensor(41.5218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.4937744140625  loc loss 2.2634963989257812\n",
      "tensor(36.7573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.348167419433594  loc loss 4.486732006072998\n",
      "tensor(36.8349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.124052047729492  loc loss 3.111764907836914\n",
      "tensor(29.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.29315185546875  loc loss 4.586208343505859\n",
      "tensor(32.8794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.835739135742188  loc loss 2.8811471462249756\n",
      "tensor(33.7169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.43882751464844  loc loss 2.8566317558288574\n",
      "tensor(38.2955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.998779296875  loc loss 3.490870475769043\n",
      "tensor(25.4897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.24056053161621  loc loss 3.165422201156616\n",
      "tensor(29.4060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.1766357421875  loc loss 3.1218929290771484\n",
      "tensor(31.2985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.483551025390625  loc loss 3.33931040763855\n",
      "tensor(38.8229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.633398056030273  loc loss 2.8142502307891846\n",
      "tensor(34.4476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.406753540039062  loc loss 2.4224586486816406\n",
      "tensor(29.8292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.752120971679688  loc loss 2.305046319961548\n",
      "tensor(34.0572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.337833404541016  loc loss 3.8423635959625244\n",
      "tensor(35.1802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.36960220336914  loc loss 2.9045250415802\n",
      "tensor(25.2741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.423511505126953  loc loss 2.8236286640167236\n",
      "tensor(31.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.300065994262695  loc loss 3.016904354095459\n",
      "tensor(28.3170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.90110397338867  loc loss 4.632816314697266\n",
      "tensor(38.5339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.675033569335938  loc loss 2.927366018295288\n",
      "tensor(25.6024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.36192512512207  loc loss 2.502399444580078\n",
      "tensor(27.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.820722579956055  loc loss 3.5267019271850586\n",
      "tensor(32.3474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.47996711730957  loc loss 4.252239227294922\n",
      "tensor(32.7322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.068761825561523  loc loss 3.65832781791687\n",
      "tensor(27.7271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.245241165161133  loc loss 2.744220733642578\n",
      "tensor(28.9895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.264545440673828  loc loss 2.0899572372436523\n",
      "tensor(29.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.95306968688965  loc loss 3.1485986709594727\n",
      "tensor(30.1017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.697860717773438  loc loss 2.1824941635131836\n",
      "tensor(23.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.739259719848633  loc loss 2.5731780529022217\n",
      "tensor(30.3124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.499435424804688  loc loss 2.3580031394958496\n",
      "tensor(24.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.433643341064453  loc loss 2.2731239795684814\n",
      "tensor(24.7068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.001514434814453  loc loss 2.3663806915283203\n",
      "tensor(30.3679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.78856086730957  loc loss 3.441312313079834\n",
      "tensor(34.2299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.211524963378906  loc loss 4.70040225982666\n",
      "tensor(32.9119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.926807403564453  loc loss 2.5001556873321533\n",
      "tensor(33.4270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.32391929626465  loc loss 4.3847270011901855\n",
      "tensor(32.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.70751190185547  loc loss 3.697809934616089\n",
      "tensor(48.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.566932678222656  loc loss 3.493833065032959\n",
      "tensor(37.0608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.494251251220703  loc loss 2.495086908340454\n",
      "tensor(24.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.091896057128906  loc loss 2.6338860988616943\n",
      "tensor(33.7258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.436256408691406  loc loss 1.9210491180419922\n",
      "tensor(23.3573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.879844665527344  loc loss 3.737575054168701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.6174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.609046936035156  loc loss 3.4814953804016113\n",
      "tensor(31.0905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.75652313232422  loc loss 4.085634708404541\n",
      "tensor(29.8422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.744491577148438  loc loss 2.3268840312957764\n",
      "tensor(23.0714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.404346466064453  loc loss 2.4716856479644775\n",
      "tensor(24.8760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.313282012939453  loc loss 3.8084044456481934\n",
      "tensor(32.1217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.105255126953125  loc loss 2.9795022010803223\n",
      "tensor(31.0848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.482263565063477  loc loss 2.0763838291168213\n",
      "tensor(27.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.477195739746094  loc loss 3.319287061691284\n",
      "tensor(36.7965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 44.0345458984375  loc loss 3.9576382637023926\n",
      "tensor(47.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.48685073852539  loc loss 3.071455717086792\n",
      "tensor(28.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.753738403320312  loc loss 2.2055609226226807\n",
      "tensor(26.9593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.471607208251953  loc loss 3.7027528285980225\n",
      "tensor(32.1744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.625755310058594  loc loss 2.058123826980591\n",
      "tensor(20.6839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.62446975708008  loc loss 2.9788198471069336\n",
      "tensor(38.6033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.9764347076416  loc loss 2.5040409564971924\n",
      "tensor(27.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.114980697631836  loc loss 3.419848680496216\n",
      "tensor(31.5348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.163921356201172  loc loss 2.7120282649993896\n",
      "tensor(26.8759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.62234878540039  loc loss 2.4730255603790283\n",
      "tensor(27.0954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.061344146728516  loc loss 3.288677215576172\n",
      "tensor(36.3500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.05183982849121  loc loss 2.481846809387207\n",
      "tensor(32.5337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.197166442871094  loc loss 3.337790012359619\n",
      "tensor(34.5350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.6373291015625  loc loss 5.150456428527832\n",
      "tensor(37.7878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.809310913085938  loc loss 2.1330206394195557\n",
      "tensor(25.9423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.131275177001953  loc loss 2.8790860176086426\n",
      "tensor(28.0104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.32483673095703  loc loss 2.8142569065093994\n",
      "tensor(36.1391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 43.12157440185547  loc loss 6.714566707611084\n",
      "tensor(49.8361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.588123321533203  loc loss 2.026336908340454\n",
      "tensor(22.6145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.425148010253906  loc loss 4.7574944496154785\n",
      "tensor(35.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.477527618408203  loc loss 4.6601152420043945\n",
      "tensor(33.1376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.330198287963867  loc loss 3.472914218902588\n",
      "tensor(29.8031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.96512222290039  loc loss 2.9867238998413086\n",
      "tensor(25.9518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.42485046386719  loc loss 3.6762895584106445\n",
      "tensor(42.1011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.3621883392334  loc loss 2.403930187225342\n",
      "tensor(25.7661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.163654327392578  loc loss 2.645793914794922\n",
      "tensor(26.8094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.93846130371094  loc loss 4.32550573348999\n",
      "tensor(46.2640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.522586822509766  loc loss 3.105896234512329\n",
      "tensor(33.6285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.8612003326416  loc loss 2.898408889770508\n",
      "tensor(26.7596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.56341552734375  loc loss 3.2533373832702637\n",
      "tensor(26.8168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.094358444213867  loc loss 2.860678195953369\n",
      "tensor(25.9550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.77447509765625  loc loss 4.491827487945557\n",
      "tensor(38.2663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.5782527923584  loc loss 3.2197272777557373\n",
      "tensor(24.7980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 39.12269592285156  loc loss 4.458892345428467\n",
      "tensor(43.5816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.084049224853516  loc loss 3.0130460262298584\n",
      "tensor(31.0971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.57859992980957  loc loss 3.62934947013855\n",
      "tensor(30.2079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.962940216064453  loc loss 4.267026424407959\n",
      "tensor(31.2300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.102462768554688  loc loss 2.4365639686584473\n",
      "tensor(28.5390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.42519760131836  loc loss 3.0922300815582275\n",
      "tensor(24.5174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.84769058227539  loc loss 2.433967113494873\n",
      "tensor(22.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.889202117919922  loc loss 3.4997177124023438\n",
      "tensor(32.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.042997360229492  loc loss 2.4002320766448975\n",
      "tensor(25.4432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.55643653869629  loc loss 2.2618541717529297\n",
      "tensor(24.8183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.416149139404297  loc loss 2.1641294956207275\n",
      "tensor(32.5803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.003307342529297  loc loss 3.1566162109375\n",
      "tensor(31.1599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.480451583862305  loc loss 3.2000973224639893\n",
      "tensor(27.6805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.87980651855469  loc loss 6.508656024932861\n",
      "tensor(39.3885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.01443862915039  loc loss 3.368683338165283\n",
      "tensor(26.3831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.232290267944336  loc loss 2.1245851516723633\n",
      "tensor(22.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.337162017822266  loc loss 3.9686765670776367\n",
      "tensor(28.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.884477615356445  loc loss 2.8104610443115234\n",
      "tensor(26.6949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.372255325317383  loc loss 2.2685632705688477\n",
      "tensor(26.6408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.259151458740234  loc loss 3.7570440769195557\n",
      "tensor(32.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.164791107177734  loc loss 4.871766090393066\n",
      "tensor(40.0366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.269390106201172  loc loss 2.202194929122925\n",
      "tensor(30.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.135467529296875  loc loss 2.9585251808166504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.0940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.487476348876953  loc loss 2.2201547622680664\n",
      "tensor(20.7076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.42002296447754  loc loss 4.133079528808594\n",
      "tensor(30.5531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.1830997467041  loc loss 2.241501808166504\n",
      "tensor(23.4246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.103178024291992  loc loss 3.141399621963501\n",
      "tensor(33.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.608848571777344  loc loss 3.184469223022461\n",
      "tensor(26.7933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.11585807800293  loc loss 3.0335586071014404\n",
      "tensor(24.1494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.32904815673828  loc loss 5.185006141662598\n",
      "tensor(34.5141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.139501571655273  loc loss 1.9271663427352905\n",
      "tensor(25.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.46473503112793  loc loss 1.932640790939331\n",
      "tensor(29.3974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.68218994140625  loc loss 3.5833373069763184\n",
      "tensor(28.2655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.50698471069336  loc loss 2.841017246246338\n",
      "tensor(28.3480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.030529022216797  loc loss 4.042789459228516\n",
      "tensor(30.0733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.074726104736328  loc loss 2.5177054405212402\n",
      "tensor(23.5924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.588459014892578  loc loss 3.50480318069458\n",
      "tensor(31.0933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.66119384765625  loc loss 2.163771867752075\n",
      "tensor(24.8250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.323833465576172  loc loss 1.8191890716552734\n",
      "tensor(21.1430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.926149368286133  loc loss 3.0891010761260986\n",
      "tensor(30.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.09568214416504  loc loss 1.9175429344177246\n",
      "tensor(23.0132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.17469024658203  loc loss 2.5104079246520996\n",
      "tensor(27.6851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.63893127441406  loc loss 2.9517416954040527\n",
      "tensor(41.5907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.327802658081055  loc loss 4.277791976928711\n",
      "tensor(30.6056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.701189041137695  loc loss 2.6313884258270264\n",
      "tensor(30.3326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.19017791748047  loc loss 3.6652872562408447\n",
      "tensor(28.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.678932189941406  loc loss 4.042526721954346\n",
      "tensor(31.7215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.045814514160156  loc loss 5.122332572937012\n",
      "tensor(47.1681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.024402618408203  loc loss 2.587524890899658\n",
      "tensor(25.6119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.86090087890625  loc loss 1.9323930740356445\n",
      "tensor(29.7933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.410167694091797  loc loss 3.118722438812256\n",
      "tensor(27.5289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.42539405822754  loc loss 4.364693641662598\n",
      "tensor(32.7901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.83431625366211  loc loss 3.2777578830718994\n",
      "tensor(28.1121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.09130096435547  loc loss 2.178039312362671\n",
      "tensor(26.2693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.265687942504883  loc loss 2.219090700149536\n",
      "tensor(23.4848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.671154022216797  loc loss 2.7913169860839844\n",
      "tensor(24.4625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.746313095092773  loc loss 2.601032257080078\n",
      "tensor(25.3473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.086519241333008  loc loss 3.726853370666504\n",
      "tensor(31.8134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.919586181640625  loc loss 2.7461390495300293\n",
      "tensor(24.6657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.959125518798828  loc loss 3.884422540664673\n",
      "tensor(32.8435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.32851791381836  loc loss 1.84871506690979\n",
      "tensor(27.1772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.70834732055664  loc loss 3.470980167388916\n",
      "tensor(27.1793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.081695556640625  loc loss 1.6924355030059814\n",
      "tensor(22.7741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.141326904296875  loc loss 6.437976837158203\n",
      "tensor(43.5793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.757280349731445  loc loss 1.681230902671814\n",
      "tensor(21.4385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.20281219482422  loc loss 3.893648624420166\n",
      "tensor(30.0965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.46363067626953  loc loss 3.060556650161743\n",
      "tensor(28.5242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.20332908630371  loc loss 3.191845417022705\n",
      "tensor(24.3952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.674955368041992  loc loss 1.4471395015716553\n",
      "tensor(20.1221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.11393356323242  loc loss 4.476579189300537\n",
      "tensor(38.5905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.88375473022461  loc loss 1.910487174987793\n",
      "tensor(21.7942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 45.46015167236328  loc loss 7.59871768951416\n",
      "tensor(53.0589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.34153175354004  loc loss 2.4824883937835693\n",
      "tensor(27.8240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.929487228393555  loc loss 3.0476274490356445\n",
      "tensor(26.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.862041473388672  loc loss 3.080747127532959\n",
      "tensor(25.9428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.0716552734375  loc loss 6.133660793304443\n",
      "tensor(40.2053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.27332305908203  loc loss 3.0904297828674316\n",
      "tensor(30.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.372825622558594  loc loss 2.47375226020813\n",
      "tensor(34.8466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.402427673339844  loc loss 5.770862579345703\n",
      "tensor(38.1733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.99630355834961  loc loss 5.0313615798950195\n",
      "tensor(46.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.867279052734375  loc loss 6.811637878417969\n",
      "tensor(36.6789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.51356315612793  loc loss 2.401088237762451\n",
      "tensor(23.9147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.650611877441406  loc loss 2.5446553230285645\n",
      "tensor(26.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.799945831298828  loc loss 2.4093878269195557\n",
      "tensor(24.2093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.3743953704834  loc loss 2.322758197784424\n",
      "tensor(24.6972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.729034423828125  loc loss 1.9382789134979248\n",
      "tensor(21.6673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.9946231842041  loc loss 4.010611534118652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(29.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.954116821289062  loc loss 2.00966215133667\n",
      "tensor(21.9638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.042497634887695  loc loss 3.5308094024658203\n",
      "tensor(28.5733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.60713005065918  loc loss 3.1146342754364014\n",
      "tensor(23.7218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.13025665283203  loc loss 5.228089332580566\n",
      "tensor(67.3583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.213533401489258  loc loss 2.95210599899292\n",
      "tensor(27.1656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.372100830078125  loc loss 3.5948824882507324\n",
      "tensor(24.9670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.7181396484375  loc loss 6.943816184997559\n",
      "tensor(44.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.08306884765625  loc loss 2.674570322036743\n",
      "tensor(20.7576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.26398468017578  loc loss 3.2450263500213623\n",
      "tensor(36.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.123836517333984  loc loss 2.456942081451416\n",
      "tensor(21.5808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.387041091918945  loc loss 2.8542251586914062\n",
      "tensor(23.2413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.401220321655273  loc loss 2.4382164478302\n",
      "tensor(27.8394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.176977157592773  loc loss 1.978568196296692\n",
      "tensor(22.1555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.946395874023438  loc loss 2.560955286026001\n",
      "tensor(31.5074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.759862899780273  loc loss 2.3720898628234863\n",
      "tensor(26.1320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.720706939697266  loc loss 2.8988890647888184\n",
      "tensor(23.6196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.80429458618164  loc loss 2.7087349891662598\n",
      "tensor(35.5130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.00810432434082  loc loss 3.6449289321899414\n",
      "tensor(29.6530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.488941192626953  loc loss 2.2001709938049316\n",
      "tensor(23.6891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.417203903198242  loc loss 3.4112441539764404\n",
      "tensor(33.8284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.02680206298828  loc loss 1.6176421642303467\n",
      "tensor(19.6444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 33.69007873535156  loc loss 3.5267539024353027\n",
      "tensor(37.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.330509185791016  loc loss 2.068005323410034\n",
      "tensor(24.3985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.0095272064209  loc loss 2.5192346572875977\n",
      "tensor(24.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.51214027404785  loc loss 1.9689888954162598\n",
      "tensor(25.4811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.846973419189453  loc loss 2.0424141883850098\n",
      "tensor(21.8894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.465984344482422  loc loss 2.174483060836792\n",
      "tensor(27.6405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 49.04771423339844  loc loss 2.9572622776031494\n",
      "tensor(52.0050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.947566986083984  loc loss 3.3149056434631348\n",
      "tensor(27.2625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.334766387939453  loc loss 2.166422128677368\n",
      "tensor(22.5012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.740795135498047  loc loss 1.5766572952270508\n",
      "tensor(21.3175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.92116355895996  loc loss 2.29526948928833\n",
      "tensor(31.2164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 40.57828140258789  loc loss 3.5546560287475586\n",
      "tensor(44.1329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.664220809936523  loc loss 2.595853567123413\n",
      "tensor(21.2601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.283811569213867  loc loss 2.9330315589904785\n",
      "tensor(27.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.23000717163086  loc loss 3.1642065048217773\n",
      "tensor(24.3942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.487995147705078  loc loss 4.915951251983643\n",
      "tensor(32.4039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.661346435546875  loc loss 2.692131996154785\n",
      "tensor(21.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 42.030067443847656  loc loss 8.818670272827148\n",
      "tensor(50.8487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.47681427001953  loc loss 1.7134257555007935\n",
      "tensor(27.1902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.776674270629883  loc loss 2.6261637210845947\n",
      "tensor(22.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.702152252197266  loc loss 3.2257423400878906\n",
      "tensor(28.9279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.526762008666992  loc loss 2.626624822616577\n",
      "tensor(29.1534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.294681549072266  loc loss 2.3942463397979736\n",
      "tensor(24.6889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.537033081054688  loc loss 2.3199002742767334\n",
      "tensor(25.8569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.505329132080078  loc loss 2.1142451763153076\n",
      "tensor(27.6196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.076168060302734  loc loss 2.3777952194213867\n",
      "tensor(24.4540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.62578582763672  loc loss 3.2634129524230957\n",
      "tensor(32.8892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.241775512695312  loc loss 3.0237529277801514\n",
      "tensor(26.2655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.15741729736328  loc loss 1.7645982503890991\n",
      "tensor(20.9220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.85675811767578  loc loss 2.4488983154296875\n",
      "tensor(24.3057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.890792846679688  loc loss 2.021519899368286\n",
      "tensor(23.9123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.065486907958984  loc loss 1.5924092531204224\n",
      "tensor(21.6579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.502965927124023  loc loss 3.191446542739868\n",
      "tensor(29.6944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.87010383605957  loc loss 3.3248558044433594\n",
      "tensor(28.1950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.313095092773438  loc loss 3.287442684173584\n",
      "tensor(26.6005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.677337646484375  loc loss 2.5011019706726074\n",
      "tensor(40.1784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.870403289794922  loc loss 2.0298445224761963\n",
      "tensor(23.9002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.688016891479492  loc loss 3.422381639480591\n",
      "tensor(27.1104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.722867965698242  loc loss 4.135765075683594\n",
      "tensor(34.8586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.32708168029785  loc loss 5.682717800140381\n",
      "tensor(37.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.805055618286133  loc loss 2.558093786239624\n",
      "tensor(24.3631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.18203353881836  loc loss 1.743708610534668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.9257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.074365615844727  loc loss 2.033945322036743\n",
      "tensor(23.1083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.21269989013672  loc loss 2.5364086627960205\n",
      "tensor(25.7491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.12789535522461  loc loss 3.936727285385132\n",
      "tensor(30.0646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.985942840576172  loc loss 2.966662883758545\n",
      "tensor(26.9526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.207576751708984  loc loss 3.4307925701141357\n",
      "tensor(23.6384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.970726013183594  loc loss 2.0839293003082275\n",
      "tensor(23.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.668100357055664  loc loss 3.0325963497161865\n",
      "tensor(32.7007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.277347564697266  loc loss 2.7032876014709473\n",
      "tensor(26.9806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.706073760986328  loc loss 1.9831286668777466\n",
      "tensor(20.6892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.095970153808594  loc loss 3.5910935401916504\n",
      "tensor(32.6871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.783245086669922  loc loss 2.2271358966827393\n",
      "tensor(23.0104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.632244110107422  loc loss 2.159931182861328\n",
      "tensor(21.7922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.00597381591797  loc loss 3.4843478202819824\n",
      "tensor(35.4903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.848459243774414  loc loss 2.4653429985046387\n",
      "tensor(23.3138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.000991821289062  loc loss 2.264758825302124\n",
      "tensor(25.2658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.127458572387695  loc loss 2.8615269660949707\n",
      "tensor(23.9890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.89833641052246  loc loss 4.1629958152771\n",
      "tensor(31.0613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.37420082092285  loc loss 2.4245100021362305\n",
      "tensor(24.7987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.83219528198242  loc loss 2.63936185836792\n",
      "tensor(35.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.517728805541992  loc loss 4.435050010681152\n",
      "tensor(27.9528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.03301239013672  loc loss 3.597165584564209\n",
      "tensor(27.6302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.524717330932617  loc loss 3.591209888458252\n",
      "tensor(30.1159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.237075805664062  loc loss 2.768573045730591\n",
      "tensor(26.0056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 41.77096176147461  loc loss 8.825420379638672\n",
      "tensor(50.5964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.790424346923828  loc loss 3.263902187347412\n",
      "tensor(25.0543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.507591247558594  loc loss 3.1721904277801514\n",
      "tensor(26.6798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.856273651123047  loc loss 2.5503647327423096\n",
      "tensor(23.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.0371036529541  loc loss 3.0256526470184326\n",
      "tensor(34.0628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.03913116455078  loc loss 3.504892349243164\n",
      "tensor(33.5440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.056793212890625  loc loss 4.1715545654296875\n",
      "tensor(31.2283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.58823585510254  loc loss 2.414471387863159\n",
      "tensor(25.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.050743103027344  loc loss 2.3934245109558105\n",
      "tensor(23.4442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.955188751220703  loc loss 2.15134334564209\n",
      "tensor(23.1065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.897754669189453  loc loss 3.717045307159424\n",
      "tensor(25.6148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.677892684936523  loc loss 2.3933560848236084\n",
      "tensor(23.0712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.296165466308594  loc loss 2.346615791320801\n",
      "tensor(25.6428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.370264053344727  loc loss 2.1637282371520996\n",
      "tensor(22.5340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.59666442871094  loc loss 3.0795183181762695\n",
      "tensor(38.6762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.2066650390625  loc loss 5.016170978546143\n",
      "tensor(30.2228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.202104568481445  loc loss 3.1857683658599854\n",
      "tensor(22.3879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.019039154052734  loc loss 2.8276350498199463\n",
      "tensor(23.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 16.47726821899414  loc loss 2.363762617111206\n",
      "tensor(18.8410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.90835189819336  loc loss 3.1739492416381836\n",
      "tensor(30.0823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.0944881439209  loc loss 2.935134172439575\n",
      "tensor(28.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.989259719848633  loc loss 4.000881671905518\n",
      "tensor(31.9901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.52677917480469  loc loss 4.649735450744629\n",
      "tensor(42.1765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.1512393951416  loc loss 2.6636674404144287\n",
      "tensor(24.8149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.485858917236328  loc loss 2.110159397125244\n",
      "tensor(22.5960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.212581634521484  loc loss 4.04419469833374\n",
      "tensor(34.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.576183319091797  loc loss 3.402557134628296\n",
      "tensor(34.9787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.264633178710938  loc loss 2.497619867324829\n",
      "tensor(21.7623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.05646896362305  loc loss 3.342862129211426\n",
      "tensor(38.3993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.35807800292969  loc loss 2.4386022090911865\n",
      "tensor(36.7967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.616426467895508  loc loss 2.6583235263824463\n",
      "tensor(23.2747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.79477310180664  loc loss 2.2839133739471436\n",
      "tensor(23.0787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.920682907104492  loc loss 2.4309329986572266\n",
      "tensor(24.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.356792449951172  loc loss 4.276988983154297\n",
      "tensor(28.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.555797576904297  loc loss 2.3232619762420654\n",
      "tensor(22.8791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.496097564697266  loc loss 2.3575387001037598\n",
      "tensor(31.8536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.972579956054688  loc loss 2.9479217529296875\n",
      "tensor(25.9205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.80396270751953  loc loss 3.219775915145874\n",
      "tensor(39.0237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.61151885986328  loc loss 2.009683132171631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.6212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.765024185180664  loc loss 3.5565898418426514\n",
      "tensor(28.3216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.53080940246582  loc loss 2.3723225593566895\n",
      "tensor(20.9031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.22858428955078  loc loss 2.321040153503418\n",
      "tensor(22.5496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.96728515625  loc loss 2.099494218826294\n",
      "tensor(26.0668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.002685546875  loc loss 2.7824909687042236\n",
      "tensor(27.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.30554962158203  loc loss 3.0997800827026367\n",
      "tensor(25.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 46.12070846557617  loc loss 5.094623565673828\n",
      "tensor(51.2153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 16.432113647460938  loc loss 1.6304346323013306\n",
      "tensor(18.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.059898376464844  loc loss 1.9123594760894775\n",
      "tensor(22.9723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.07231330871582  loc loss 2.363776683807373\n",
      "tensor(29.4361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.204891204833984  loc loss 4.567829132080078\n",
      "tensor(32.7727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.760398864746094  loc loss 2.9272327423095703\n",
      "tensor(28.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.269550323486328  loc loss 2.55495285987854\n",
      "tensor(23.8245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.755966186523438  loc loss 1.732753872871399\n",
      "tensor(21.4887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.652320861816406  loc loss 3.283646821975708\n",
      "tensor(30.9360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.48927879333496  loc loss 2.808668613433838\n",
      "tensor(24.2979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.332149505615234  loc loss 3.8916430473327637\n",
      "tensor(29.2238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.08695411682129  loc loss 3.6218857765197754\n",
      "tensor(31.7088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.599023818969727  loc loss 3.576359272003174\n",
      "tensor(28.1754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 16.953224182128906  loc loss 2.0501911640167236\n",
      "tensor(19.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.543365478515625  loc loss 3.234862804412842\n",
      "tensor(30.7782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 16.098064422607422  loc loss 2.2087440490722656\n",
      "tensor(18.3068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.875892639160156  loc loss 2.4143805503845215\n",
      "tensor(24.2903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.3203125  loc loss 3.5633459091186523\n",
      "tensor(26.8837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.56416130065918  loc loss 4.231936931610107\n",
      "tensor(30.7961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.228500366210938  loc loss 1.9582375288009644\n",
      "tensor(23.1867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.83334732055664  loc loss 2.1052298545837402\n",
      "tensor(30.9386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.178462982177734  loc loss 2.6997931003570557\n",
      "tensor(32.8783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.624698638916016  loc loss 2.4099693298339844\n",
      "tensor(22.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.073272705078125  loc loss 2.304975986480713\n",
      "tensor(28.3782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.456111907958984  loc loss 5.0434722900390625\n",
      "tensor(36.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.8900203704834  loc loss 2.5987355709075928\n",
      "tensor(23.4888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.907512664794922  loc loss 2.6895012855529785\n",
      "tensor(30.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.006494522094727  loc loss 4.522902488708496\n",
      "tensor(29.5294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.93056869506836  loc loss 2.983586311340332\n",
      "tensor(29.9142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.49716567993164  loc loss 2.2525792121887207\n",
      "tensor(22.7497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.902950286865234  loc loss 2.2417306900024414\n",
      "tensor(23.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.828462600708008  loc loss 2.78816294670105\n",
      "tensor(28.6166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.46677017211914  loc loss 3.346029281616211\n",
      "tensor(27.8128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.5328369140625  loc loss 3.522526741027832\n",
      "tensor(35.0554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.109485626220703  loc loss 2.791621446609497\n",
      "tensor(28.9011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.37993621826172  loc loss 5.135624885559082\n",
      "tensor(36.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.90464210510254  loc loss 3.7616403102874756\n",
      "tensor(30.6663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.396686553955078  loc loss 2.2525744438171387\n",
      "tensor(22.6493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.651451110839844  loc loss 3.002070188522339\n",
      "tensor(23.6535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.52927589416504  loc loss 2.506749391555786\n",
      "tensor(28.0360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 34.47927474975586  loc loss 3.6388070583343506\n",
      "tensor(38.1181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.135128021240234  loc loss 4.531153678894043\n",
      "tensor(29.6663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.84250259399414  loc loss 2.875427007675171\n",
      "tensor(31.7179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.614974975585938  loc loss 3.1790876388549805\n",
      "tensor(26.7941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.846839904785156  loc loss 2.8784611225128174\n",
      "tensor(25.7253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.738672256469727  loc loss 3.9302315711975098\n",
      "tensor(29.6689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.73413848876953  loc loss 3.9656128883361816\n",
      "tensor(30.6998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.59368896484375  loc loss 3.1605067253112793\n",
      "tensor(22.7542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.356658935546875  loc loss 3.395592451095581\n",
      "tensor(40.7523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 15.14678955078125  loc loss 1.6108589172363281\n",
      "tensor(16.7576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.584491729736328  loc loss 3.1456620693206787\n",
      "tensor(27.7302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.482315063476562  loc loss 2.2443783283233643\n",
      "tensor(23.7267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.524335861206055  loc loss 1.9957966804504395\n",
      "tensor(21.5201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.54570770263672  loc loss 2.4331085681915283\n",
      "tensor(23.9788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.04860496520996  loc loss 3.5338873863220215\n",
      "tensor(25.5825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.811044692993164  loc loss 3.0612025260925293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30.8722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.25558090209961  loc loss 2.8563995361328125\n",
      "tensor(25.1120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.830612182617188  loc loss 2.2264814376831055\n",
      "tensor(22.0571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.322723388671875  loc loss 2.0128023624420166\n",
      "tensor(22.3355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.4049129486084  loc loss 2.3848462104797363\n",
      "tensor(27.7898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.9078369140625  loc loss 2.704511880874634\n",
      "tensor(20.6123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 37.921512603759766  loc loss 3.134876251220703\n",
      "tensor(41.0564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.810148239135742  loc loss 1.6021372079849243\n",
      "tensor(19.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.363422393798828  loc loss 2.9658050537109375\n",
      "tensor(32.3292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.041610717773438  loc loss 3.678739309310913\n",
      "tensor(29.7204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.33171844482422  loc loss 3.2293777465820312\n",
      "tensor(27.5611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.36267852783203  loc loss 1.9378433227539062\n",
      "tensor(20.3005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.518993377685547  loc loss 3.4785189628601074\n",
      "tensor(28.9975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.31539535522461  loc loss 2.2712135314941406\n",
      "tensor(22.5866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.023427963256836  loc loss 3.753302574157715\n",
      "tensor(27.7767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.833797454833984  loc loss 1.9273781776428223\n",
      "tensor(20.7612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.97268295288086  loc loss 3.035674571990967\n",
      "tensor(21.0084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.962406158447266  loc loss 2.0449488162994385\n",
      "tensor(23.0074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.953697204589844  loc loss 2.2216553688049316\n",
      "tensor(20.1754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.940643310546875  loc loss 2.9672110080718994\n",
      "tensor(23.9079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.17670440673828  loc loss 1.6631221771240234\n",
      "tensor(18.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.25205421447754  loc loss 3.6486849784851074\n",
      "tensor(32.9007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.35089111328125  loc loss 2.3479795455932617\n",
      "tensor(24.6989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.287559509277344  loc loss 3.6290600299835205\n",
      "tensor(26.9166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.9200382232666  loc loss 3.535555124282837\n",
      "tensor(28.4556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.15073585510254  loc loss 2.2752444744110107\n",
      "tensor(19.4260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.99797821044922  loc loss 2.206505060195923\n",
      "tensor(22.2045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.047962188720703  loc loss 3.3508362770080566\n",
      "tensor(33.3988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.53615951538086  loc loss 3.1027913093566895\n",
      "tensor(22.6390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.306385040283203  loc loss 1.7219200134277344\n",
      "tensor(22.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.492721557617188  loc loss 2.5737009048461914\n",
      "tensor(22.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.65024185180664  loc loss 2.511122465133667\n",
      "tensor(28.1614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.010814666748047  loc loss 2.7283077239990234\n",
      "tensor(26.7391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.535404205322266  loc loss 2.891914129257202\n",
      "tensor(25.4273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.502532958984375  loc loss 1.8580117225646973\n",
      "tensor(21.3605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.050012588500977  loc loss 2.1510426998138428\n",
      "tensor(32.2011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.609529495239258  loc loss 5.660061359405518\n",
      "tensor(31.2696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.31618881225586  loc loss 3.168386459350586\n",
      "tensor(22.4846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.60635757446289  loc loss 2.6267077922821045\n",
      "tensor(22.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.129201889038086  loc loss 2.5542922019958496\n",
      "tensor(23.6835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.317960739135742  loc loss 2.801194429397583\n",
      "tensor(23.1192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 32.04776382446289  loc loss 3.4395556449890137\n",
      "tensor(35.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.712915420532227  loc loss 1.906965970993042\n",
      "tensor(20.6199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.050954818725586  loc loss 2.057584762573242\n",
      "tensor(21.1085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.141963958740234  loc loss 3.313955783843994\n",
      "tensor(22.4559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.27010726928711  loc loss 3.318138837814331\n",
      "tensor(24.5882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.443788528442383  loc loss 2.1326494216918945\n",
      "tensor(22.5764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.047182083129883  loc loss 3.0158298015594482\n",
      "tensor(22.0630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.22058868408203  loc loss 1.59130859375\n",
      "tensor(23.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.633861541748047  loc loss 1.6980881690979004\n",
      "tensor(19.3319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.32552719116211  loc loss 2.398954391479492\n",
      "tensor(22.7245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.761688232421875  loc loss 2.6993274688720703\n",
      "tensor(20.4610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 16.557170867919922  loc loss 1.500205636024475\n",
      "tensor(18.0574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.731916427612305  loc loss 2.391395330429077\n",
      "tensor(28.1233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.14879608154297  loc loss 2.2350738048553467\n",
      "tensor(23.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.80254364013672  loc loss 3.648237466812134\n",
      "tensor(23.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.187076568603516  loc loss 4.149638652801514\n",
      "tensor(29.3367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.781238555908203  loc loss 2.8403892517089844\n",
      "tensor(27.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.0  loc loss 4.235907077789307\n",
      "tensor(33.2359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.80057144165039  loc loss 4.044770240783691\n",
      "tensor(27.8453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.738910675048828  loc loss 3.2320752143859863\n",
      "tensor(25.9710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.137859344482422  loc loss 2.3938214778900146\n",
      "tensor(22.5317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.649539947509766  loc loss 3.1842751502990723\n",
      "tensor(23.8338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.25787353515625  loc loss 2.981990337371826\n",
      "tensor(22.2399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.867910385131836  loc loss 1.8673009872436523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.7352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.769746780395508  loc loss 3.698723316192627\n",
      "tensor(34.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.4708309173584  loc loss 2.4052047729492188\n",
      "tensor(25.8760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.97840690612793  loc loss 2.887289047241211\n",
      "tensor(26.8657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.06485366821289  loc loss 4.224400520324707\n",
      "tensor(25.2893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.5721492767334  loc loss 2.4520349502563477\n",
      "tensor(22.0242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.268741607666016  loc loss 3.50402569770813\n",
      "tensor(32.7728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.94622230529785  loc loss 1.4515838623046875\n",
      "tensor(20.3978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.02435302734375  loc loss 2.5541837215423584\n",
      "tensor(23.5785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.637020111083984  loc loss 6.122516632080078\n",
      "tensor(28.7595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.336284637451172  loc loss 2.548370361328125\n",
      "tensor(22.8847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.01677131652832  loc loss 3.1072661876678467\n",
      "tensor(25.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.52352523803711  loc loss 2.1401724815368652\n",
      "tensor(27.6637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.472736358642578  loc loss 2.611734628677368\n",
      "tensor(23.0845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.49765396118164  loc loss 2.0760085582733154\n",
      "tensor(27.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.118925094604492  loc loss 2.2628941535949707\n",
      "tensor(24.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.067134857177734  loc loss 2.2102818489074707\n",
      "tensor(20.2774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 38.839256286621094  loc loss 3.125777244567871\n",
      "tensor(41.9650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.517961502075195  loc loss 3.776646137237549\n",
      "tensor(27.2946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.788585662841797  loc loss 2.3259925842285156\n",
      "tensor(21.1146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.102771759033203  loc loss 2.392500400543213\n",
      "tensor(27.4953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.022727966308594  loc loss 3.35915470123291\n",
      "tensor(33.3819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.8201961517334  loc loss 3.452932119369507\n",
      "tensor(27.2731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.07965850830078  loc loss 2.9647316932678223\n",
      "tensor(26.0444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.639404296875  loc loss 1.933396339416504\n",
      "tensor(20.5728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.97008514404297  loc loss 3.2719388008117676\n",
      "tensor(32.2420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.65106201171875  loc loss 2.802084445953369\n",
      "tensor(21.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 28.848182678222656  loc loss 5.082207679748535\n",
      "tensor(33.9304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.000686645507812  loc loss 3.0087382793426514\n",
      "tensor(28.0094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.225452423095703  loc loss 3.4011175632476807\n",
      "tensor(24.6266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 62.54417037963867  loc loss 3.5137503147125244\n",
      "tensor(66.0579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.950740814208984  loc loss 3.448885679244995\n",
      "tensor(25.3996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.501266479492188  loc loss 3.214590311050415\n",
      "tensor(25.7159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.181713104248047  loc loss 2.518549680709839\n",
      "tensor(23.7003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.46853256225586  loc loss 2.639829397201538\n",
      "tensor(29.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.300270080566406  loc loss 3.6142959594726562\n",
      "tensor(24.9146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.598285675048828  loc loss 2.60292911529541\n",
      "tensor(25.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 29.068809509277344  loc loss 2.775848865509033\n",
      "tensor(31.8447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.325180053710938  loc loss 1.7583857774734497\n",
      "tensor(24.0836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.54644203186035  loc loss 2.0945234298706055\n",
      "tensor(22.6410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.569616317749023  loc loss 2.773472547531128\n",
      "tensor(20.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 27.34345245361328  loc loss 2.901765823364258\n",
      "tensor(30.2452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 31.72239112854004  loc loss 2.2340352535247803\n",
      "tensor(33.9564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.446048736572266  loc loss 2.114741802215576\n",
      "tensor(21.5608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.723941802978516  loc loss 2.4082818031311035\n",
      "tensor(23.1322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.72890281677246  loc loss 2.0435681343078613\n",
      "tensor(20.7725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.362905502319336  loc loss 3.835454225540161\n",
      "tensor(34.1984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.276426315307617  loc loss 4.160170078277588\n",
      "tensor(25.4366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.55842590332031  loc loss 2.729703426361084\n",
      "tensor(38.2881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.127328872680664  loc loss 2.7590062618255615\n",
      "tensor(21.8863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 16.54177474975586  loc loss 2.335383176803589\n",
      "tensor(18.8772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 15.192070007324219  loc loss 1.7857495546340942\n",
      "tensor(16.9778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.643882751464844  loc loss 3.41451096534729\n",
      "tensor(26.0584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.256336212158203  loc loss 2.039597988128662\n",
      "tensor(23.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.224687576293945  loc loss 2.4005215167999268\n",
      "tensor(20.6252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.427268981933594  loc loss 2.871858596801758\n",
      "tensor(29.2991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.752601623535156  loc loss 1.74338960647583\n",
      "tensor(23.4960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.09832000732422  loc loss 3.1255366802215576\n",
      "tensor(24.2239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.926748275756836  loc loss 2.615999698638916\n",
      "tensor(21.5427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.210250854492188  loc loss 3.060821056365967\n",
      "tensor(33.2711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 25.33531951904297  loc loss 3.384909152984619\n",
      "tensor(28.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.34275245666504  loc loss 3.0510547161102295\n",
      "tensor(22.3938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.238426208496094  loc loss 2.314228057861328\n",
      "tensor(20.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 16.193832397460938  loc loss 2.015289306640625\n",
      "tensor(18.2091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls loss 15.712422370910645  loc loss 2.323425054550171\n",
      "tensor(18.0358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.206928253173828  loc loss 3.2501513957977295\n",
      "tensor(26.4571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.92996597290039  loc loss 2.438530445098877\n",
      "tensor(20.3685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 23.057065963745117  loc loss 3.103313684463501\n",
      "tensor(26.1604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.791608810424805  loc loss 3.134988307952881\n",
      "tensor(23.9266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.739944458007812  loc loss 2.1626317501068115\n",
      "tensor(22.9026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 26.575700759887695  loc loss 4.104878902435303\n",
      "tensor(30.6806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 30.37104034423828  loc loss 4.009044647216797\n",
      "tensor(34.3801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 24.5771484375  loc loss 3.177001476287842\n",
      "tensor(27.7542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 15.20145320892334  loc loss 1.9276493787765503\n",
      "tensor(17.1291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.698209762573242  loc loss 2.4207510948181152\n",
      "tensor(21.1190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.200897216796875  loc loss 2.0022594928741455\n",
      "tensor(21.2032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.322797775268555  loc loss 2.4639644622802734\n",
      "tensor(21.7868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 19.229610443115234  loc loss 2.267240524291992\n",
      "tensor(21.4969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.111787796020508  loc loss 2.2540366649627686\n",
      "tensor(22.3658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.612064361572266  loc loss 2.686384916305542\n",
      "tensor(23.2984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 21.49818992614746  loc loss 1.7505319118499756\n",
      "tensor(23.2487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 18.485366821289062  loc loss 3.3747496604919434\n",
      "tensor(21.8601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.70267105102539  loc loss 3.222508430480957\n",
      "tensor(25.9252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 35.3511848449707  loc loss 7.745979309082031\n",
      "tensor(43.0972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.470359802246094  loc loss 2.186814308166504\n",
      "tensor(22.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 20.58926010131836  loc loss 2.2467610836029053\n",
      "tensor(22.8360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 22.106658935546875  loc loss 3.9334802627563477\n",
      "tensor(26.0401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([12096])\n",
      "cls loss 17.465763092041016  loc loss 2.295816659927368\n",
      "tensor(19.7616, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a26e785ce86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcollect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpikachu_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounding_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-807c499b5dbe>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/image/detection.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                     \u001b[0mnum_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                     \u001b[0mbatch_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_object\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnum_object\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                         \u001b[0mbatch_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/ndarray/utils.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(source_array, ctx, dtype)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sparse_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(source_array, ctx, dtype)\u001b[0m\n\u001b[1;32m   2337\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source_array must be array like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2339\u001b[0;31m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2340\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mindexing_dispatch_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_indexing_dispatch_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexing_dispatch_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NDARRAY_BASIC_INDEXING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_nd_basic_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mindexing_dispatch_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NDARRAY_ADVANCED_INDEXING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_nd_advanced_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36m_set_nd_basic_indexing\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    705\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sync_copyfrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# value might be a list or a tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                     \u001b[0mvalue_nd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_value_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36m_sync_copyfrom\u001b[0;34m(self, source_array)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0msource_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             ctypes.c_size_t(source_array.size)))\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "collect = []\n",
    "for epoch in range(10):\n",
    "    for b in pikachu_dl:\n",
    "        optimizer.zero_grad()\n",
    "        image, bounding_boxes, labels = b\n",
    "        image = image.to(device)\n",
    "        bounding_boxes = bounding_boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "        loc_pred, cls_pred = model(image)\n",
    "        total_loss = criterion(loc_pred, bounding_boxes, cls_pred, labels)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        print(total_loss)\n",
    "        collect.append([total_loss.detach().cpu().numpy()])\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-54., device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f4340ddfef0>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(collect, columns=['loss']).astype(float)[100:].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed in nnms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'score tensor([0.4747], grad_fn=<IndexBackward>)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "bbspred, labelpred, score  = pikachu_ds.encoder.decode(\n",
    "    loc_pred[i].float().cpu(), \n",
    "    cls_pred[i].float().cpu(), \n",
    "    torch.Tensor([256, 256]).float().cpu()\n",
    ")\n",
    "\n",
    "image_to_show = np.moveaxis(\n",
    "    image[i].detach().cpu().numpy(),0, 2)\n",
    "\n",
    "matched_anchors_on_image = ia.BoundingBoxesOnImage(\n",
    "    [ia.BoundingBox(*b) for b in bbspred.detach().cpu().numpy()], shape=(256, 256))\n",
    "\n",
    "image_to_show = matched_anchors_on_image.draw_on_image(image_to_show, thickness=3)\n",
    "plt.imshow(image_to_show)\n",
    "plt.title('score ' + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Load a custom image with pikachu( or many ) and try to make predictiosn with the network and visualize the result\n",
    "-  Can you think of anything that could confuse our detector? yellow dots ?\n",
    "- Currently the code is not really modular, try to make it nice by splitting it into logical parts\n",
    "    - Base feature extractor Module\n",
    "    - Head Creator module\n",
    "- Currently the detection/cls HEADS are very simple (just one CONV layer) they can be more complex. Try using more convolutions, check other architectures how its done\n",
    "\n",
    "- Can you use our network to train using some new data for instance:\n",
    "    - https://www.kaggle.com/tomluther/ships-in-google-earth\n",
    "    - https://www.kaggle.com/aruchomu/data-for-yolo-v3-kernel\n",
    "    - https://www.kaggle.com/dataturks/face-detection-in-images\n",
    "    - https://www.kaggle.com/dataturks/face-dataset-with-age-emotion-ethnicity  \n",
    " You will need to create a data loader/data sets similar as we did for the pikachu loader. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
