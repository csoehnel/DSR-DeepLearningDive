{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from albumentations import (\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,\n",
    "    Compose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomGamma\n",
    ")\n",
    "\n",
    "from metrics import dice\n",
    "from data import NeuronSegmDataset\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "from encoders import ResNetEncoders\n",
    "from unet import UNet\n",
    "\n",
    "def tonp(t):\n",
    "    return t.detach().cpu().numpy()\n",
    "    \n",
    "def process_batch(b):\n",
    "    X, y  = b\n",
    "    X = X.to(DEVICE)\n",
    "    y = torch.tensor(y, dtype=torch.float).to(DEVICE)\n",
    "    return X, y\n",
    "\n",
    "def prediction_to_numpy(pred):\n",
    "    return pred.sigmoid().detach().cpu().numpy() \n",
    "\n",
    "def evaluate(model, loader, threshold):\n",
    "    model = model.eval()\n",
    "    for b in loader:\n",
    "        X, y = process_batch(b)\n",
    "        X = X.repeat(1, 3, 1, 1)\n",
    "        res = model(X)\n",
    "    val_loss = nn.BCEWithLogitsLoss()(res, y)\n",
    "    pred_Y, real_Y = prediction_to_numpy(res) > threshold, tonp(y)> threshold\n",
    "    dices = []\n",
    "    for ypred, yreal in zip(pred_Y, real_Y):\n",
    "        dices.append(dice(ypred, yreal))\n",
    "    return np.array(dices).mean(), val_loss.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_target = './train-labels.tif'\n",
    "neuron_train = './train-volume.tif'\n",
    "\n",
    "\n",
    "trans_train = transforms.Compose([transforms.Resize(192), \n",
    "                                  transforms.ToTensor()])\n",
    "trans_test = transforms.Compose([transforms.Resize(192), \n",
    "                                 transforms.ToTensor()])\n",
    "\n",
    "aug = Compose([RandomGamma(), \n",
    "               VerticalFlip(), \n",
    "               HorizontalFlip(),\n",
    "               RandomRotate90(), \n",
    "               GridDistortion(),\n",
    "               ElasticTransform(),\n",
    "               OpticalDistortion(distort_limit=1, shift_limit=1)])\n",
    "\n",
    "\n",
    "train_ds = NeuronSegmDataset(neuron_train, neuron_target, image_transform=trans_train, augmenter=aug)\n",
    "test_ds = NeuronSegmDataset(neuron_train, neuron_target, image_transform=trans_test)\n",
    "train_ds_val = NeuronSegmDataset(neuron_train, neuron_target, image_transform=trans_train)\n",
    "\n",
    "\n",
    "random_training_sampler = RandomSampler(train_ds)\n",
    "train_idx , test_idx = train_test_split(range(len(train_ds)), test_size=0.15)\n",
    "\n",
    "random_sampler_train = RandomSampler(train_idx)\n",
    "sampler_test = SequentialSampler(test_idx)\n",
    "\n",
    "training_data_loader = DataLoader(train_ds, batch_size=1, num_workers=1, sampler=random_training_sampler)\n",
    "test_data_loader = DataLoader(test_ds, batch_size=6, num_workers=1, sampler=sampler_test)\n",
    "train_ds_val_loader = DataLoader(train_ds_val, batch_size=6, num_workers=1, sampler=random_training_sampler)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# unet = OriginalUnet(n_classes=1,depth=3, padding=True, up_mode='upsample').cuda()\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "resnet = ResNetEncoders(18, pretrained=True).to(DEVICE)\n",
    "unet = UNet(resnet, 1).to(DEVICE)\n",
    "\n",
    "optim = torch.optim.Adam(unet.parameters())\n",
    "epochs = 1000\n",
    "loss_bce = nn.BCEWithLogitsLoss()\n",
    "loss = 0\n",
    "THRESHOLD = 0.5\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(range(epochs)):\n",
    "    for batch in training_data_loader:\n",
    "        X, y = process_batch(batch)\n",
    "        X = X.repeat(1,3,1,1)\n",
    "        prediction = unet(X)  # [N, 2, H, W]\n",
    "        loss = loss_bce(prediction, y)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()   \n",
    "        \n",
    "    val_mean_dice, val_loss = evaluate(unet, test_data_loader, threshold=THRESHOLD)\n",
    "    train_mean_dice, train_loss = evaluate(unet, train_ds_val_loader, threshold=THRESHOLD)\n",
    "    \n",
    "    print(\"epoch\", i)\n",
    "    print('dice', val_mean_dice)\n",
    "    print('loss', val_loss)\n",
    "    print('train_dice', train_mean_dice)\n",
    "    print('train_loss', train_loss)\n",
    "    unet.train()\n",
    "    \n",
    "    history['val_dice'].append(val_mean_dice)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_dice'].append(train_mean_dice)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(history)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('train/val dice')\n",
    "plt.plot(df.val_dice)\n",
    "plt.plot(df.train_dice)\n",
    "plt.legend(['val_dice', 'train_dice'])\n",
    "plt.figure()\n",
    "plt.title('val/train loss')\n",
    "plt.plot(df.val_loss)\n",
    "plt.plot(df.train_loss)\n",
    "plt.legend(['val_loss', 'train_loss'])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(prediction[0][0].detach().sigmoid().cpu().numpy(), cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(y.detach()[0][0].cpu().numpy(), cmap='gray')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
